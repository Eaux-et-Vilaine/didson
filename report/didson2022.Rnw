% lancement avec sweave, xelatex et biber
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%============================================================
%% DOCUMENT CLASS SETUP
%%============================================================
%%
\documentclass[11pt,twocolumn,titlepage,twoside]{article}
\setlength{\columnsep}{0.8cm} % séparateur central
\usepackage{float}
\usepackage[section]{placeins}  %The placeins package provides the command \FloatBarrier

%%============================================================
%%============================================================
%% PACKAGE SETUP
\usepackage{Sweave}
%\SweaveOpts{pdf=TRUE, echo=FALSE, fig=FALSE, eps=FALSE, tidy=T, width=4,
%height=4, keep.source=TRUE}

%% Input and language packages.
%\usepackage[utf8]{inputenc} %encodage du fichier source not used with xelatex
\usepackage[T1]{fontenc}  %gestion des accents (pour les pdf) 
%\usepackage[english]{babel}
\usepackage[francais]{babel}

%https://tex.stackexchange.com/questions/464585/what-tips-and-tricks-should-i-know-when-using-the-georgia-font-in-latex/464586
% \usepackage{fontspec} % charte graphique EPTB
\usepackage{amsmath}
\usepackage[math-style=ISO]{unicode-math}
\usepackage{microtype}
\defaultfontfeatures{Scale=MatchLowercase}
\setmainfont{Georgia}[Scale = 1.0]
\setmathfont{Asana Math.otf}
\addto\captionsfrench{\def\tablename{Tableau}}
\addto\captionsfrench{\renewcommand*{\contentsname}{Sommaire:}}
\addto{\captionsfrench}{\renewcommand*{\abstractname}{Résumé}}
\addto{\captionsfrench}{\renewcommand*{\listfigurename}{Figures}}
\addto{\captionsfrench}{\renewcommand*{\listtablename}{Tableaux}}

%% Parskip is the extra vertical space inserted before a paragraph. It has a natural length of zero but should be a rubber length so that it may be stretched in a flushbottom environment. To increase \parskip to skip a line between paragraphs one could use \addtolength{\parskip} {\baselineskip}.
\usepackage{parskip}

%% Sets space between lines.
\usepackage{setspace} 


%% If you use PostScript figures in your article
%% use the graphics package for simple commands
%\usepackage{graphics}
%% or use the graphicx package for more complicated commands (places the float at precisely the location in the LaTeX code [H]).
\usepackage{graphicx} 
\usepackage{float}
%% or use the epsfig package if you prefer to use the old commands.
%\usepackage{epsfig}

%% Using captions in floating environment. Note: might not work with other packages.
%\usepackage{caption}

%% Making numbered and bulleted lists.
\usepackage{enumerate}
\usepackage{enumitem} % listes avec A B C
%\definecolor{marron}{rgb}{0.64,0.16,0.16}
%% Math packages
%\usepackage{amsmath, amssymb}

%% The amsthm package provides extended theorem environments.
%\usepackage{amsthm}

%% The verbatim environment, \begin{verbatim} ... \end{verbatim}, permits us to insert large sections of reformatted text in a LaTeX file (including block of comments). It is very handy for inserting large chunks of code in a document, for example, literal TeX code or the Maple code you sweated over and now want to comment on.
%\usepackage{verbatim}

%% Add hyperlinks, so that you can click on references, theorem numbers etc. to jump to the place where they are in the paper (at least for the DVI and PDF versions), it seems that \documentclass{article} does not work with hyperref; use instead \documentclass{amsart}. Note: first test it with Elsevier template!

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor} % Invoke the package with the usenames and dvipsnames option to get 68 colors
\usepackage{color}
\definecolor{bleu_EV}{RGB}{0,33,143}
\definecolor{turquoise_EV}{RGB}{0,201,196}
\definecolor{orange_EV}{RGB}{255,117,87}
\definecolor{orange_EVf}{RGB}{178,81,60}
\definecolor{bleu_clair_EV}{RGB}{51,181,255}
\definecolor{jaune_EV}{RGB}{255,180,40}

\definecolor{grisbleu}{RGB}{66,66,143}
\definecolor{grisbleufonce}{RGB}{21,21,93}
\definecolor{rouille}{RGB}{135,71,45}
\definecolor{orange}{RGB}{255,165,0}
\definecolor{turquoise}{RGB}{0,128,128}
\definecolor{limegreen}{RGB}{50,205,50} % correspond a limegreen en R
\definecolor{purple2}{RGB}{160,32,240}
\definecolor{purplesombre}{RGB}{50,0,74}
\definecolor{purplemedian}{RGB}{67,0,100}
\definecolor{purpleclair}{RGB}{115,0,171}
\definecolor{violetred}{RGB}{208,32,144}
% A EDITER LIGNE 726 dans elsarticle.cls

%% The numcompress package shorten the last page in references.
%% `nodots' option removes dots from firstnames in references.
%\usepackage[nodots]{numcompress}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% If you are printing how many pages you submitted...
%\usepackage{lastpage}

%% The \url{...} command does all the work: It sets the enclosed expression in the appropriate typewriter style font, it takes care of any necessary linebreaking, and it chooses break points intelligently (e.g., between components of an address), and it ensures that special symbols such as the tilde symbol or the "at" symbol get typeset correctly.
\usepackage{url}

%% A new implementation of LATEX's tabular and array environment.
\usepackage{array}
\usepackage{enumerate}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{siunitx,booktabs}
\sisetup{group-separator={~}, 
group-minimum-digits={3}, % 3 caractères pour séparer les
output-decimal-marker={.}, % separateur
round-mode = places, % nombre de décimales après la virgule
round-precision = 0 % precision des arrondis
}
\usepackage{caption} % pour les subfigures http://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions
\usepackage{subcaption} % pour les subfigures

\addto{\captionsfrench}{\renewcommand{\tablename}{Tableau}}
\usepackage{calc}
\newlength\defaultparindent
\setlength{\defaultparindent}{\parindent}   %save default indentation   
%http://tex.stackexchange.com/questions/59175/boxes-overflow-column
%%============================================================
%% BIBLIOGRAPHY SETUP
%%============================================================
\usepackage[style=authoryear, %numeric
            natbib=true, % citep and citet
            backend=biber, % default for biblatex
            bibencoding=utf8,
            url=false, 
            doi=false,
            firstinits=true, % pas de prenoms
            %sorting=nyt, % name, year, title
            eprint=false]{biblatex} % option natbib to use cite and citep
\addbibresource{didson2021.bib}
%\usepackage[round, comma, sort]{natbib}


%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon (default)
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   authoryear - selects author-year citations (default)
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%   longnamesfirst  -  makes first citation full author list
%%
%%  e.g. \biboptions{longnamesfirst,comma}

\usepackage{hyperref}
\hypersetup{
     colorlinks=true,
     linkcolor=orange_EVf,
     urlcolor=bleu_EV,
     citecolor=grisbleufonce,
     bookmarks=true,  %créé des signets pour Acrobat
     bookmarksopen=true,            %si les signets Acrobat sont créés,
                                    %les afficher complètement.
     pdftitle={Suivi de la dévalaison de l'anguille argentée en 2021--2022
     (10ème année) sur la Vilaine à l'aide d'un didson},
     %informations apparaissant dans
     pdfauthor={Cédric Briand,Brice Sauvaget, Gérard Eriau},     %dans les
     % informations du document
     pdfsubject={anguille argentée},          %sous Acrobat
     pdfkeywords={anguille argentée}{migration}{dévalaison}{didson}{Vilaine}
}

%%============================================================
%%============================================================
%% PAGE SETUP
%% Use this section to override Elsevier article page settings!!!

	%% Easier way...
\usepackage[a4paper, right=1.5cm, left=1.5cm, top=2cm, bottom=3cm]{geometry}
	%% The hard way involves setting all the desired values manually. Here are some values that can be set: 
	%% Dimensions of the PDF file.
	%\pdfpageheight \pdfpagewidth
	%% Length of margin at top of page above all printing. 1 inch is added to this value.
	%\topmargin   
	%% Left margin on even numbered pages. 1 inch is added to this value.
	%\evensidemargin  
	%% Left margin on odd numbered pages. 1 inch is added to this value.
	%\oddsidemargin
	%% Height of the page header.
	%\headheight
	%% Distance from bottom of header to the body of text on a page.
	%\headsep
	%% Distance from top of main text box to the baseline of the first line of text in the main text box.
	%\topskip 
	%% Height and width of main text box.
	%\textheight \textwidth
	%% Distance from bottom of body to the bottom of the footer.
	%\footskip
	%% Distance between paragraphs.
	%\parskip
	%% Amount of indentation at the first line of a paragraph.
	%\parindent
	%% Uncomment if don't want page numbers.
	%\pagestyle{empty}
	%% Uncomment for 1.5 spacing between lines...
	%\renewcommand{\baselinestretch}{1.5}
	%% or use some of these
		%\singlespacing
		%\onehalfspacing
		%\doublespacing
		%\setstretch{1.1}
	%% Sets up hyphenation threshold.
	%\hyphenpenalty=675 \tolerance=950

\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{placeins}
\usepackage{animate}

%----------------------------------------------------------------------------------------
%	PAGE HEADERS (this must come after loading and setting geometry)
%----------------------------------------------------------------------------------------

\usepackage{fancyhdr} % Required for header and footer configuration
\pagestyle{fancy}

% Chapter text font settings
\renewcommand{\sectionmark}[1]{\markright{\sffamily\normalsize\thesection\hspace{7pt}#1}{}}
%\renewcommand{\subsectionmark}[1]{\markboth{}{\sffamily\normalsize\thesubsection\hspace{7pt}#1}}
% Section text font settings
\fancypagestyle{stylestandard}{
\fancyhf{} \fancyfoot[C]{\sffamily\normalsize\thepage} % Font setting for
% the page number in the header
\fancyhead[LE,RO]{\sffamily \rightmark}
\fancyhead[LO,RE]{\slshape \normalsize Rapport didson 2021-2022}
\renewcommand{\headrulewidth}{0.5pt} % Width of the rule under the header (slightly more than 0.4 pt)
\addtolength{\headheight}{2.5pt} % Increase the spacing around the header slightly
\renewcommand{\footrulewidth}{0pt} % Removes the rule in the footer
}
\fancypagestyle{styleannexe}{
\fancyhf{} \fancyfoot[C]{\sffamily\normalsize\thepage} % Font setting for
% the page number in the header
\fancyhead[LE,RO]{\sffamily Annexes}
\fancyhead[LO,RE]{\slshape \normalsize Rapport didson 2021-2022}
\renewcommand{\headrulewidth}{0.5pt} % Width of the rule under the header (slightly more than 0.4 pt)
\addtolength{\headheight}{2.5pt} % Increase the spacing around the header slightly
\renewcommand{\footrulewidth}{0pt} % Removes the rule in the footer
}

\fancypagestyle{plain}{\fancyhead{}\renewcommand{\headrulewidth}{0pt}} % Style for when a plain pagestyle is specified

%%============================================================
%%============================================================
%% DEFINING NEW COMMANDS AND ABBREVIATIONS
%% Use this section to define new commands that you will use in
%% your report.

%% Makes a path to your graphics' folder.
\graphicspath{{../../../pdata/didson/rapport/image/}}

\newcommand{\tab}{\hspace*{2em}}
\newcommand{\DD}{D\&D}
\newcommand{\oxygen}{O$ _2 $}

\renewcommand{\labelitemi}{--}
\newcommand\solidrule[1][1cm]{\rule[0.5mm]{#1}{0.2mm}}
\newcommand\dashedrule{\mbox{%
  \solidrule[1mm]\hspace{1mm}\solidrule[1mm]\hspace{1mm}\solidrule[1mm]}}


%% Add extra space to multi-line equation environments
%\setlength{\jot}{9pt}

% use \mbox{...} for no separation of the defined word


%----------------------------------------------------------------------------------------
%	TO POSITION WITH TKIZ (definition commande page)
% https://tex.stackexchange.com/questions/89588/positioning-relative-to-page-in-tikz 
%
% ----------------------------------------------------------------------------------------
\usepackage{tikz} % Required for drawing custom shapes
\makeatletter
\def\parsecomma#1,#2\endparsecomma{\def\page@x{#1}\def\page@y{#2}}
\tikzdeclarecoordinatesystem{page}{
    \parsecomma#1\endparsecomma
    \pgfpointanchor{current page}{north east}
    % Save the upper right corner
    \pgf@xc=\pgf@x%
    \pgf@yc=\pgf@y%
    % save the lower left corner
    \pgfpointanchor{current page}{south west}
    \pgf@xb=\pgf@x%
    \pgf@yb=\pgf@y%
    % Transform to the correct placement
    \pgfmathparse{(\pgf@xc-\pgf@xb)/2.*\page@x+(\pgf@xc+\pgf@xb)/2.}
    \expandafter\pgf@x\expandafter=\pgfmathresult pt
    \pgfmathparse{(\pgf@yc-\pgf@yb)/2.*\page@y+(\pgf@yc+\pgf@yb)/2.}
    \expandafter\pgf@y\expandafter=\pgfmathresult pt
}
\makeatother
\usepackage{eso-pic,graphicx}
%%===============================================%%
%%==========    END OF THE PREAMBLE    ==========%%



%%============================================================
%%============================================================
%%============================================================
% BEGINNING OF THE TEXT BODY

%% You can write here small footer that will go on the first page, together with
%% the date stamp; comment the line if you don't want that!
%\footme{Submitted to Someone Somewhere\hspace{2mm}(\pageref{LastPage} pages)} \datestamp{Andrej Korenic, 27$^{th}$ October, 2011}

\begin{document}
\thispagestyle{empty}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
\newgeometry{right=0.5cm, left=1.5cm, top=1cm, bottom=1cm,includefoot} % also
% insert a clearpage where called
\begin{titlepage} 
\begingroup % similar to { with all settings are confined to this group ... 

% for this command creates a background picture to the title page
\AddToShipoutPicture*{\put(0,0){%
\parbox[b][\paperheight]{\paperwidth}{%
\vfill
\includegraphics[%width=\paperwidth,
height=\paperheight,%
keepaspectratio]{frontpage.png}%
%\vfill
}}}%

\hfill%
\begin{minipage}{0.28\textwidth}
\par\sffamily\selectfont
\Large 
Suivi de la dévalaison d'anguilles argentées en 2021-2022 (dixième
année) sur la Vilaine à l'aide d'un didson.\\
\vspace{2cm}\\
\includegraphics[width=0.8\textwidth]{logo_EV} 
\end{minipage}

\vspace{3cm}
\hfill{ %
\begin{minipage}{0.28\textwidth}
\textbf{
Date d'édition :\\}
\color{orange_EV}
\begin{center}
\Large
Mars 2022
\end{center}
\vspace{2cm}\\
\end{minipage}
}%
       
    
\hfill{ %
\begin{minipage}{0.28\textwidth}
\textbf{Réalisé avec le concours de} : 
% le logo de l'agence doit au moins faire 25 mm de haut      
\vspace{1cm}\\
\centering{\includegraphics[\textwidth]{logo_agence.png}} 
\end{minipage}
}%  
\vfill
\hfill{ %
\begin{minipage}{0.3\textwidth}
\large
\color{bleu_EV}
\leftskip=1cm
Cédric Briand\par   
Brice Sauvaget\par
Gérard Eriau\par
\vspace{1cm}
\end{minipage}
}% 
\endgroup
\end{titlepage}





\newpage
\newgeometry{right=1.5cm, left=1.2cm, top=0.2cm, bottom=2cm}
\pagecolor{white}
\thispagestyle{empty}
\begin{minipage}{\textwidth}
\includegraphics[width=6cm,keepaspectratio=true]{logo_EV.jpg}
\end{minipage}

\vspace*{2cm}
\begin{minipage}{0.1\textwidth}
\phantom{This text will be invisible}
\end{minipage}
\begin{minipage}{0.8\textwidth}
\begin{center}
\noindent
{\color{turquoise_EV}\rule{\textwidth}{2.5pt}}\\
\vspace{10mm}
\color{bleu_EV}
{ \huge  \bfseries{Suivi de la dévalaison d'anguilles argentées sur la Vilaine
à l'aide d'un didson}}\\ 
\bigskip
{ \LARGE en 2020--2021 (9ème année)}

\noindent
{\color{turquoise_EV}\rule{0.9\textwidth}{1.8pt}}\\
\vspace{5mm}
{\color{orange_EV}{\Large \itshape{Cédric Briand, Brice Sauvaget, Gérard
Eriau}}}
\end{center}
\end{minipage}
\vfill
\hfill \Large Mars 2022

\normalsize

\restoregeometry
\clearpage



<<init, echo=FALSE, eval=TRUE,results=hide >>=
# ATTENTION LE LANCEMENT DE CHUNKS CONTENANT DPLYR FAIT PLANTER LE CALCUL DE INTERSECT POUR LES POLYGONES
# CHUNKS d3ej d3ejperiodes d3ejfinal didson... tout ce qui utilise la fonction drawdi !
#options("encoding" = "UTF-8")
obj<-ls(all=TRUE)
obj<-obj[!obj%in%c("passworddistant","passwordlocal","userdistant","hostdistant","mainpass")]

rm(list=obj) # nettoyage complet sauf passwords
load_library=function(necessary) {
	if(!all(necessary %in% installed.packages()[, 'Package']))
		install.packages(necessary[!necessary %in% installed.packages()[, 'Package']], dep = T)
	for(i in 1:length(necessary))
		library(necessary[i], character.only = TRUE)
}
load_library('stringr') # text handling
CY=2022
saison <- str_c((CY-1),"-",CY)
debut <- str_c(CY-1,"-09-01 00:00:00")
fin <- str_c(CY,"-05-01 00:00:00")
toutdebut <- str_c(2012,"-09-01 00:00:00")
datedebut<-str_c(CY-1,"-09-01")
datefin<-str_c(CY,"-05-01")
graphics.off()
setwd("C:/workspace/didson/report")
datawd<-"C:/workspace/didson/data/" 
datawdy<-str_c(datawd,CY,"/")
imgwd<-"C:/workspace/didson/image/"
imgwdy<-str_c(imgwd,CY,"/")
tabwdy<-str_c("C:/workspace/didson/table",CY,"/")

load_library('RODBC') # odbc connector
load_library('stacomirtools') # connection tools
load_library('grDevices') # star symbol
load_library('sqldf') # mimict sql queries in a data.frame #citation("sqldf")
load_library('RPostgreSQL') # one can use RODBC, here I'm using direct connection via the sqldf package
# loading RPostgresSQL ensures that postgres is used as a default driver by sqldf
# setting options to access postgres using sqldf
#load_library('plyr')# join fuction
load_library('ggplot2')# join fuction
load_library('gpclib') # to calculate polygons intersections
load_library('Hmisc')
load_library('png')
load_library('car')
load_library('grid')
load_library('vcd')
load_library('lubridate')
load_library('circular')
load_library('reshape2')
load_library('stargazer')
load_library('mgcv')
load_library('MASS')
load_library('xtable')
load_library('tidyverse') # conflict with intersect ... fixed
#'==========================================================
#' fonction de nettoyage du code latex
#'==========================================================

sanitizeLatexS <- function(str) {
	gsub('([#$%&~_\\^\\\\{}])', '\\\\\\\\\\1', str, perl = TRUE);
}

#'==========================================================
#' fonction d'impression des nombres
#'==========================================================
#'==========================================================
#' fonction d'application de la transparence à des couleurs.
#'==========================================================
makeTransparent<-function(someColor, alpha=100)
{
	newColor<-col2rgb(someColor)
	apply(newColor, 2, function(curcoldata){rgb(red=curcoldata[1], green=curcoldata[2],
						blue=curcoldata[3],alpha=alpha, maxColorValue=255)})
}	#note: always pass alpha on the 0-255 scale
#'==========================================================
#' FONCTION DE TRACAGE ET CALCUL DU didson
#' l'angle beta est négatif vers le bas, l'angle alpha est positif vers le bas.
#' alpha en degrés
#'fond  Paramètre fixant la profondeur du fond
#' profdid profondeur didson
#' dist distance de l'intercept sur l'axe des X, beta l'angle, donner l'un ou l'autre
#' hpas parametre donnant la hauteur de la colonne d'eau dans laquelle passent les anguilles
#' hvan hauteur de la vanne
#' print faut il donner les valeurs de l'angle ou de l'intercept (en fonction de l'un et l'autre)
#' graph faut il produire un graphique ?
#' divide si une valeur autre que NA est donnée, faut il produire des polygones tous les découpages, divide nombre en mètres, peut-être un vecteur, correspond aux distances pas aux limites
#' vectdist vecteur des distances d'observations au didson (correspond à des anguilles)
#' vectdir direction des anguilles
#' distnoise bruit sur la droite perpendiculaire
#' fond=-7.72;profdid=-6.92;alphadegres=14;dist=6;betadegres=NA;d1=2.5;d2=d1+10;hpas=2;print=FALSE;graph=FALSE;divide=NA;hvan=NA
#'  Attention la surface de la zone de migration est surestimée de 0.2 pour des raisons graphiques, le calcul n'est pas repris dans le script....
#'==========================================================
drawdi<-function(fond=-7.72, profdid=-6.92, alphadegres=14, dist=6, betadegres=NA, d1=2.5,d2=d1+10, hvan=NA, hpas=2,
		print=FALSE, graph=FALSE, divide=NA, volet=FALSE, chargevolet=NA, retrait=0.2, vectdist=NA, vectdir=NA,
		couleur=rainbow(length(detection_frames),alpha=0.3)){
	hautvolet<-1.38
	if (is.na(chargevolet)) chargevolet<-0.3
	if (is.na(hvan)) hvan=hpas
	alpha= alphadegres*pi/180# conversion de degrés en radians (180°=Pi)
	slopealpha=tan(alpha) # pente de l'angle par rapport à l'axe 0x
	if (is.na(dist)&is.na(betadegres)|!is.na(dist)&!is.na(betadegres)) {
		stop ("il faut dist ou béta, l'un des deux")
	} else if (is.na(dist)){ # on donne un angle
		beta=betadegres*pi/180
		dist=(fond-profdid)/tan(beta) #H/dist=cos(pi/2-beta)
		slopebeta=tan(beta)
		if (print) cat ("la distance d'interception est de ", dist,"m \n")
	} else { # on donne une distance 
		
		slopebeta=(fond-profdid)/dist
		beta=atan(slopebeta)		
		betadegres<-beta*180/pi
		if (print) cat ("l'angle est de ",round(betadegres,2),"degrés \n")
	}
	pentesup <- tan(beta+alpha/2) # pente de la limite de la zone de détection vers la surface
	penteinf <- tan(beta-alpha/2) # pente de la limite de la zone de détection vesr le fond
	perpslope <- -1/slopebeta # pente de la droite perpendiculaire à l'axe de détection, le produit des
	# coefficients directeurs vaut -1
	# ou
	#perpslope<-tan(beta+pi/2)
	# CALCUL DES POLYGONES DE DETECTION ET MIGRATION
	calculate_poly<-function(d1,d2){
		d1supx=(d1/cos(alpha/2))*cos(beta+alpha/2)
		d1infx=(d1/cos(-alpha/2))*cos(beta-alpha/2)
		d1supy=pentesup*d1supx+profdid  # a partir de l'équation de la droite
		d1infy=penteinf*d1infx+profdid  # a partir de l'équation de la droite
		d2supx=(d2/cos(alpha/2))*cos(beta+alpha/2)
		d2infx=(d2/cos(-alpha/2))*cos(beta-alpha/2)
		d2supy=pentesup*d2supx+profdid  # a partir de l'équation de la droite
		d2infy=penteinf*d2infx+profdid  # a partir de l'équation de la droite
		poly<-cbind(c(d1supx,d2supx,d2infx,d1infx),c(d1supy,d2supy,d2infy,d1infy))
		#polygon(poly2,col="red")
		detection_frame <- as(poly, "gpc.poly")
		return(detection_frame)
	}
	detection_frame<-calculate_poly(d1,d2)
	poly2<-	cbind(c(18,18,retrait,retrait),c(fond,fond+hpas,fond+hpas,fond))
	if (volet) poly2<-	cbind(c(18,18,retrait,retrait),c(hautvolet+chargevolet-hpas,hautvolet+chargevolet,hautvolet+chargevolet,hautvolet+chargevolet-hpas))
	migration_frame <- as(poly2, "gpc.poly")	
	# CALCUL D'UN DECOUPAGE DE POLYGONES
	if (!is.na(divide[1])){
		detection_frames <- list()
		if (max(divide)>=(d2-d1)) stop("il n'est pas possible de diviser d2-d1=",d2-d1,"en portions de ",divide," m, suggestion mettre divide=NA" )
		dist <- d1
		i <- 1
		dividev <- divide[1]
		while (dist<d2-dividev){	
			if (length(divide)>1)
				dividev<-divide[i] else dividev<(divide[1])
			detection_frames[[i]]<-list()
			detection_frames[[i]][["range"]]<-str_c(dist,"-",dist+dividev)
			detection_frames[[i]][["poly"]]<-calculate_poly(dist,dist+dividev)
			dist=dist+dividev
			i=i+1
		}
		# pour le dernier
		detection_frames[[i]]<-list()
		detection_frames[[i]][["range"]]<-str_c(dist,"-",d2)	
		detection_frames[[i]][["poly"]]<-calculate_poly(dist,d2)
		
		
		detection_frames_range <- sapply(detection_frames,function(X) X$range)	
		detection_frames_intersect_area <- sapply(detection_frames,
				function(X) round(gpclib::area.poly(gpclib::intersect(X$poly,migration_frame)),2))
	} else {
		detection_frames_range<-NA	
		detection_frames_intersect_area<-NA
	}
	
	# GRAPHIQUE
	if (graph){
		plot(x=NA,xlim=c(20,-2),ylim=c(fond-3,4.63),ylab="profondeur (m NGF)",xlab="distance(m)")
		im <- readPNG( str_c(imgwd,"concrete.png"), native = TRUE )
		rasterImage( im,  20, fond-3, -2, 4.63 )
		rect(xleft=18,ybottom=fond,xright=retrait,ytop=4.63,col="aquamarine")
		im <- readPNG( str_c(imgwd,"iron.png"), native = TRUE )
		rasterImage( im,  xleft=18,ybottom=fond+hvan,xright=retrait,ytop=hautvolet+hvan)
		
		#polygon(x=c(19,19,18,18,0,0,-1,-1),y=c(fond-2,4.63,4.63,fond,fond,4.63,4.63,fond-2),col="grey20") # fond
		
		plot(migration_frame,poly.args = list(col=makeTransparent("yellow",alpha=100)),add=TRUE)
		if(volet){
			rect(xleft=18,ybottom=hautvolet,xright=retrait,ytop=hautvolet+chargevolet,col="aquamarine3")			
		}
		if (is.na(divide)){
			# affichage si le polygone de détection n'est pas découpé
			plot(detection_frame,poly.args = list(col = makeTransparent("yellow",alpha=100)), add = TRUE)
		}
		plot(gpclib::intersect(migration_frame,detection_frame),poly.args = list(col = makeTransparent("white",alpha=80)), add = TRUE)
		points(0,profdid,col="green",cex=2,pch=16) # didson
		# pour une droite bx+a, tracé des lignes
		abline(a=profdid,b=slopebeta,col="red") # pour un intercept à la distance de dist, on touche le fond et il faut rajouter l'intercept x=(Y-b)/a
		abline(a=profdid,b=pentesup,lty=2) # droite supérieure
		abline(a=profdid,b=penteinf,lty=2) # droite inférieure
		abline(b=perpslope,a=fond-perpslope*dist,lty=3) # perpendiculaire au point ou le centre touche le fond
		# fonction pour tracer les droites perpendiculaires à l'axe du didson
		fperp<-function(newdist,col){
			y=profdid+newdist*sin(beta)
			x=0+newdist*cos(beta)
			adistx=y-perpslope*x# Y-slope*x
			abline(a=adistx,b=perpslope,lty=4,col=col) # perpendiculaire au point ou le centre touche le fond
			text(x,y,str_c(newdist,"m"),pos=4, col=col)
		}
		fperp(d1,"white")
		fperp(d2,"white")
		if (!is.na(divide)){
			couleurs<-couleur
			for (i in 1:length(detection_frames)){
				plot(detection_frames[[i]]$poly,poly.args = list(col = couleurs[i]), add = TRUE)
			}
		}
		
		# ci dessous pour mettre les anguilles vues à un vecteur de dist du didson
		# et pour un bruit (le long de la droite perpendiculaire) de distnoise
		if (!is.na(vectdist[1])){
			fpointperp<-function(vectdist,vectdir){
				# au max on met des points jusqu'à 0.6 le bord
				noise<-runif(length(vectdist),-d1*0.6*tan(alpha/2),d1*0.6*tan(alpha/2))
				noise<-noise*vectdist/d1
				y=profdid+vectdist*sin(beta)+noise*cos(beta)
				x=0+vectdist*cos(beta)-noise*sin(beta)
				dir<-vectdir=="Up"
				points(x[dir],y[dir],pch="+",cex=0.7)
				points(x[!dir],y[!dir],pch="-",cex=0.7)
			}
			fpointperp(vectdist,vectdir)
		}
	}
	return(list("area_intersect"=round(area.poly(gpclib::intersect(detection_frame,migration_frame)),2),
					"area_migration_frame"=area.poly(migration_frame),
					"det_frames_int_area"=detection_frames_intersect_area,
					"det_frames_range"=detection_frames_range))
}
#'==========================================================
#' FONCTION DE TRACAGE ET CALCUL DES DISTANCES DE PASSAGE D'ANGUILLES POUR DES CONDITIONS DONNEES
#' proddid profondeur du didson
#' incl beta en degrés
#' Phi  "s" ou "f" note "sf" (transitions entre vannes et volets) est selectionné par les deux 
#' distancestart distance de début du didson, si plusieurs valeurs existent pour les conditions sélectionnées, la
#' fonction renvoit un message, et la zone entre les distances est sélectionné pour le calcul
#' timestamp un vecteur charactère de longueur 2, transformé en timestamp, le format doit être 
#' timestamp=c("2013-11-05 00:00:00","2013-12-25 00:00:00")
#' nomperiod= nom stocké dans la liste et nom du pdf écrit dans le répertoire imgwdy
#' print soit "pdf" pour sortir un pdf soit png, soit n'importe quelle chaine pour avoir à l'écran
#' @return ppp une liste avec les extrations dddp, d3ej, le nombre total montant + avalant, le nombre de périodes de 30 minutes (N)
#' le nombre d'anguilles + et -, la hauteur moyenne de la vanne4 (moyenne pondérée par les effectifs dévalant durant chaque période),
#' d1=la distance d'enregistrement au didson, chargevolet la moyenne pondérée par les effectifs de la charge sur le volet. La fonction retourne aussi un graphique. Attention les positions des anguilles
#' dans le champ perpendiculaire a la direction du faisceau sont générés aléatoirement.

drawdicriter<-function(profdid,
		incl,
		Phi, # s ou f, les valeurs sf de transition sont inclues pour les deux
		distancestart=NA,
		timestamp=NA,
		nomperiode="preciser",
		print="pdf",
		couleur=rainbow(5,alpha=0.3)){
# regarder distancestart et ouverture vanne	
	cat(nomperiode, "\n ---------------------------\n")
	logi<-d3ej$dsf_incl==incl&
			!is.na(d3ej$dsf_incl)&
			d3ej$dsf_depth==profdid&
			!is.na(d3ej$dsf_depth)&
			grepl(Phi,d3ej$optvanne4)
	if (!is.na(distancestart)) logi<-logi&d3ej$dsf_distancestart==distancestart
	if (!is.na(timestamp[1])) {
		if(length(timestamp)!=2) stop("le timestamp doit comporter une date de début et une date de fin")
		timestamp<-strptime(timestamp,format="%Y-%m-%d %H:%M:%S")
		logi<-logi&d3ej$dsf_timeinit>=timestamp[1]&
				d3ej$dsf_timeinit<=timestamp[2]
	}
	
	if (incl==0) incl_=incl+0.1 else incl_=incl#pb de division par zéro
	if (sum(logi)==0) stop("attention ne correspond à aucun critères")
	cat(str_c("N=",sum(logi),"\n"))
	d3ej_per<-d3ej[logi,
			c("dsf_id","dsf_timeinit","dsf_depth","optvanne4","dsf_distancestart","niveauvilaine30","hvanne4","dsr_eelplus","dsr_eelminus")]
	daterange<-str_c(min(d3ej_per$dsf_timeinit),"=>",max(d3ej_per$dsf_timeinit))
	eff<-d3ej_per$dsr_eelplus+d3ej_per$dsr_eelminus
	cat((str_c("Nsuivi=",length(eff[!is.na(eff)]),"\n")))
	cat((str_c("dates =",daterange," ")))
	daterange<-str_c(format(as.Date(min(d3ej_per$dsf_timeinit)),"%d %b")," au ",format(as.Date(max(d3ej_per$dsf_timeinit)),"%d %b"))
	cat((str_c("prof =",profdid," incl=",incl," Phi=",Phi,"\n")))
	eff1<-eff
	eff1[is.na(eff)]<-"NA"
	cat((str_c("Eff=",str_c(eff1,collapse=","),"\n")))
	
	cat((str_c("Eff_tot=",sum(eff,na.rm=TRUE),"\n")))
	if (Phi=="s"){
		chargevolet<-round(weighted.mean(d3ej_per$niveauvilaine30[!is.na(eff)],eff[!is.na(eff)])-1.38,2)
		volet=TRUE
		hvanne4=0
		hpas=chargevolet*PARM[2]
	} else {
		chargevolet<-NA
		hvanne4<-round(weighted.mean(d3ej_per$hvanne4[!is.na(eff)],eff[!is.na(eff)]),2)
		volet=FALSE
		hpas=hvanne4*PARM[1]
	}
	d1<-unique(d3ej_per$dsf_distancestart)
	if (length(d1)>1) {
		cat(str_c("attention d1=",str_c(d1,collapse=",")," précisez les valeurs, utilisation de toute la gamme"))
		d2=max(d1)+10
		d1=min(d1)
	} else {
		d2=d1+10
	}
# Dans dddp je n'ai pas les conditions de l'environnement, je vais chercher les bonnes lignes
# avec dsf_id
	
	dddp_per<-dddp[dddp$dsf_id%in%d3ej_per$dsf_id,
			c("dsf_timeinit","psf_dir","psf_l_cm","psf_q","psf_motion","psf_move","psf_comment","psf_radius_m")]
	ppp[[nomperiode]]$plus<-sum(d3ej_per$dsr_eelplus,na.rm=TRUE) # 26
	ppp[[nomperiode]]$minus<-sum(d3ej_per$dsr_eelminus,na.rm=TRUE)
	ppp[[nomperiode]]$dates<-daterange
	ppp[[nomperiode]]$dddp<-dddp_per
	ppp[[nomperiode]]$d3ej<-d3ej_per
	ppp[[nomperiode]]$hvanne4<-hvanne4
	ppp[[nomperiode]]$d1<-d1
	ppp[[nomperiode]]$chargevolet<-chargevolet
	ppp[[nomperiode]]$N<-sum(logi)
	ppp[[nomperiode]]$Nsuivis<-length(eff[!is.na(eff)])
	ppp[[nomperiode]]$prof <-profdid
	ppp[[nomperiode]]$incl<-incl
	ppp[[nomperiode]]$Phi=Phi
	dddp[dddp$dsf_id%in%d3ej_per$dsf_id,"periode"]<-nomperiode
	if (print=="pdf"){
		cat(str_c("écriture du fichier ",nomperiode,".pdf\n"))
		pdf(file=str_c(imgwdy,nomperiode,".pdf"),width=7,height=5)
	} else if (print=="png"){
		cat(str_c("écriture du fichier ",nomperiode,".png\n"))
		png(file=str_c(imgwdy,nomperiode,".png"),width=700,height=500)
	}
	d<-drawdi(fond=-7.72,
			profdid=profdid,
			alphadegres=14,
			dist=NA,
			betadegres=incl_,
			d1=d1, 
			d2=d2,
			hpas=hpas,# lambda=6
			hvan=hvanne4, 
			graph=TRUE,
			divide=2,
			volet=volet,
			chargevolet=chargevolet,
			vectdist=dddp_per$psf_radius_m,
			vectdir=dddp_per$psf_dir,
			couleur=couleur)
	if (print=="pdf"|print=="png"){
		dev.off()
	}
	dddp<<-dddp
	return(ppp)
}

open_in_excel <- function(some_df){
	tFile<-paste("C:/temp/",gsub("\\\\","",tempfile(fileext=paste0(substitute(some_df), ".csv"),tmpdir="")),sep="")
	write.table(some_df, tFile, row.names=F, sep=";", quote=F)
	system(paste('open -a \"/ProgramData/Microsoft/Windows/Start Menu/Programs/Microsoft Office/Microsoft Excel 2010\"', tFile))
}
#'==========================================================
#' Définition du nom des couleurs
#'==========================================================
#'  Ces couleurs sont en cohérence avec les couleurs latex
rouille="#87472D"
turquoise="#008080"
orange="#FF8040"
bleu_EV <- "#00218f"
turquoise_EV <- "#00C9C4"
orange_EV <- "#ff7557"
orange_EVf <- "#b2513c" # foncé
bleu_clair_EV <- "#33b5ff"
jaune_EV <- "#ffb428"
grisbleu="#42428F"
purplesombre="#32004A"
purplemedian="#430064"
purpleclair="#7300AB"
grisbleufonce="#15155D"


#drawdi(fond=-7.72,profdid=-6.92,alphadegres=14,dist=6,betadegres=NA,d1=5,print=TRUE,graph=TRUE)
#drawdi(fond=-7.72,profdid=-6.92,alphadegres=14,dist=6,betadegres=NA,d1=5,print=TRUE,graph=TRUE,divide=1)
#vannefond
#drawdi(fond=-7.72,profdid=-6.92,alphadegres=14,dist=NA,betadegres=-3,d1=2.5,d2=12.5, hpas=3,hvan=1.5,graph=TRUE,divide=2) # ici on passe l'angle
#vannedroit
#drawdi(fond=-7.72,profdid=-6.92,alphadegres=14,dist=NA,betadegres=4,d1=5,d2=15,hpas=7,hvan=1.5,print=TRUE,graph=TRUE,divide=c(2,2,2,2,2))
# Volets
#drawdi(fond=-7.72,profdid=1.15,alphadegres=14,dist=NA,betadegres=-7,d1=5,d2=15,hvan=0,hpas=4,print=FALSE,graph=TRUE,divide=2,volet=TRUE,chargevolet=0.7)
# Volets 40 °
#drawdi(fond=-7.72,profdid=1.20,alphadegres=14,dist=NA,betadegres=-40,d1=4,d2=14,hvan=0,hpas=2,print=TRUE,graph=TRUE,divide=2,volet=TRUE,retrait=0.4)
# fond 70 °
#drawdi(fond=-7.72,profdid=-7.2,alphadegres=14,dist=NA,betadegres=70,d1=2,d2=12,hvan=0,hpas=2,print=TRUE,graph=TRUE,divide=2,volet=FALSE)
# fonddroitbutée
#drawdi(fond=-7.72,profdid=-7.2,alphadegres=14,dist=NA,betadegres=5,d1=2,d2=12,hvan=0,hpas=2,print=TRUE,graph=TRUE,divide=2,volet=FALSE)
#crue surface ouestil ?
#drawdi(fond=-7.72,profdid=1.15,alphadegres=14,dist=NA,betadegres=7,d1=2,d2=12,hvan=0,hpas=2,print=TRUE,graph=TRUE,divide=2,volet=TRUE,chargevolet=0.72)
#crue surface ouestil ?
# ce tableau est compilé en fin de rapport, en boucle, je le repasse en début de rapport dans le résumé
#drawdi(fond=-7.72,profdid=1.15,alphadegres=14,dist=NA,betadegres=-26,d1=5,d2=15,hvan=0,hpas=2,print=TRUE,graph=TRUE,divide=2,volet=TRUE,chargevolet=0.72)
# ppp<-list()
#save(ppp,file=str_c(datawdy,"ppp.Rdata"))
load(file=str_c(datawdy,"final.Rdata")) #final
load(file=str_c(datawdy,"Nprim04all.Rdata")) #Nprim04all=

load(file=str_c(datawdy,"ppp.Rdata"))
#Nprim04all=0
#final<-matrix(1,10,10)
#PARM=c(3,6)#paramètres d'extrapolation fond surface
# premier paramètre = DEPRECATED mulitplication de la hauteur pour ouverture vanne
# deuxième paramètre = hauteur de migration pour la tranche de surface.
#(en coefficient multiplicateur de la charge)
# troisième paramètre couche de surface sans migration
PARM=c(NA,6,2)
# attention changement de la signification pour les stats bayésiennes
load(file=str_c(datawdy,"vvv.Rdata"))
@


\pagestyle{stylestandard}
\begin{abstract}
    
Les dévalaisons d'anguilles argentées ont été suivies, pour la neuvième année
  consécutive, à l'aide d'un sonar multifaisceaux (didson). Le didson est placé
  sur un rail porteur au niveau du quatrième pertuis de vannes du barrage d'Arzal à la limite de l'estuaire de la Vilaine.
 Sur les neuf années,  \num{\Sexpr{round(Nprim04all)}} anguilles
 argentées ont été comptées lors des dépouillements. En \Sexpr{saison},
 \num{\Sexpr{round(Nprim04allCY)}} anguilles ont été comptées. L'efficacité de
 la détection a été calculée en fonction de la taille des anguilles, de la
 position du didson et de la distance au didson. Les effectifs migrants sont
 calculés en extrapolant à l'ensemble de la vanne le pourcentage de surface de
 suivi par le sonar, puis en utilisant le ratio des débits de la vanne 4 aux
 autres vannes.
 Les effectifs suivis pour les configurations correctes, 
 c'est à dire quand le didson est bien positionné par rapport aux écoulements,
  en surface et au fond sur la vanne (N=\num{\Sexpr{vvv$Nprim04.odot}}),  
  ont été extrapolés à l'ensemble des vannes
  (N=\num{\Sexpr{vvv$N.odot}}).
  Lorsque le didson est mal placé, les effectifs sont estimés à partir des densités du jour même 
  (N=\num{\Sexpr{vvv$N.oplus}}). Un modèle calé sur l'ensemble des journées de
  suivi a été calé pour estimer les effectifs lorsque le didson n'était pas en
  mesure d'apporter une estimation journalière des effectifs
  (N=\num{\Sexpr{vvv$N.otimes}}).
  L'estimation
  quantitative de la dévalaison sur la Vilaine, sur la période de suivi,
  s'établit à (N=\num{\Sexpr{vvv$N}}) soit \Sexpr{vvv$total_weight} tonnes. 
  Les tendances interannuelles de cette migration sont détaillées dans le
  rapport (baisse, puis possible augmentation).\\
  
  Mots clés : anguille argentée \sep migration \sep dévalaison \sep didson \sep
	Vilaine.
    
  \textit{  
  \centering{\textbf{Abstract}}\\
  \smallskip
 Silver eel migrations were monitored, for the ninth year
  in a row, using a multibeam sonar (didson). The didson is placed
  on a guiding rail at the level of the fourth sluice gate of the Arzal dam at
  the limit of the Vilaine estuary.
 Over nine years, \num{\Sexpr{round(Nprim04all)}} silver eels
 silver were counted during the readings. In \Sexpr{saison},
 \num{\Sexpr{round(Nprim04allCY)}} eels have been counted. The effectiveness of
 the detection was calculated according to the size of the eels, the
 position of the didson and distance to the didson. To extrapolate the
 numbers of silver eel to the entire dam, the percentage of gate area monitored
 by sonar, and the ratio of the flow rates from gate 4 to other gates were used.
 Numbers monitored for the correct setting,
 i.e. when the didson is well positioned in relation to the flows,
  at the surface and at the bottom on the gate (N = \num{\Sexpr{vvv$Nprim04.odot}}),
  have been extrapolated to all gates
  (N = \num{\Sexpr{vvv$N.odot}}).
  When the didson is in the wrong position, numbers are estimated from
  densities of the same day (N = \num {\Sexpr{vvv$N.oplus}}). A model based on all days of
  monitoring was calibrated to estimate the numbers when the didson was not
  capable of providing a daily estimate of the migration
  (N = \num{\Sexpr{vvv$N.otimes}}).
  A quantitative estimation of downstream migration on the Vilaine, over the
  monitoring period is established at (N = \num {\Sexpr{vvv$N}}) or \Sexpr{vvv$total_weight} tonnes.
  The interannual trends of this migration are detailed in the
  report (decrease, then possible increase).
}

 Keywords: \textit{silver eel} \sep \textit{downtream migration}
     \sep \textit{didson} \sep \textit{Vilaine}.
  
\end{abstract}

%% Switch on the line numbers for the whole article at this place.
%\linenumbers

%% Here you can put your table of contents and also give it a new name.		
%\newpage

%\renewcommand{\contentsname}{Sommaire:}
\onecolumn
\tableofcontents
\twocolumn

\clearpage
%% Main text is going here.
\pagestyle{stylestandard}
\section*{Introduction}
\label{Introduction}
L'objectif à long
terme fixé par le  plan de restauration de l'anguille est la restauration de la
biomasse d'anguilles argentées à 40 \% du niveau sans impact anthropique. Pour évaluer l'atteinte des objectifs de
ce plan par les états membres, la commission européenne demande,
dans son règlement, de quantifier la biomasse d'anguilles
argentées \footnote{Les anguilles argentées sont les individus encore immatures
qui débutent leur migration vers la zone de reproduction dans la mer des
Sargasses depuis les eaux continentales. Elles descendent à partir de la
fin de l'été principalement sous l'effet des augmentations de débit.}.
Elle demande aussi de la comparer, soit à une valeur historique de biomasse d'anguilles produite par les bassins,
avant la chute des arrivées de civelles dans les années 1970, soit à une valeur
théorique de production basée sur les productivités en anguilles
des différents milieux aquatiques. Enfin, les états membres
doivent montrer que les mesures de gestion mises en place pour
restaurer le stock d'anguilles sont suffisantes. 
L'estimation de la biomasse d'anguilles argentées produite par les
bassins versants français est basée, pour la mise en place du règlement
anguille (2009) sur le modèle EDA \citep{jouanin_eel_2012,briand_eel_2015}. 
Ce dernier extrapole une estimation de l'abondance moyenne
d'anguilles à partir des données de pêches
électriques d'anguilles jaunes sur l'ensemble du territoire français.
Pour le rapportage les données de ce modèle sont complétées par un suivi sur des
bassins ateliers, les rivières index \citep{briand_index_2016}.

La Vilaine est l'un des fleuves intégré à ce réseau.
Un sonar multifaisceau didson a été placé  en 2012 sur une poutre HEB au droit
de la vanne 4 du barrage.
Ce dernier renvoit des images, interprétable comme des vidéos, sur un faisceau
d'une taille réduite (25m$^2$). La lecture des échos radar
a montré qu'il était possible de distinguer les
anguilles des autres poissons, dans des conditions de
débit qui interdisent en pratique d'utiliser des méthodes plus conventionnelles.
La gestion particulière du barrage d'Arzal qui évacue les crues au niveau de la
mer fait que les conditions de vitesses lors des crues ne sont pas extrêmes et
que la lecture des fichiers reste possible. 
En période de débit réduit, le didson placé en surface près du volet peut
observer une large portion de la section de migration, mais lorsque la vanne
s'ouvre, et que l'écoulement se fait sur une section plus large, voire sur
d'autres portes, la section relative observée par le didson devient plus
réduite. 
La distinction des anguilles dévalantes dépend également de leur taille et de
leur distance au didson. Depuis 2012, une méthode a été développée pour
permettre d'extrapoler les comptages d'anguilles observées au didson, à
l'ensemble du fleuve. Le rapport qui suit propose le recalcul de l'ensemble des
migrations depuis le début du suivi, et fait en particulière la synthèse des
résultats \Sexpr{saison}. Les résultats sont comparés aux résultats des saisons
2012--2013, 2013--2014, 2014--2015 2015--2016, 2016--2017, 2017--2018,
2018--2019 et 2019--2020)
\citep{briand_suivi_2014,briand_suivi_2015,briand_suivi_2016,briand_suivi_2017, briand_suivi_2018,briand_suivi_2019,
briand_suivi_2021}.
]
\section{Matériel et méthodes}



% METTRE EVAL TRUE / FALSE POUR CALCULER/ACCELERER 
<<sqldf, echo=FALSE, eval=FALSE,results=hide >>=
require("safer")
require("getPass")
if (!exists("userdistant") | !exists("passworddistant")) stop('Il faut configurer Rprofile.site avec les bons mots de passe et user')
if (!exists("mainpass")) pois <- getPass(msg="Main password") else pois <- mainpass
host <- decrypt_string(hostdistant,pois)
user <- decrypt_string(userdistant,pois)
password<- decrypt_string(passworddistant,pois)
options(sqldf.RPostgreSQL.user = user, 
		sqldf.RPostgreSQL.password = password,
		sqldf.RPostgreSQL.dbname ="didson",
		sqldf.RPostgreSQL.host =host,
		sqldf.RPostgreSQL.port ="5432" )
# test de la connection en interne ou en externe EPTB-Vilaine
t<-tryCatch(sqldf("select * from did.t_didsonfiles_dsf limit 1"),error=function(e) e)
is_simple_error <- function(x) inherits(x, "simpleError")
if (is_simple_error(t)) stop("didsant call using host failed, check connection to the database")
cat("depouillement\n")
depouillement = sqldf(str_c("with depouillement as (select dsf_timeinit,dsr_id,extract('month' from dsf_timeinit) as mois,dsr_reader, dsf_position, ",
				"dsr_readend-dsr_readinit as temps_lecture from did.t_didsonread_dsr join did.t_didsonfiles_dsf on dsf_id=dsr_dsf_id",
				" where dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,"')",
				" select mois,justify_hours(sum(temps_lecture)) from depouillement group by mois order by  mois"))
save(depouillement,file=str_c(datawdy,"depouillement.Rdata"))
sumdepouillement = sqldf(str_c("with depouillement as (select dsf_timeinit,dsr_id,extract('month' from dsf_timeinit) as mois,dsr_reader, dsf_position, 
						dsr_readend-dsr_readinit as temps_lecture from did.t_didsonread_dsr join did.t_didsonfiles_dsf on dsf_id=dsr_dsf_id
						where dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,
				"'--UNION
						-- select NULL,NULL,9,NULL,NULL,'41:45'::interval
						)
						select justify_hours(sum(temps_lecture)) from depouillement "))
save(sumdepouillement,file=str_c(datawdy,"sumdepouillement.Rdata"))
cat("d3edj\n") # ddde_dj dj=données journalières
d3edj <- sqldf(str_c("select * from did.v_dddedj where enj_date>'",toutdebut,
				"' and enj_date<'",datefin,"'"))
save(d3edj,file=str_c(datawdy,"d3edj.all.Rdata"))
#cat("vdlload\n")
#vdlload<-sqldf("SELECT v_didsonlectures.dsf_id_csot, v_didsonlectures.dsf_filename, v_didsonlectures.dsf_timeinit,
#				v_didsonlectures.dsf_position, v_didsonlectures.brice, v_didsonlectures.brice_et_gerard,
#				v_didsonlectures.gerard, v_didsonlectures.round_time, v_didsonlectures.debitvilaine30, 
#				v_didsonlectures.volbarrage30, v_didsonlectures.volet4, v_didsonlectures.vanne4, 
#				v_didsonlectures.volet5, v_didsonlectures.vanne5, v_didsonlectures.volet3, v_didsonlectures.vanne3, 
#				v_didsonlectures.volet2, v_didsonlectures.vanne2, v_didsonlectures.volet1, v_didsonlectures.vanne1, 
#				v_didsonlectures.hvanne4
#				FROM public.v_didsonlectures v_didsonlectures
#				ORDER BY v_didsonlectures.round_time")
#save(vdlload,file=str_c(datawdy,"vdlload.Rdata"))
cat("dddp\n")
dddp<-sqldf(str_c("select * from did.v_dddp 
						where dsf_timeinit>'",toutdebut,
				"' and dsf_timeinit<'",fin,
				"'")) # dsf_dsr_drr_psf


# xtabs(count~dsf_distancestart+dsf_incl+dsf_position,data=dddp)
dddp$mois<-strftime(dddp$dsf_timeinit,'%m')
dddp$mois<-factor(dddp$mois, levels=c("09","10","11","12","01","02","03","04"),	ordered =TRUE)
correct<-function(data,var,value,newvalue){
	data[data[,var]==value&!is.na(data[,var]),var]<-newvalue
	return(data)
}
dddp<-correct(dddp,"dsf_distancestart",2,2.08)
dddp<-correct(dddp,"dsf_distancestart",1.25,2.08)
dddp[dddp$psf_radius_m<=2,"psf_radius_m"]<-2.08 # pour éviter les pb ds cut... deux lignes
stopifnot(all(dddp$psf_radius_m>2))
save(dddp,file=str_c(datawdy,"dddp.all.Rdata"))
# ATTENTION si mise à jour lancer d3ejperiodes pour reconstituer les périodes !!!!
tps<-sqldf(str_c("select dsf_timeinit,dsr_id,extract('month' from dsf_timeinit) as mois,dsr_reader, dsf_position, 
						dsr_readend-dsr_readinit as temps_lecture from did.t_didsonread_dsr join did.t_didsonfiles_dsf on dsf_id=dsr_dsf_id
						where dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,
				"'"))
tps$temps_lecture<-as.numeric(as.difftime(tps$temps_lecture,units = "mins"))
# dd c'est juste didsonfiles et didsonread
dd<-sqldf(str_c("select * from did.t_didsonfiles_dsf  dsf 	
						join  did.t_didsonread_dsr dsr on dsr_dsf_id=dsf_id
						where dsr_csotismin and dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,
				"'")) # dsf_dsr_drr_psf
save(dd, file=str_c(datawdy,"dd.Rdata"))
save(tps, file=str_c(datawdy,"tps.Rdata"))
#données journalières
enj <- sqldf(str_c("select * from did.t_envjour_enj
						where enj_date>'",datedebut,
				"' and enj_date<'",datefin,"'"))
if(nrow(enj)==0) stop("Il faut faire tourner le script calcul_debit_chargement_cond_env.R pour charger les données environnementales")
save(enj,file=str_c(datawdy,"enj.Rdata"))
#plot(enj$enj_date,enj$enj_turb,type="l")
env <- sqldf(str_c("select * from did.t_env_env 
						where env_time>'",debut,
				"' and env_time<'",fin,"' order by env_time" ))

#plot(env$env_time,env$env_tempaval,ylim=c(0,25))
#points(env$env_time,env$env_tempamont,col="red")
#points(env$env_time,env$env_tempair,col="blue",cex=0.2)
# d3ej sera la selection de celui-ci pour le jour 
save(env,file=str_c(datawdy,"env.Rdata"))
ddde <- sqldf(str_c("select * from did.v_ddde
						where dsf_timeinit>'",toutdebut,
				"' and dsf_timeinit<'",fin,
				"'"))

ddde$count=1
# xtabs(count~dsf_distancestart+dsf_incl+dsf_position,data=ddde)
correct<-function(data,var,value,newvalue){
	data[data[,var]==value&!is.na(data[,var]),var]<-newvalue
	return(data)
}
ddde <- correct(ddde,"dsf_distancestart",2,2.08)
stopifnot(all(dddp$psf_radius_m>2))
ddde <- ddde[!is.na(ddde$dsf_id),]
ddde$date <- as.Date(ddde$dsf_timeinit,tz="Europe/Paris")
ddde <- ddde[!is.na(ddde$date),]
ddde$mois <- strftime(ddde$round_time,'%m')
ddde$mois <- factor(ddde$mois,levels=c("09","10","11","12","01","02","03","04"),ordered=TRUE)

# ci dessus génère des NA
save(ddde,file=str_c(datawdy,"ddde.all.Rdata"))
write.table(ddde,file=str_c(datawdy,"ddde.csv"),sep=";",row.names=FALSE)
#nbvilaine<-sqldf(
#		"select 0.05*sum(abondance) from rht.crosstab_rhtvs2 where id_drain in (select rht.upstream_segments(212340))",
#		dbname=getOption("eda2.0_RHT"),
#		host=getOption("sqldf.RPostgreSQL.hostname")) # 87546

#nbvilaine<-sqldf(
#	"select sum(surface) from rht.crosstab_rhtvs2 where id_drain in (select rht.upstream_segments(212340))
#		dbname=getOption("eda2.0_RHT"),
#		host=getOption("sqldf.RPostgreSQL.hostname")) # 31.16
nblpm=sqldf(str_c("select count(*), psf_dir from did.t_didsonfiles_dsf  dsf 	
						join  did.t_didsonread_dsr dsr on dsr_dsf_id=dsf_id
						join did.t_didsonreadresult_drr drr on 	drr_dsr_id=dsr_id
						join did.t_poissonfile_psf on psf_drr_id=drr_id
						where psf_species='2014'
						and dsr_csotismin
						and dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,
				"' group by psf_dir " ))

lpm<-sqldf(str_c("select * from did.t_didsonfiles_dsf  dsf 	
						join  did.t_didsonread_dsr dsr on dsr_dsf_id=dsf_id
						join did.t_didsonreadresult_drr drr on 	drr_dsr_id=dsr_id
						join did.t_poissonfile_psf on psf_drr_id=drr_id
						where psf_species='2014' 
						and dsr_csotismin 
						and dsf_timeinit>'",debut,
				"' and dsf_timeinit<'",fin,
				"'"))
lpm$date<-as.Date(lpm$dsf_timeinit,tz=Sys.timezone())
save(nblpm,lpm,file=str_c(datawdy,"lpm.Rdata"))
# FIN CHUNK sqldf
@
% METTRE EVAL TRUE / FALSE POUR CALCULER/ACCELERER 
<<d3ej, echo=FALSE, eval=FALSE,results=hide >>=
#CHUNK PRINCIPAL DE CALCUL
load(file = str_c(datawdy, "ddde.all.Rdata"))
load(file = str_c(datawdy, "dddp.all.Rdata"))

tapply(rowSums(ddde[, c("drr_eelplus", "drr_eelminus")],na.rm = TRUE), ddde$dsf_season, sum, na.rm=TRUE)  
# 2566      1990      1964   3810>3809    2020     1425       1739      1434
# nouveau calcul 202
# 2012-2013 2013-2014 2014-2015 2015-2016 2016-2017 2017-2018 2018-2019 2019-2020 
# 2617      1999      1937      3808      2020      1425      1736      1434 

nrow(dddp)  # 1734
hour <- as.numeric(strftime(ddde$round_time, format = "%H"))
stopifnot(length(which(duplicated(ddde$dsf_id))) == 0)
stopifnot(nrow(dddp) == sum(colSums(ddde[, c("drr_eelplus", "drr_eelminus")], na.rm = TRUE)))
# ddde[which(duplicated(ddde$dsf_id)),]
d3ej <- subset(ddde, (hour > 17 | hour <= 9) & !is.na(ddde$date))  # ddde de jour

# CALCUL DES DEBITS ------------------------------------------
d3ej$volbarrage30 <- rowSums(d3ej[, grep("env_volv", colnames(d3ej))])
# je recalcule le volume du barrage sur la base volets et vannes (mon calcul)
# on met pas na.rm exprès pour voir si il y a encore des pb
# dans certains cas e.g. 2013-11-08_00:30:00  je n'ai pas de calcul de débits sur les volets (tous les env_vol_volet sont NA)
# d3ej[d3ej$date=="2013-11-08",] OK pb règlé
# View(d3ej[is.na(d3ej$volbarrage30),])
# entre le 09-10-2012 et le 14-10-2012 il y a des valeurs manquantes ?
d3ej$env_volvanne4_30[is.na(d3ej$env_volvanne4_30)]<-0
d3ej$env_volvolet1_30[is.na(d3ej$env_volvolet1_30)]<-0
d3ej$env_volvolet2_30[is.na(d3ej$env_volvolet2_30)]<-0
d3ej$env_volvolet3_30[is.na(d3ej$env_volvolet3_30)]<-0
d3ej$env_volvolet4_30[is.na(d3ej$env_volvolet4_30)]<-0
d3ej$env_volvolet5_30[is.na(d3ej$env_volvolet5_30)]<-0
d3ej$volbarrage30 <- rowSums(d3ej[, grep("env_volv", colnames(d3ej))])
stopifnot(!all(is.na(d3ej$volbarrage30))) # il ne faut plus de valeurs manquantes
d3ej$pvanne4 <- d3ej$env_volvanne4_30/ d3ej$volbarrage30
# debit de la vanne 4 sur l'ensemble des écoulements
# je mets NA rm car si env
d3ej$pvanne4[d3ej$env_volvanne4_30 == 0] <- 0
stopifnot(sum(is.na(d3ej$pvanne4))==0)
d3ej$pvolet4 <-  d3ej$env_volvolet4_30/d3ej$volbarrage30
d3ej$pvolet4[d3ej$env_volvolet4_30==0] <- 0  
stopifnot(sum(is.na(d3ej$pvolet4))==0)
d3ej$vol4 <- d3ej$env_volvolet4_30 + d3ej$env_volvanne4_30
d3ej$pvol4 <- d3ej$vol4/d3ej$volbarrage30
d3ej$pvol4[d3ej$vol4==0] <- 0
stopifnot(sum(is.na(d3ej$pvol4))==0)
#d3ej$pvol4[is.na(d3ej$pvol4)] <- 0 il peut arriver que je n'ai pas de débits.... je dois propager ces problèmes
d3ej$env_Qtotal30 <- d3ej$volbarrage30/1800

# CALCUL DU FONCTIONNEMENT DE LA VANNE 4  -------------------------------------
# sur une période de 30 minutes il peut y avoir du fonctionnement au fond et en surface
d3ej$optvanne4 <- NA
suppressWarnings(d3ej$optvanne4 <- str_c(as.character(d3ej$vanne4), "-", as.character(d3ej$volet4)))  # le tiret n'est pas répété on veut pas d'erreur pour autant
d3ej$optvanne4 <- as.factor(d3ej$optvanne4)
stopifnot(length(unique(d3ej$optvanne4))==4)
levels(d3ej$optvanne4) <- c("0", "s", "f", "sf") # replace "FALSE-FALSE" "FALSE-TRUE"  "TRUE-FALSE"  "TRUE-TRUE"  

# RECODAGE DU POSITIONNEMENT DU didson
d3ej$dsf_position[d3ej$dsf_position == "vanne"] <- "f"
d3ej$dsf_position[d3ej$dsf_position == "volet"] <- "s"
d3ej$dsf_position[is.na(d3ej$dsf_position)] <- "n"  # le didson est enlevé durant cette période
# plus loin évite les problèmes de réindexation, on utilise ça pour retirer les
# périodes pour lesquelles la fonction drawdi calcule les surfaces, mettre un NA
# ici conduit à faire planter le calcul de cette fonction donc on garde 'n', et
# on enlève les valeurs calculées ensuite.
d3ej$dsf_distancestart[is.na(d3ej$dsf_distancestart)] <- 0
d3ej$dsf_incl[is.na(d3ej$dsf_incl)] <- 0
d3ej$dsf_position <- as.factor(d3ej$dsf_position)


# Surface T
d3ej[d3ej$dsf_position == "s" & d3ej$dsf_incl <= 10 & d3ej$dsf_incl >= -10, "position"] <- "s"
# penché
d3ej[d3ej$dsf_incl > 10 | d3ej$dsf_incl < -10, "position"] <- "sl"
# FOND 5 m Tous ces enregistrements commencent à la distance de 5 m
d3ej[d3ej$dsf_position == "f" & d3ej$dsf_distancestart >= 5, "position"] <- "f5"
# FOND 3.75
d3ej[d3ej$dsf_position == "f" & d3ej$dsf_distancestart < 5, "position"] <- "f3"
# pas de didson dans l'eau
d3ej[d3ej$dsf_position == "n", "position"] <- "n"

#d3ej[is.na(d3ej$position),c("dsf_season","dsf_incl","dsf_position","dsf_distancestart")]
if (any(is.na(d3ej$position))) stop("position should no be NA")
#calcul pour tous

# Conditions d'extrapolation (ex) -----------------------------------------

# ex = extrapolation calculés dans l'ordre, le premier surpasse le dernier
# par exemple si la vanne est fermée, le statut sera toujours 0 même si pb technique
#  0 Vanne ou volet fermés, quelles que soient les autres conditions d3ej$optvanne4=="0" la vanne est fermée
#  4 => Vanne ouverte, problème de lecture ou d'écriture la position est "n" = pas de didson ou  fls (1,2) pb d'aquisition ou d'écriture
#  2 => Pas de lecture (tous les is.na(dsr_id)), écoulement sur la vanne 4,  pas de problème d'acquisition ou d'écriture
#  1 => Lecture , vanne ou volet ouvert, didson bien positionné, pas de problème d'acquisition ou d'écriture
# fond fond +  périodes de trantions (d3ej$optvanne4="fs")
# surface surface + périodes de transition
# didson penché loin du didson : vanne et didson sl en surface regarde en bas, volet et didson au fond sl regarde en haut
#  3 => Lecture en mauvaise position, écoulement sur la vanne 4,  pas de problème d'acquisition ou d'écriture 


d3ej$ex <- NA #extrapolation
# Fonctionnement OK
d3ej$dsf_incl[d3ej$dsf_incl==0] <- 0.5 # sinon plante
d3ej$ex[d3ej$optvanne4%in%c("s","sf")&d3ej$dsf_position=="s"| # surface surface
				d3ej$optvanne4%in%c("s","sf")&d3ej$dsf_position=="f"&d3ej$dsf_incl>300&d3ej$position=="sl"| # surface et didson au fond regarde en haut
				d3ej$optvanne4%in%c("f","sf")&d3ej$dsf_position=="f"| # fond et fond 
				d3ej$optvanne4%in%c("f","sf")&d3ej$dsf_position=="s"&d3ej$position=="sl"&d3ej$dsf_incl<0]<-1 # fond et didson en surface regarde en bas
d3ej$ex[d3ej$optvanne4%in%c("s")&d3ej$dsf_position=="f"&d3ej$position!="sl"|
				d3ej$optvanne4%in%c("f")&d3ej$dsf_position=="s"&d3ej$position!="sl"] <- 3
d3ej$ex[is.na(d3ej$dsr_id)] <- 2
d3ej$ex[d3ej$position=="n"] <- 4 # le 2 est effacé par les pb techniques
d3ej$ex[d3ej$dsf_fls_id%in%c(1,2)] <- 4
d3ej$ex[d3ej$optvanne4=="0"] <- 0

d3ej_perc_pos <- 
		inner_join(
				d3ej %>% group_by(dsf_season, ex)%>%summarize(Nex=n()),
				d3ej %>% group_by(dsf_season)%>%summarize(N=n())
		) %>% 
		mutate(perc = Nex/N)

d3ej$lecture <- !is.na(d3ej$dsr_id)
# pour verif d3ej[is.na(d3ej$ex),c("dsf_position","dsf_incl","optvanne4")]
save(d3ej_perc_pos, file=str_c(datawdy,"d3ej_perc_pos.Rdata"))

#CALCULS DE RATIO DE SURFACE ----------------------------


volet <- d3ej$dsf_position=="s"&d3ej$volet4 #1167 #sum(volet,na.rm=TRUE)
vanne <- d3ej$dsf_position=="f"&d3ej$vanne4 #1374 # sum(vanne,na.rm=TRUE)
#plot(d3ej$dsf_position,as.factor(d3ej$vanne4))
vanne_et_penche <- d3ej$dsf_position=="s" & d3ej$position=="sl" & d3ej$dsf_incl<0&d3ej$vanne4 
volet_et_penche <- d3ej$dsf_position=="f" & d3ej$position=="sl" & d3ej$dsf_incl>10&d3ej$volet4 
vanne[vanne_et_penche]<-TRUE
volet[volet_et_penche]<-TRUE
hpas <- rep(NA,nrow(d3ej))
d3ej$chargevolet <- d3ej$niveauvilaine30-1.38
# La hauteur de passage (pas l'altitude...) est au moins égale à une hauteur de 2m
# mais correspond sinon à 6 * la charge des volets sauf si 6 * la charge des volets dépasse le fond
# auquel cas ça devient l'ensemble de la colonne d'eau
hpas[volet] <- pmax(2,d3ej$niveauvilaine30[volet]-pmax(-7.72,d3ej$niveauvilaine30[volet]-PARM[2]*d3ej$chargevolet[volet]))
# La hauteur de passage sur la Vanne correspond à l'ensemble de la hauteur d'eau moins 2 m en surface
hpas[vanne] <- d3ej$niveauvilaine30[vanne]+7.72-PARM[3]  
d3ej$hpas <- hpas


# petit arrondi pour valeurs de 4.58 au lieu de 5

d3ej$dsf_distancestart[d3ej$dsf_distancestart==4.58] <-5

# calcul des polygones en fonction de la distance de départ du didson

divide=matrix(NA,nrow=nrow(d3ej),ncol=5)
divide[d3ej$dsf_distancestart<5,1:4] <- cbind(
		(5-d3ej$dsf_distancestart)[d3ej$dsf_distancestart<5], 
		2,2,2)
divide[d3ej$dsf_distancestart<5,5] <- 10-rowSums(divide[d3ej$dsf_distancestart<5,],na.rm=TRUE)
divide[d3ej$dsf_distancestart==5,] <- rep(2,5)
divide <- split(divide, c(row(divide))) # coercing to list

#----------------------------------------------------------------------
# Dans le script de l'année précédente il y avait un seuil
# pour lequel je condidérais qu'il n'y avait plus de détection
# là  je ne prends en compte que l'efficacité donc je remets distancestart+ 10
#------------------------------------------------------------------------
#date_seuil_pb_lentille <- dmy(13122018)
system.time(d <- mapply(drawdi,
				fond=-7.72,
				profdid=d3ej$dsf_depth,
				alphadegres=14,
				dist=NA,		
				betadegres=d3ej$dsf_incl,
				d1=d3ej$dsf_distancestart,
				d2=  d3ej$dsf_distancestart+10,   
				hpas=hpas,
				hvan=0, # on s'en fout
				graph=FALSE,
				divide=divide,
				volet=volet,
				#vectdist=c(2,5,7,9,11),
				chargevolet=d3ej$chargevolet, SIMPLIFY =FALSE))
# ATTENTION IL PEUT Y AVOIR UN PB AVEC INTERSECT SI LA METHODE EST CHARGEE PAR UN AUTRE PACKAGE
save(d,file=str_c(datawdy,"d.Rdata")) # load(file=str_c(datawdy,"d.Rdata"))
d3ej$area_intersect<-unlist(lapply(d,function(X) X$area_intersect))

# d3ej %>% filter(area_intersect>0 & area_intersect<max(d3ej$area_intersect,na.rm=TRUE))%>%
#		 ggplot() + geom_density(aes(x=area_intersect, fill=dsf_season), alpha=0.6)+
#		 facet_wrap(~position)


d3ej$area_intersect[d3ej$dsf_position == "n"] <- NA
# Pour ne pas extrapoler débilement sur de toutes petites surfaces
d3ej$area_intersect <- pmax(d3ej$area_intersect,10, na.rm=TRUE)


d3ej$area_detframe <- unlist(lapply(d, function(X) sum(X$det_frames_int_area)))
d3ej$area_detframe[d3ej$dsf_position == "n"] <- NA
d3ej$area_migration_frame <- unlist(lapply(d, function(X) sum(X$area_migration_frame)))
d3ej$area_migration_frame[d3ej$dsf_position == "n"] <- NA
d3ej[d3ej$vanne4, "area_migration_frame"] <- (d3ej$niveauvilaine30[d3ej$vanne4] + 
			7.72 - PARM[3]) * 18
d3ej$psurface <- d3ej$area_intersect/d3ej[, "area_migration_frame"]
d3ej$psurface[d3ej$psurface == 0] <- NA  # pour ne pas diviser par zéro

# plot(d3ej$psurface) # entre 0 et 0.5 OK
# ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=psurface,col=position))
# ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=area_migration_frame,col=position))
# ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=area_migration_frame,col=factor(dsf_fls_id)))
# plot(d3ej$area_migration_frame)

save(d3ej,file=str_c(datawdy,"d3ej.all.Rdata"))
rm(hpas,vanne,volet)
@
% METTRE EVAL TRUE / FALSE POUR CALCULER/ACCELERER 
<<d3ejperiodes, echo=FALSE, eval=FALSE, results=hide >>=
###########################################
# FONCTION UTILISANT DES CRITERES DE CHOIX POUR TRACER LE GRAPHIQUE
# ET GARDER DANS VVV UN RESUME DE LA PERIODE DE PASSAGE
############################################
d3ejs <- d3ej[d3ej$dsf_timeinit>=debut & d3ej$dsf_timeinit<=fin,]
res <- d3ejs %>% 
		group_by(dsf_incl,	dsf_depth,optvanne4) %>% 
		summarize(start=min(dsf_timeinit, na.rm=TRUE), end=max(dsf_timeinit, na.rm=TRUE), nbperiode=n()) %>% 
		filter (!is.na(dsf_depth) & optvanne4!="sf", nbperiode>10) %>%
		arrange(start)	
print(res, n=Inf,width=Inf)
ppp<-list()
#print= "sortieecran" # pour ne pas voir les graphes, peut importe ce qui est écrit ici
print="png"

for (j in 1:nrow(res)){
	ppp<-drawdicriter(profdid=res$dsf_depth[j], 
			incl=res$dsf_incl[j], 
			Phi=res$optvanne4[j],
			distancestart=NA,
			timestamp=c(res$start[j],res$end[j]),
			nomperiode=str_c("periode",j,
					"_phi",res$optvanne4[j],
					"_did", ifelse(res$dsf_depth[j]>-1,"s","f"),"_",
					res$dsf_incl[j]),
			print=print,
			couleur=c(makeTransparent(jaune_EV,90),"#00FF664D", makeTransparent(bleu_EV,70),makeTransparent(turquoise_EV,90),
					makeTransparent(orange_EV, 90))) 
}
# les periodes sont écrites par la fonction dans dddp$periode, 
# sur la nouvelle version dddp contient toutes les années, mais les données mises à jour sont écrites sur l'année en cours
# je les écris en base dans t_didsonfiles.dsf_periode 

#TODO 2021 RUNONCE (commenté pour ne pas écrire en base)
#xxxx<- dddp[!is.na(dddp$periode),c("dsf_id","periode")]
#sqldf("UPDATE did.t_didsonfiles_dsf set dsf_periode = periode FROM xxxx where xxxx.dsf_id = t_didsonfiles_dsf.dsf_id ")



save(ppp,file=str_c(datawdy,"ppp.Rdata"))
save(dddp,file=str_c(datawdy,"dddp.Rdata"))
@



<<didson, echo=FALSE, eval=FALSE, results=hide >>=
# CHUNK POUR CREER LES GRAPHES DE POSITIONS
#vannefond
pdf(file=str_c(imgwdy,"didsonA.pdf"),width=8,height=6)
listdidson<-list("didsonA"=drawdi(fond=-7.72, profdid=1, alphadegres=14, dist=NA, betadegres=-7,
				d1=5, d2=15,
				chargevolet=1.8, hpas=7.72+1.8, hvan=0, graph=TRUE, divide=2))
dev.off()
#vannedroit
pdf(file=str_c(imgwdy,"didsonD1.pdf"),width=8,height=6)
listdidson$didsonD1=drawdi(fond=-7.72,profdid=-5.5,alphadegres=14,dist=NA,
		betadegres=0.5,d1=5,d2=15,hpas=7.72+1.6,hvan=1.5,print=TRUE,graph=TRUE,divide=2)
dev.off()
pdf(file=str_c(imgwdy,"didsonD2.pdf"),width=8,height=6)
listdidson$didsonC2=drawdi(fond=-7.72,profdid=-4.5,alphadegres=14,dist=NA,betadegres=-7,
		d1=5,d2=15,hpas=7.72+1.6,hvan=1.5,print=TRUE,graph=TRUE,divide=2)
dev.off()

vvv$listdidson<-listdidson
save(vvv,file=str_c(datawdy,"vvv.Rdata"))
@

<<didson2, echo=FALSE, eval=FALSE,results=hide >>=
# Les mêmes mais sans limitation de la taille de la fenêtre pour le ratio des surfaces
volet<-drawdi(fond=-7.72,profdid=1.15,alphadegres=14,dist=NA,betadegres=-7,d1=5,d2=15,hvan=0,hpas=5,print=FALSE,graph=FALSE,divide=2,volet=TRUE)
f3<-drawdi(fond=-7.72,profdid=-6.00,alphadegres=14,dist=NA,betadegres=0,d1=2,d2=12, hpas=3,hvan=3,graph=TRUE,divide=c(3,2,2,2,2)) # ici on passe l'angle
f5<-drawdi(fond=-7.72,profdid=-6.92,alphadegres=14,dist=NA,betadegres=6,d1=5,d2=15,hpas=5,hvan=3,print=FALSE,graph=TRUE,divide=2)
vvv$volet<-volet
vvv$f5<-f5
vvv$f3<-f3
save(vvv,file=str_c(datawdy,"vvv.Rdata"))

@

<<loadrdata, echo=FALSE, eval=TRUE,results=hide >>=
load(file=str_c(datawdy, "depouillement.Rdata"))
load(file=str_c(datawdy, "sumdepouillement.Rdata"))
load(file=str_c(datawdy, "d3edj.all.Rdata")) # d3edj
#load(file=str_c(datawdy,"vdlload.Rdata")
load(file=str_c(datawdy, "dddp.all.Rdata")) # dddp
load(file=str_c(datawdy, "ddde.all.Rdata")) # ddde
load(file=str_c(datawdy, "tps.Rdata"))
load(file=str_c(datawdy, "dd.Rdata"))
load(file=str_c(datawdy, "enj.Rdata"))
load(file=str_c(datawdy, "d3ej.all.Rdata")) #d3ej produced by chunk d3ej
load(file=str_c(datawdy, "d3ej_perc_pos.Rdata"))
load(file=str_c(datawdy, "lpm.Rdata"))
load(file=str_c(datawdy, "ppp.Rdata"))

#require(Hmisc)
#describe(dddp)
correct<-function(data,var,value,newvalue){
	data[data[,var]==value&!is.na(data[,var]),var]<-newvalue
	return(data)
}
dddp <- correct(dddp,"dsf_distancestart",2,2.08)
ddde <- correct(ddde,"dsf_distancestart",2,2.08)
ddde <- ddde[!is.na(ddde$dsr_id),]
ddde$hour <- as.numeric(strftime(ddde$round_time,format="%H"))
lpm$count <- 1
horaires <- function(data){
	data$Hdeb<-as.numeric(strftime(data$dsf_timeinit,"%H"))+as.numeric(strftime(data$dsf_timeinit,"%M"))/60
	data$Hfin<-as.numeric(strftime(data$dsf_timeend,"%H"))+round(as.numeric(strftime(data$dsf_timeend,"%M"))/60,2)
	data$Hfin[data$Hfin==0]<-24
	indx<-data$Hfin==24&data$Hdeb==0
	data[indx,"Hfin"]<-24.0
	data[indx,"Hdeb"]<-23.5
	data$xmin<-as.POSIXct(strptime(str_c(as.character(data$date)," 09:00"),"%Y-%m-%d %H:%M")) # pour les graphiques en rectangle
	data$xmax<-as.POSIXct(strptime(str_c(as.character(data$date)," 17:00"),"%Y-%m-%d %H:%M"))
	return(data)
}
ddde <- horaires(ddde)
d3ej <- horaires(d3ej)
# changement 2019 17 h à 16h
fulldays <- unique(ddde[ddde$Hdeb >= 10 & ddde$Hdeb <= 16, "date"])  # jours complets
# voir http://www.leshorairesdusoleil.com/ical.aspx
# préparer un fichier csv pour l'année en cours en extrayant les bonnes dates, et en collant deux années.
# j'ai déjà copié 2022 et 2023 ds data/2022+, renommer les fichiers en lever_soleil.csv en lever_coucher.csv
# ci dessous deux formats historiques différents que je compile en un seul ficher
#https://www.sunrise-and-sunset.com/fr/sun/france/nantes/2020/decembre
for (Y in 2013:2014){
	eph <- killfactor(read.table(str_c(datawd,Y, "/lever_coucher.csv"), header = TRUE, 
					sep = ";"))  #ephéméride	
	eph$lever_soleil <- strptime(paste(eph$date,eph$lever_soleil), format = "%d/%m/%Y %H:%M")
	eph$coucher_soleil <- strptime(paste(eph$date,eph$coucher_soleil), format = "%d/%m/%Y %H:%M")
	eph$lever_soleil_h <- as.numeric(strftime(eph$lever_soleil, "%H")) + as.numeric(strftime(eph$lever_soleil, 
					"%M"))/60
	eph$coucher_soleil_h <- as.numeric(strftime(eph$coucher_soleil, "%H")) + as.numeric(strftime(eph$coucher_soleil, 
					"%M"))/60
	eph$date <- as.Date(eph$lever_soleil)
	if (Y==2013){
		ephall1 <- eph
	} else {
		ephall1 <- rbind(ephall1,eph)
	}	
}
for (Y in 2015:CY){
	eph <- killfactor(read.table(str_c(datawd,Y, "/lever_coucher.csv"), header = TRUE, 
					sep = ";"))  #ephéméride
	eph$lever_soleil <- strptime(eph$lever, format = "%d/%m/%Y %H:%M")
	eph$coucher_soleil <- strptime(eph$coucher, format = "%d/%m/%Y %H:%M")
	eph$lever_soleil_h <- as.numeric(strftime(eph$lever_soleil, "%H")) + as.numeric(strftime(eph$lever_soleil, 
					"%M"))/60
	eph$coucher_soleil_h <- as.numeric(strftime(eph$coucher_soleil, "%H")) + as.numeric(strftime(eph$coucher_soleil, 
					"%M"))/60
	eph$date <- as.Date(eph$lever_soleil, tz = Sys.timezone())
	if (Y==2015){
		ephall2 <- eph
	} else {
		ephall2 <- rbind(ephall2,eph)
	}	
}
ephall2 <- ephall2[,colnames(ephall1)]
eph <- rbind(ephall1, ephall2)
# eph$date<-as.POSIXct(eph$date)
#eph <- eph[eph$date >= min(ddde$date), ]
#eph <- eph[eph$date <= max(ddde$date), ]
# Cette année je fais un traitement particulier des efficacités donc le fsl_id = 3 
# est inclus dans les périodes de fonctionnement
indexOK <- (d3ej$dsf_fls_id == 0 | d3ej$dsf_fls_id == 3) & d3ej$ex == 1    # effectifs utilisés pour extrapolation plus loin
indexOK[is.na(indexOK)] <- FALSE
d3ej$indexOK <- indexOK
dsfindexOK <- unique(d3ej[indexOK, "dsf_id"])
indexOKex3 <- d3ej$dsf_fls_id == 0 & d3ej$ex == 3  # le didson est mal positionné
dsfindexOKex3 <- unique(d3ej[indexOKex3, "dsf_id"])
# summary(d3ej[d3ej$periode=='A','hvanne4'])

@



\subsection{Description du site}
Le barrage d'Arzal-Camoël est construit à 10 kilomètres de l'embouchure de la
Vilaine. Il a été édifié entre 1965 et 1970 et est constitué d'un pertuis
central de 160 mètres comprenant 5 vannes, d'une écluse et d'une digue en terre
de 360 mètres.
Ce barrage constitue une rupture nette entre le milieu estuarien et le plan d'eau douce artificiellement créé 
à l'amont (Figure \ref{vueaeriennebarrage}).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{vueaeriennebarrage.png}
\caption[Vue aérienne du barrage d'Arzal]{Vue aérienne du barrage d'Arzal,
montrant en rive droite l'écluse et le pertuis des vannes.}
\label{vueaeriennebarrage}
\end{figure}

Le sonar multifaisceaux est positionné 15 m en amont de la
vanne 4 (Figure \ref{arzal_aval}), dans l'échancrure de batardage de
la vanne.  La structure porteuse de l'appareil est une poutre HEB 240 de 12m, sa fixation permet de maintenir le didson à l'abri des corps
dérivants (Figure \ref{positionnementdidson}).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2017/arzal_aval}
\caption[Vue aval du volet]{Vue montrant un écoulement sur le volet 4 à
partir de l'aval du barrage.}
\label{arzal_aval}
\end{figure}


\begin{figure}[hbp]
\centering
\includegraphics[width=0.5\textwidth]{positionnementdidson.png}
\caption[Positionnement du didson]{Positionnement du didson dans l'échancrure
de batardage de la vanne. Le didson est placé à l'abri des corps dérivants.}
\label{positionnementdidson}
\end{figure}








\subsection{Description du matériel}

Le système d'enregistrement est composé d'un sonar multifaisceaux (didson de
Soundmetrics) équipé par un rotateur (Soundmetrics, X2) permettant de guider le
didson dans un positionnement vertical et latéral (Figure
\ref{didson2017}). Le chariot du didson permet de le positionner à différentes
profondeurs dans la colonne d'eau (Figure
\ref{chariot}). Les images sont traitées à l'aide du logiciel de dépouillement
didson V5.27.48 de la société Soundmetrics. 



\begin{figure}[htbp]
\centering
\includegraphics[width=0.3\textwidth]{2022/didson.png}
\caption[Le didson en 2017]{Le didson en 2017.
}
\label{didson2017}
\end{figure}


\begin{figure}[htbp]
\centering
\includegraphics[width=0.3\textwidth]{chariot}
\caption[Chariot du didson]{Chariot du didson.}
\label{chariot}
\end{figure}

\subsection{Automatisation de la position verticale du didson}

La position verticale du didson est automatisée par un treuil. 
Le treuil est relié à l'automate du barrage par une liaison
ethernet et le pilotage des positionnements du didson se fait par une
interface graphique (Figures \ref{automate2} et \ref{ihm}).
Un système de gestion
des câbles permet le déplacement vertical du didson à l'aide un chariot (Figure
\ref{automate3}).

%------------------------------------------
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/automate2.png}
\caption[automatisation]{A Armoire électrique de commande du treuil,
déportée sur la pile, B treuil avec codeur incrémental, C chariot de levage et
de positionnement du didson (pour la sécurité). }
\label{automate2}
\end{figure}
%------------------------------------------
%------------------------------------------
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/automate3.png}
\caption[automatisation]{Automatisation de la position verticale du didson. 1
chariot sur poutre HEB, 2 rail, 3 coffret électrique comprenant les éléments de
contrôle de l'automate, 4 câble du didson (alimentation et signal) renforcé par une gaine, 5 guide
câble, 6 câble de traction du didson, 7 poutre HEB du chariot de didson
(plongeant en amont de la vanne), 8 treuil et chaise de protection, 9 poulie, 10 contrepoids assurant la
tension du câble. }
\label{automate3}
\end{figure}
%------------------------------------------
%------------------------------------------
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/ihm2.png}
\caption[automatisation]{Ecrans de contrôle et de programmation de la position
du didson}
\label{ihm}
\end{figure}
%------------------------------------------
\subsection{Suivi des migrations}

Lors de l'hiver 2012--2013, le didson avait été placé dans trois types de
positions. En position haute lorsque les écoulements étaient en
surface (Figure \ref{didsonsurface}). Lorsque l'écoulement s'effectuait
par le fond, en période de plus fort débit, il a été placé en position basse, à
80 cm du fond. Il a alors été programmé afin d'échantillonner alternativement
une zone où une partie de l'écho se reflétait sur le fond, et une zone en pleine
eau.\\

En 2013--2014, la stratégie d'échantillonnage a été revue : l'analyse des
données 2012--2013 montre que l'écho sur le fond a pu générer une perte
d'efficacité du didson dans la zone d'écho. L'enregistrement près du fond a continué à être
effectué à -6.92 m (80 cm du fond) mais les angles du didson ont été réglés à 4
et 6 ° pour que la zone d'acquisition reste en pleine eau. En surface,
l'acquisition a été faite à angle constant \ang{-7} afin que la
zone d'acquisition du didson reste sous la surface, pour éviter que les reflets à la surface de l'eau ne gênent la lecture (Figure
\ref{echo}).
Des essais ont également été effectués en surface, et au fond, en alternant
les directions du didson entre un angle élevé et une position droite,
pour tenter de collecter des informations sur 
la position verticale des anguilles en fonction
des ouvertures de la vanne.  \\

En 2014--2015, la gestion du positionnement du didson a été fortement dépendante
de la gestion de crise du barrage du fait des avaries répétées des vannes. Le
rotateur a été cassé lors de la principale crue, alors que la majeure partie du
débit a été évacuée sur la vanne 4.

En 2015--2016, le rotateur n'a été remplacé qu'au 4 janvier. Le didson a
fonctionné avec un angle constant pour le début de la saison. Il a été placé
alternativement en surface et au fond en fonction des débits du barrage. 
Du 4 janvier au 26 avril, la saison a été constituée d'une
succession de pics de crue d'ampleur moyenne, pendant lesquels le didson
a enregistré au fond. 

En 2016--2017, le didson a été bien positionné pour enregistrer les deux
premiers pics de crue. À partir du 13/02, le signal a été détérioré par une
atttaque de corrosion. Jusqu'au 17/03, malgré plusieurs essais de remise en
fonctionnement, il n'y a pas vraiment de suivi. En fin de saison, le didson a
été placé en volets puis en vannes mais les effectifs observés sont restés
faibles.

En 2017--2018, un problème de déformation du concentrateur de faisceau (slit) a dégradé
la qualité des images à partir de fin janvier.

En 2018--2019 l'essentiel de la saison est couvert par le mode "suivi
vanne volet" qui permet de positionner correctement le didson en cours de
nuit lorsque la gestion du barrage alterne entre vannes en volets. 

En 2019--2020, la saison s'effectue avec un suivi principalement en vannes dès
le début de la saison. Le suivi a été arrêté le 19/02 après que le câble ait
été entaillé par un objet dérivant qui a mis fin au suivi (Figure
\ref{fig_effectif}). Cette situation intervient cependant après plusieurs pics
de crue et il est probable que l'essentiel de la migration ait eu lieu.

En 2020--2021 le didson est remis en place le 02/10 après répartion du câble.
Jusqu'au 12/12 une succession de problèmes techniques sont réglés, plantage lié
à l'humidité, arrêts électriques à répétition sur l'ouvrage, plantage de la
mémoire vive du PC d'acquisition, problème de codeur et de fin de course sur le
volet, difficultés à mettre en service l'automatisme de suivi vanne volets...
Les arrêt de fin novembre correspondent de nouveau à des coupures électriques du barrage. 
Le didson fonctionne globalement plutôt bien sur le reste de la saison. Il est
enlevé de l'eau lors du deuxième pic de crue le 03/02, les effectifs observés
sont faibles (et il ne s'agit pas d'un problème d'efficacité) et les risques d'avarie
sont importants. Il ne sera remis en place que le 01/03 un peu après la fin de
la crue. Dans tous les cas sur les derniers jours de février, une pièce
défectueuses sur la centrale 4 empêche le fonctionnement en vannes, et les
écoulement sur le pertuis 4 s'effectuent en volets alors que les deux vannes
alentour, 3 et 5 fonctionnent en vannes. Les dépouillements s'arrêtent le 30/04.

En 2021--2022 TODO

%------------------------------------------
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/didsonA}
\caption[schéma didson -7° 5-15m]{Schéma montrant la position du didson et
la fenêtre d'échantillonnage couverte par l'appareil lorsque celui-ci est placé
1 m sous la surface (-7°) pour détecter les anguilles migrant sur le volet.
Les polygones de couleur représentent les différentes sections
d'échantillonnage en fonction de la distance.
}
\label{didsonsurface}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/didsonD1}
\caption[schéma didson 0° 5-15m]{Fond 0° 5-15m, didson placé à 5.5 m de
profondeur lorsqu'il alterne entre des positions au fond et en surface à l 'aide
du positionnement géré par l'automate. Le didson échantillonne 
\num[round-mode=places,round-precision=1]{\Sexpr{round(100*vvv$listdidson$didsonD1$area_intersect/vvv$listdidson$didsonD1$area_migration_frame,1)}}\%
de la fenêtre de passage supposée. 
}
\label{didsonD1}
\end{figure}
\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2019/didsonD2}
\caption[schéma didson -7° 5-15m]{Fond -7° 5-15m, Didson placé à 4.5 m de
profondeur avec un angle de -7°. Par rapport à la position en
Figure \ref{didsonD1} le didson est remonté. L'angle de -7° permet d'éviter les
échos sur la surface lorsque le didson est remonté en position haute par l'automate. Le didson
échantillonne
(\num[round-mode=places,round-precision=1]{\Sexpr{round(100*vvv$listdidson$didsonC2$area_intersect/vvv$listdidson$didsonC2$area_migration_frame,1)}}\%
de la fenêtre de passage supposée).
}
\label{didsonD2}
\end{figure}

 
\subsection{Mesure des conditions environnementales}

Les paramètres décrivant le fonctionnement du barrage sont enregistrés toutes
les dix minutes dans la base de données SIVA \footnote{SIVA=Système
d'Information de la Vilaine et de ses Affluents}. Il s'agit :
\begin{enumerate}
\item Des niveaux d'ouverture des 5 vannes. 
\item De la position des volets, 5 clapets flottants par lesquels sont évacués
les débits du barrage lorsque le débit est suffisamment faible (entre 10 et 50 $m3^.s^-1$).
\item Des débits transitant par la
passe à poissons. 
\item Des débits des siphons \footnote{Les siphons sont des tuyaux dont le
fonctionnement gravitaire permet d'évacuer les lentilles d'eau salée
s'accumulant en profondeur en amont du barrage, du fait du fonctionnement
estival de l'écluse. Les siphons débouchent près de l'entrée de la passe en
rive gauche de l'ouvrage.}. 
\item Du débit de la Vilaine, calculé au niveau
du pont de Cran, 30 kilomètres en amont du barrage d'Arzal.
\item Des températures d'eau enregistrées au niveau de sondes en amont
et en aval du barrage.
\item Des niveaux d'eau enregistrés en amont et en aval du barrage sur plusieurs
sondes.
\end{enumerate}
Les données ont été collectées à partir de la base de données 
 et compilées par
séquences de 30 minutes dans un format compatible avec celui du didson.

D'autres données, au format journalier, comme les horaires de levers et couchers
du soleil, ont été ajoutées à cette base. Les durées de pénombre civile correspondant à une position
du soleil entre 0° et -6° ont été estimées à partir d'une durée de 24 minutes avant le lever 
et après le coucher du soleil.
\subsection{Calcul des débits}
Les débits ont été re-calculés au droit du barrage d'Arzal car les formules de
débit utilisées étaient fausses, particulièrement en période de forts débits, où
les formules de débit en écoulement libres conduisaient à sous-estimer les
débits. Les formules ont été recalculées à partir des débits de la station du
pont de Cran 30 km en amont du barrage. Les nouveaux débits sont donnés pour les volets et pour les vannes
avec la prise en compte de plusieurs formules en fonction des
conditions d'écoulement (orifice dénoyé, orifice noyé, écoulement libre)
\citep{briand_note_2015}.

Les débits de 2020-2021 ont été ré-ajustés pour les écoulements libres et un
coefficient de 1.4 a été utilisé en place du coefficient de 3.34 pour palier aux
dérives de capteurs de niveau du barrage \fottnote{correction temporaire, travail en cours sur les formules de débit,
pour expliquer et corriger ce biais.} (Figure
\ref{debits_ajustes}).

TODO 2022

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2022/debits_ajustes_zoom2022}
\caption[Débits recalculés 2022]{Débits recalculés 2022.
Comparaison des débits mesurés au niveau de la station de Rieux (Pont de Cran - station
hydrométrique), des débits calculés par l'automate du barrage d'Arzal et des
débits recalculés par la méthode de \citet{briand_note_2015}. La saison de suivi
s'étend de XXXXX à XXXX.}
\label{debits_ajustes}
\end{figure}

L'analyse des dérives des codeurs du volet 3 conduit à corriger
substantiellement les périodes avec et sans écoulement sur les volets en début de saison. En
pratique, les ouvertures de septembre ne sont que des ouvertures diurnes et
n'ont pas d'effet sur les suivis au didson qui se concentrent sur les périodes
nocturnes (Figure \ref{debitvoletjour}).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2022/debitvoletjour2022}
\caption[Débits volet 2022]{Comparaison des valeurs produites par
l'automate du barrage et des valeurs obtenues après correction de la dérive des codeurs. Les formules de
débits des volets ont été recalées mais donnent à peu de choses près les mêmes
débits avec des formules de débit différentes  \citep{briand_note_2015}.}
\label{debitvoletjour}
\end{figure}

Les débits ont été recalculés pour chacun des pertuis de vanne
(Figure \ref{debits_inst2022}).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{2022/debits_inst2022}
\caption[Débits sur chaque pertuis de vanne pour l'hiver 2021--2022]{Débits de
chacun des pertuis de vanne pour l'hiver 2021--2022 en
fonction des différents types d'écoulements calculés
sur chaque vanne \citet{briand_note_2015}.}
\label{debits_inst2022}
\end{figure}

\subsection{Dépouillement des fichiers}\label{par_depouillement}

Les fichiers sont recueillis au niveau du local de la passe à intervalles réguliers et rapatriés 
au siège de l'EPTB Vilaine. Ils sont ensuite traités par le logiciel pour
réduire le temps de dépouillement.
Le traitement (CSOT) retire les éléments stables de l'image (échos constants) et ne retient que des
poissons des objets, voire rien en période de fort débit et forte turbidité. Ce processus permet de
réduire la taille des fichiers et de limiter le temps de dépouillement, mais il dépend aussi des conditions. Le passage d'un banc de mulets,
par exemple, pourra conduire à garder l'ensemble du fichier. 
Les seuils de traitement appliqués sont identiques aux années précédentes, 2.8 dB en volet et 2.5 dB en vanne.
A plusieurs reprises des
comparaisons ont été menées aux fichiers complets pour vérifier que
l'application du CSOT ne conduisait pas à écarter des données. 
Les fichiers qui contenaient des anguilles douteuses (notées 1 sur une échelle de 1 à 5) ont été relus par les deux lecteurs pour validation. 
La présence de mulets en dévalaison ou de nombreux alevins est notée sur une échelle de 0 à 5, 
depuis le niveau zéro (pas d'alevins ou de mulets) à 5 (gêne maximale).

Trois type de nage sont notés : 
\begin{itemize}
\item \emph{Running} l'anguille dévale normalement,
\item \emph{Backsliding} l'anguille dévale avec la tête orientée vers l'amont,
\item \emph{Hanging} l'anguille a un comportement de nage à contre courant et au
final il est difficile de savoir si elle est passée ou pas, ce type de
comportement se produit en général à l'ouverture des vannes.
\end{itemize}
Par rapport à la lecture du didson, les opérateurs renseignent également
l'entrée et la sortie des anguilles du champ. La zone d'écho du sonar se
présente comme un cône (Figure \ref{fig_anguilles}). Cette image rassemble en
deux dimensions les échos enregistrés à plusieurs hauteurs, il n'est donc pas
possible de connaître le positionnement vertical de l'anguille dans le cône du
faisceau (Figure \ref{didsonsurface}). Plusieurs types d'enregistrement sont
donc répertoriés :
\begin{itemize}
\item \emph{<-->} l'anguille traverse l'ensemble du champ horizontal prospecté
par le didson (elle traverse le faisceau d'un bord à l'autre (Figure
\ref{fig_anguilles})),
\item \emph{In} l'anguille entre dans le champ, soit par-dessus, soit par
dessous, soit latéralement (dans ce cas elle entre généralement en début de
champ de détection, c'est à dire qu'elle était entre la pile et la zone de
prospection); pour l'observateur elle apparaît donc en cours de trajectoire au milieu du champ,
\item \emph{Out} l'anguille sort du champ,
\item \emph{InOut} l'anguille entre et ressort.
\end{itemize}

\subsection{Traitements}

\label{partraitement}
Les données sont récupérées depuis la base de données PostgreSQL à l'aide
d'outils RODBC et sqldf
\citep{grothendieck_SqldfManipulateData_2017,conway_RPostgreSQLInterfacePostgreSQL_2021}.

Les suivis concernent quatre classes de tailles d'anguilles ($\tau$ formule \ref{eq_tau}) dont les probabilités de détection par le didson ne sont pas
équivalentes en fonction des distances ($\delta$, formule \ref{eq_delta}, Figures
\ref{didsonsurface} \ref{didsonD1}).
La fenêtre de détection est découpée en cinq quadrilatères situés à des
distances croissantes $\delta$ (formule \ref{eq_delta}).
Les résultats ont été regroupés en fonction de deux positions du didson ($k$, formule
\ref{eq_k}). Les suivis sont ramenés à la durée d'un fichier de suivi, c'est à dire $t$=30 minutes.
Les données sont séparées par saison de suivi de 2012-2013 à 2020-2022.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
  \label{eq_tau}
  \text{Tailles d'anguilles}~(\tau)=
  \begin{cases}
      <45cm~\text{mâles}\\
      45-60cm~\text{petites femelles}\\
      60-80cm~\text{femelles}\\
      >80cm~\text{grandes femelles}
  \end{cases}
\end{equation}
\begin{equation}
  \label{eq_delta}
  \text{Distance}~(\delta)=
  \begin{cases}
      (2,5m[\\
      (5,7m[\\
      (7,9m[\\
      (9,11m[\\
      (11,13m[\\
      (13,15m[      
  \end{cases}
\end{equation}
Les positions du didson au cours des différentes années de suivi peuvent se
résumer à 4 configurations,  sl correspond à un appareil penché pour essayer
d'évaluer le positionnement vertical des anguilles dans la lame d'eau.
\begin{equation}
  \label{eq_k}
  \text{Position}~(k)=
  \begin{cases}
      f_{5}~\text{fond, 5-15m}\\
      f_{3}~\text{fond, 3-12m}\\      
      s~\text{surface, 5-15m}\\
      sl~\text{fond et surface, 3-12m}\\
  \end{cases}
 \end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
L'objectif des traitements est
d'extrapoler le nombre d'anguilles observées au niveau du sonar
$N_{4o}(t,\tau,\delta)$, à l'ensemble de la vanne 4, $N_4(t,\tau)$, puis à 
l'ensemble du fleuve Vilaine $N(t,\tau)$. 

\subsubsection{Efficacité de la détection}\label{par_traitement_efficacite}

Le nombre observé par les opérateurs du didson pour chaque classe de
taille, correspond au nombre d'anguilles
migrant multiplié par l'efficacité du didson $E_k(t,\delta,\tau,t)$, calculée pour
chaque classe de taille $\tau$ , chaque classe de distance $\delta$ et pour les
différentes positions du didson $k$ (Formule \ref{eq_efficacite}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq_efficacite}
N'_{o4}(t,\tau,\delta,k)= N_{o4}(t,\tau,\delta,k) \times E_k(t,\delta,\tau)\\
\end{equation} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Le nombre de détections disponibles pour le didson est trop faible
pour permettre de tester une variation temporelle de l'efficacité du didson et
la somme des effectifs observés sur l'ensemble de chaque saison et pour chaque
position du didson sert de base au calcul.
$$N_{o4}(\tau,\delta,k)=\sum_t N_{o4}(t,\tau,\delta,k,t)$$
Si l'efficacité était de 100\%, le nombre d'anguilles détectées devrait
augmenter régulièrement avec la distance au didson en proportion de
l'augmentation de la surface couverte par le faisceau $S(k)$ (Figure \ref{didsonsurface}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq_efficacite2}
\begin{aligned}
&N_{o4}(\tau,\delta+1,k)=\\
&N_{o4}(\tau,\delta,k) \times \frac{S(\delta+1,k)}{S(\delta,k)}
\end{aligned}
\end{equation} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Les surfaces des polygones sont calculées par
l'intersection de droites \citep{murdoch_GpclibGeneralPolygon_2020} (Figures
\ref{didsonsurface}).
D'une classe de taille à la suivante, les nombres
observés devraient théoriquement augmenter en cohérence avec les rapports de
surface. Ainsi, cette augmentation devrait être
linéaire, sauf lorsque le faisceau heurte le fond, car alors une partie de la
zone de détection est perdue (cas pour les premières années de suivi).

En effet, d'après \ref{eq_efficacite} et \ref{eq_efficacite2}, on a (formule
\ref{eq_efficacite3}) :
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
\label{eq_efficacite3}
\begin{aligned}
& E(\delta+1,\tau,k)=\\
& E(\delta,\tau,k)\times\frac{S(\delta+1,k)}{S(\delta,k)}\times\frac{N'_{o4}(\tau,\delta,k)}{N'_{o4}(\tau,\delta+1,k)}\\
\end{aligned}
\end{equation} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

En pratique, les effectifs n'augmentent pas avec la surface de détection, et la
diminution dépend de la classe de taille. Les rapports des effectifs corrigés de
la taille du faisceau servent de base au calcul de l'efficacité (hypothèse 1, 
Figure \ref{fig_diag_efficacite})

En prenant comme référence E=1 pour
les classes de distance où les détections sont maximales, on pourrait calculer
l'efficacité pour chacune des classes de taille en fonction de la distance de
détection. Cette approche a été utilisée jusqu'en 2019-2020.
Le problème est que pour chaque classe de taille, la classe de
distance pour laquelle il y a le plus d'anguilles dans les effectifs corrigés se
voit attribuer la note de 1. Or un examen des qualités de détection montre clairement
un contraste entre les positions $k=$ volet ou vannes et en fonction
des classes de distance au didson et de la taille (Figure
\ref{qualite_distance}).
Les distances au didson sont déjà prises en compte dans le calcul des
efficacités, il reste donc à prendre en compte la diminution des efficacités en
fonction de la position et de la taille. L'idée est que la proportion
d'anguilles douteuses (et donc écartées des comptages) est proportionnelle
à la proportion d'anguille de bonne qualité observée pour
les deux positions $k$, et pour les différentes classes de taille $\delta$ (hypothèse 3, 
Figure \ref{fig_diag_efficacite})
A partir de 2019-2020, au lieu d'attribuer 1 comme maximum de classe on attribue
la valeur $q$ qui est le rapport entre le pourcentage d'anguilles de bonne
qualité (4 ou 5) dans la classe de observée et la classe de référence : $\tau=>80cm, k =surface$. En outre, les
données sont analysées sur les détections de toutes les saisons (Figures
\ref{qualite_distance_volet_all}, \ref{qualite_distance_vanne_all}).

\begin{figure}[htbp]
       \includegraphics[width=0.5\textwidth]{visio_efficacite_didson.png}
        \caption[Diagramme efficacité.]{Diagramme schématique du calcul de
        l'efficacité.}
       \label{fig_diag_efficacite} 
\end{figure}

On fait l'hypothèse que pour la classe de distance la plus favorable et pour la
position volets, toutes les anguilles sont détectées (efficacité 1). Cette
hypothèse est probablement juste car il n'y a que des anguilles de bonne qualité (>2) pour les deux distances les plus proches du
didson dans la classe de taille >80cm.

Ces données sont ensuite utilisées pour calculer les efficacités moyennes par un modèle linéaire, pour lequel $b_0$, $b_1$,\dots,
$b_6$ sont les coefficients de la régression.
La distance, la position, la saison (avec une séparation pour les deux premières
saisons en fonction de la position de départ à 3 ou 5 m) Les interactions entre
la distance et la position $\delta:k$ et entre la taille et la position $\tau:k$ et avec la saison de suivi sont testées. 
 La prédiction du modèle peut conduire à des efficacités supérieures à 1, qui
 sont alors ramenées à 1 (formule \ref{eq_efficacite31}).
\begin{equation}
\label{eq_efficacite31}
\begin{aligned}
&\widehat{E(\delta,\tau,k)} = \\
&min(1,b_0+b_1\tau+b_2\delta+b_3 k+b_4\delta:k+b_5\tau:k+b_6 saison)
\end{aligned}
\end{equation} 
L'efficacité pour chaque position du didson k $\bar{E_k}$
correspond à l'efficacité moyenne pondérée, calculée comme suit :
\begin{equation}
\label{eq_efficacite32}
\bar{E_k}=\frac{\sum_{\tau \delta}N'_{o4}(\tau,\delta,k) }{\sum_{\tau \delta}N_{o4}(\tau,\delta,k)}
\end{equation} 
Le rotateur n'a pas été utilisé en 2018--2019. Les autres années, le calcul
des effectifs à chaque pas de temps était finalement pondéré d'un facteur lié au
temps d'enregistrement réduit par le fonctionnement du rotateur lorsqu'il se
repositionnait. Les enregistrements de chaque heure H étaient alors sur les
périodes $H:00:00$ $\Rightarrow$ $H:29:00$ et $H:30:00$ $\Rightarrow$ $H:59:00$. 
Sur les périodes correspondant à un échantillonnage en alternance, les effectifs
étaient donc amputés d'un facteur $\rho(k)$. Pour l'ensemble de la saison, en
l'absence de fonctionnement du rotateur, on a $\rho(k)$= 1.

\begin{equation}
\label{eq_efficacite4}
\begin{aligned}
\bar{E(k)}=&\bar{E(\delta,\tau,k)}\\
N'_{o4}(t,k)=& N_{o4}(t,k) \times \bar{E(k)} \times \rho(k)
\end{aligned}
\end{equation} 

\begin{figure}[htbp]
        \centering
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics{2016/anguille_114}
                \caption{Anguille de 114 cm.}
       \end{subfigure}%         
       \quad
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics{2016/anguille_detail}
                \caption{Détail anguille 83 cm.}
       \end{subfigure}%         
       \quad
      \begin{subfigure}{0.4\textwidth}
                \centering
                \includegraphics{2016/anguilles}
                \caption{Deux anguilles}
                \label{ang0}
        \end{subfigure}%    
        \caption[Anguilles.]{Anguilles en dévalaison filmées par le didson.}
       \label{fig_anguilles}
\end{figure}

\subsubsection{Migration sur l'ensemble de la vanne}



Lors des écoulements par le fond, en vanne, l'analyse de la répartition
verticale des anguilles a montré qu'il semblait y avoir une présence des
anguilles sur l'ensemble de la colonne d'eau \citep{briand_suivi_2015}.
Compte tenu de cette observation, il a été nécessaire d'étendre la
hauteur de migration qui lors de la première année n'avait été considérée que comme étant
de deux fois la hauteur d'ouverture de la vanne. Nous faisons l'hypothèse que
les anguilles migrent sur l'ensemble de la colonne d'eau à l'exception des deux mètres en surface ($\Lambda$=2). 

L'examen des comportements d'anguilles dans
le fond de la vanne les écoulements s'effectuent en volet (par le clapet de surface),
montre que ces dernières ne sont pas affectées par les écoulements en surface. 

Au contraire, en surface, on observe bien un comportement de migration
verticale, avec une montée dans la colonne d'eau, qui se traduit par une
apparition et une disparition des anguilles du faisceau du didson et non une
traversée comme c'est plus souvent le cas lorsque les écoulements sont linéaires
au fond. En surface, les migrations sont donc extrapolées sur une zone
représentant $\lambda$=6 fois la charge sur le volet. Ainsi, pour toutes les
années de suivi, la même approche a été utilisée : le nombre passant au niveau
de la vanne correspond au nombre passant dans le cône de détection du didson $N_{o4}$, 
extrapolé à l'ensemble de la fenêtre de migration.

Le ratio des surfaces F dépend donc de la hauteur de la colonne d'eau  $D_t$ ou
de la charge sur le volet $C_t$ qui est calculée à chaque pas de temps (formules
\ref{eqmigvan1} et \ref{eqmigvan2}). 
\begin{equation}
\label{eqmigvan1}
 N_{o4}(t,k)=N_4(t,k)) \times F(t,k,\Lambda,\lambda)\\
\end{equation}
 
 \begin{equation}
\label{eqmigvan2}
 F(t,k,\Lambda,\lambda)=
 \begin{cases}
\frac{S(k)}{l (D_t-\Lambda)} \text{au fond}\\
\frac{S(k)}{l C_t \lambda} \text{en surface}
\end{cases}
 \end{equation}
 
\subsubsection{Migration sur l'ensemble du barrage}

Nous faisons l'hypothèse qu'il n'y a pas de trajet de migration préférentielle
au droit du barrage, c'est à dire que la répartition des anguilles entre les
différents pertuis se fait au \textit{prorata} du débit. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{equation}
\label{eq_Ntotal}
N_4(t) = \frac{Q_4(t)} {Q(t)} \times N(t)\\
\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Migration jour/nuit}

Comme les anguilles migrent majoritairement de nuit, les dépouillements ont été
effectués sur les fichiers correspondant à la période nocturne. Pour la
migration diurne, le pourcentage d'anguilles migrant de jour $\mu$ a été calculé.
\begin{equation}
\label{eq_mu}
N = \frac{\sum_{t=nuit}N}{1-\mu}\\
\end{equation}

\subsubsection{Modélisation de la migration}
En 2020-2022 le dépouillement des fichiers a débuté le 04/10 avec un problème de
qualité des images  Nous avons reconstitué les
effectifs en migration lors des périodes sans suivi $N_d\otimes$ à partir des densités mesurées 
pour la même nuit dans un positionnement correct $N_d\odot$ et du volume d'eau
transitant par le barrage $V\odot$ (Equation \ref{mod}).
\begin{equation}
\label{mod}
N_d\otimes=\frac{\sum_{t,k} N(t,k)\odot*V\otimes}{V\odot}
\end{equation}
Pour les jours où aucun suivi n'a été effectué à cause de problèmes
techniques les effectifs $N_d\oplus$ ont été interpolés à partir de la tendance
des effectifs journaliers par un modèle gam basé sur la
tendance saisonnière et le débit.

\subsubsection{Calcul des biomasses}

Les biomasses en dévalaison ont été calculées à partir de la fréquence de taille
corrigée des anguilles. Les fréquences des effectifs de chaque classe de taille
de 5cm ont été calculées et multipliées par le poids moyen du centre de la
classe, tel que prédit par la relation taille/poids calée sur les données régionales
d'anguilles argentées (source OFB et EPTB-Vilaine).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
\section{Résultats}
\subsection{Suivi}
\subsubsection{Fonctionnement du barrage}
<<fonctionnementvanne, echo=FALSE, eval=TRUE,results=hide>>=
png(file=str_c(imgwdy,"fonctionnementvanne.png"),,width = 8, height = 8, units = 'in', res = 300)
def.par <- par(no.readonly = TRUE)
par(mar = c(2,3,1,1))
d3ej$hv=d3ej$hvanne4-7.72
d3ej$hvo<-4.63
d3ej$hvo[d3ej$volet4]<-+2
d3ej$dsc<--2*(d3ej$volbarrage30)/max((d3ej$volbarrage30),na.rm=TRUE)+8
thisseason <- d3ej$dsf_season==saison
plot(d3ej$round_time[thisseason],d3ej$dsc[thisseason],type="b",col="grey",cex=0.3,ylim=c(-8,+8),xlab="",ylab="")
mtext(side = 2, "Niveau vanne ou volet (m)", line = 2)
points(d3ej$round_time[thisseason],d3ej$hv[thisseason],pch=16,cex=0.8,col=bleu_EV)
points(d3ej$round_time[thisseason],d3ej$hvo[thisseason],col=rouille,type="p",pch="|",cex=0.4)
abline(h=-6,col="#242D70",lty=3) # profondeur didson
abline(h=c(0,1),col="#242D70",lty=2)
abline(h=-8,col="#242D70",lty=3) # profondeur didson
Xpos<-as.numeric(d3ej$round_time[thisseason][1])
text(Xpos,0.8,label="surface",col=turquoise_EV,pos=4)
text(Xpos,-5.72,label="didson",col=orange_EV,pos=4)
text(Xpos,-7.5,label="fond",col=turquoise_EV,pos=4)
text(Xpos,6.8,label="débit",col="grey",pos=4)
text(Xpos,5.1,label="volet 4 fermé",col=rouille,pos=4)
text(Xpos,2.5,label="volet 4 ouvert",col=rouille,pos=4)
text(Xpos,-4,label="vanne 4",col=grisbleufonce,pos=4)
arrows(Xpos,8,Xpos,6,col="grey",length=0.1)
dev.off()
par(def.par)
d3ej<-d3ej[,-match(c("hv","hvo","dsc"),colnames(d3ej))]
########################
# Graphique des débits et turbidités
#######################
# make a copy of current settings
cor(d3edj$debitvilainej,d3edj$enj_turb) #
cor(d3edj$debitvilainej,d3edj$enj_turb,use="complete.obs") # 0.87
png(file=str_c(imgwdy,"debitturbidite.png"),,width = 8, height = 8, units = 'in', res = 300)
#d3edj<-d3edj[!is.na(d3edj$enj_turb),]
yat <- pretty(c(0, 800)) # loc des labels
yat2<-yat/4
# ajoute de la place à gauche
par(oma=c(0,2,0,0))
#calcul des problèmes d'acquistion
# d3ej[,c("dsf_timeinit","dsf_fls_id")]
pb<-d3ej$dsf_timeinit[thisseason][d3ej$dsf_fls_id[thisseason]==3&!is.na(d3ej$dsf_fls_id[thisseason])]
if (length(pb>0)){
	pb<-data.frame("date"=pb,"delta"=NA)
	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
	pb$delta[1]<-30
	w<-which(pb$delta>690)
	dateinit<-c(pb[1,"date"],pb[w,"date"])
	dateinit<-as.Date(dateinit,tz=Sys.timezone())
	datefin<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
	datefin<-as.Date(datefin,tz=Sys.timezone())
} else {dateinit=NULL;datefin=NULL}
#pb<-d3ej$dsf_timeinit[d3ej$dsf_fls_id==2&!is.na(d3ej$dsf_fls_id)]
#if (length(pb>0)){
#	pb<-data.frame("date"=pb,"delta"=NA)
#	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
#	pb$delta[1]<-30
#	w<-which(pb$delta>690)
#	dateinit2<-c(pb[1,"date"],pb[w,"date"])
#	dateinit2<-as.Date(dateinit2,tz=Sys.timezone())
#	datefin2<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
#	datefin2<-as.Date(datefin2,tz=Sys.timezone())
#}else {dateinit2=NULL;datefin2=NULL}
############################
pb<-d3ej$dsf_timeinit[thisseason][d3ej$dsf_fls_id[thisseason]==1]
if (length(pb>0)){
	pb<-data.frame("date"=pb,"delta"=NA)
	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
	pb$delta[1]<-30
	w<-which(pb$delta>690)
	dateinit3<-c(pb[1,"date"],pb[w,"date"])
	dateinit3<-as.Date(dateinit3,tz=Sys.timezone())
	datefin3<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
	datefin3<-as.Date(datefin3,tz=Sys.timezone())
} else {dateinit3=NULL;datefin3=NULL}
# plot, mais pas les axes 
thisseason <- d3edj$enj_date>=datedebut
plot(d3edj$enj_date[thisseason],d3edj$deb_qtotalj[thisseason],type="l",yaxt='n',col="black",ylab="",xlab="date",ylim=c(0,1000))
if (!is.null(dateinit3)){
	rect(xleft=dateinit3,ybottom=102,xright=datefin3,ytop=800,col=jaune_EV,border=jaune_EV,density=6)
}
if (!is.null(dateinit)){
	rect(xleft=dateinit,ybottom=102,xright=datefin,ytop=800,col=orange_EV,border=rouille)
}

#rect(xleft=date_seuil_pb_lentille,ybottom=102,xright=as.Date(max(d3ej$dsf_timeinit)),ytop=1000,col=makeTransparent("yellow",70),border="orange")
polygon(c(d3edj$enj_date[thisseason],max(d3edj$enj_date[thisseason])+1),c(pmax(100,d3edj$deb_qtotalj[thisseason]),100),col="grey",border=NA)
# petit ajustement 2018-2019 pour que le gris finisse à 100
#polygon(d3edj$enj_date,pmax(100,d3edj$debitvilainej),col="grey",border=NA)
points(d3edj$enj_date[thisseason][thisseason],d3edj$debitvilainej[thisseason],col=turquoise_EV,type="l")
points(d3edj$enj_date[thisseason],d3edj$enj_turb[thisseason]*4,col="black",type="l",lty=2)
axis(2, col=turquoise_EV, at=yat, labels=yat,col.axis=turquoise_EV)
axis(side=2, at=yat, labels=yat2, col=rouille, line=2,col.axis=rouille)
mtext(side=2, line=4, "Débit journalier m3/s et turbidité (NTU)")
#abline(h=100,lty=2)
dev.off()
@

Le barrage a connu quelques ouvertures nocturnes avant la mise en place du
didson le 02 octobre (Figures \ref{debitturbidite} et
\ref{fonctionnementvanne}). Les premiers pics de crue (débit supérieur à
\SI{100}{\cubic\metre\per\second}) interviennent très tôt dans la saison.
Comme la saison 2019--2020, la saison 2020--2021 est marquée un débit de grande
crue \SI{700}{\cubic\metre\per\second}, la saison 2021--2022 XXXX. Les
turbidités montent au-delà de \underline{50 NTU} au cours du premier pic de crue (Figure
\ref{debitturbidite}).

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.4\textwidth]{2022/debitturbidite.png}
  \caption[Débits, turbidité et problèmes de fonctionnement du
  sonar]{ Débit de la Vilaine 
  (m$^3$.s$^{-1}$ \textcolor{black}{\rule[0.5mm]{0.5cm}{0.3mm}}) et turbidité
  (NTU, \protect\dashedrule) pendant la période de migration. En
  \textcolor{turquoise_EV}{\rule[-0.5mm]{3mm}{2mm}} débits corrigés (moyennes journalières). En fond, problèmes de fonctionnement du sonar,
   en jaune \textcolor{jaune_EV}{\rule[-0.5mm]{3mm}{2mm}} erreurs ponctuelles
  d'acquisition, %en jaune, \textcolor{yellow}{\rule[-0.5mm]{3mm}{2mm}}
  % problèmes d'écriture,
  en orange, \textcolor{orange_EV}{\rule[-0.5mm]{3mm}{2mm}} problèmes
 de qualité, 
  voir aussi la figure
\ref{fig_horairespb} dans la discussion pour le détail des horaires.}
  \label{debitturbidite}
\end{figure}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.4\textwidth]{2022/fonctionnementvanne.png}
  \caption[Fonctionnement du barrage]{Fonctionnement du barrage, ouverture de la
  vanne 4 et du volet 4 et débit de la Vilaine pendant la période de migration.
  Chaque point correspond à une valeur pendant 30 minutes. 
  }
  \label{fonctionnementvanne}
\end{figure}



\subsubsection{Dépouillement des fichiers}
<<depouillement, echo=FALSE, eval=TRUE,results=hide>>=
##################
# tabletps
##################
colnames(depouillement)<-c("mois","temps")
ordre<-match(c(9,10,11,12,1,2,3,4),depouillement$mois)
ordre<-ordre[!is.na(ordre)]
depouillement<-depouillement[ordre,]
depouillement[nrow(depouillement)+1,"temps"]<-sumdepouillement
depouillement$temps<-gsub("days","jours",depouillement$temps)
depouillement$temps<-gsub("day","jour",depouillement$temps)
depouillement[nrow(depouillement),"mois"]<-"total"
options(encoding = "UTF-8")
depouillement.tex<-latex(depouillement,
		label="tabletps",
		rowlabel="",
		rowname=NULL,
		numeric.dollar=FALSE,
		where="h!",
		caption=str_c("Temps de dépouillement des fichiers didson en ",saison,". 
						Les temps donnés ne correspondent qu'au temps passé au dépouillement."),
		caption.lot=str_c("Temps de dépouillement"),
		file=str_c(tabwdy,"depouillement.tex"))
options(encoding = "native.enc")
##################
# tpspoint
###################
#tps$temps[tps$temps_lecture==60&!is.na(tps$temps_lecture)]<-0
pdf(file=str_c(imgwdy,"tpspoint.pdf"),width=6,height=5)
ggplot(tps)+geom_point(aes(x=dsf_timeinit,y=temps_lecture,col=dsr_reader),size=2)+
#   geom_smooth(aes(x=dsf_timeinit,y=temps_lecture,col=dsr_reader))+
		ylab("temps de dépouillement d'un ficher de 30 minutes en minutes")+
		xlab("Jour d'enregistrement du fichier")+
		scale_colour_manual("lecteur",values=c("Brice"=orange_EV,"Gerard"=turquoise_EV))
dev.off()
##################
# tpsboxplot
##################
tps$mois<-factor(tps$mois,levels=c("9","10","11", 
				"12", "1","2","3","4"), order=TRUE) 
pdf(file=str_c(imgwdy,"tpsboxplot.pdf"),width=6,height=5)
ggplot(tps)+geom_boxplot(aes(x=mois,y=temps_lecture,fill=dsr_reader))+
		ylab("temps de dépouillement d'un ficher de 30 minutes en minutes")+
		xlab("Mois")+
		#scale_y_continuous(limits=c(0,100))+
		scale_fill_manual("lecteur",values=c("Brice"=orange_EV,"Gerard"=turquoise_EV))

dev.off()		
#tapply(tps$temps_lecture,tps$mois,mean,na.rm=TRUE)
tabfls <- as.data.frame.matrix(table(d3ej$dsf_fls_id[d3ej$dsf_season==saison],d3ej$position[d3ej$dsf_season==saison]))[,c(1,3,2)]
#colnames(tabfls)<-c("f","s","n")
options(encoding = "UTF-8")
xtafls<-xtable::xtable(tabfls,
		label="tabfls",
		caption="Fonctionnement (nombre de suivis de 30 minutes) du didson en fonction de l'ouverture de la vanne
				et de la position, $s$= appareil en surface, $f5$= appareil en vannes, $n$ appareil en panne,
				0 enregistrement normal, 1 problème d'acquisition, 2 problèmes d'écriture sur le disque, 3 problèmes de qualité.",
		digits=0
)
print(xtafls,file=str_c(tabwdy,"tabfls.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)	

tabflsall <- as.data.frame.matrix(table(d3ej$dsf_fls_id,d3ej$position))
#colnames(tabfls)<-c("f","s","n")
xtafls<-xtable::xtable(tabflsall,
		label="tabfls",
		caption="Fonctionnement du didson en fonction de l'ouverture de la vanne
				et de la position pour l'ensemble des saisons de suivi, $s$= appareil en surface, $f3$ $f5$= appareil en vannes, $n$ appareil en panne,
				0 enregistrement normal, 1 problème d'acquisition, 2 problèmes d'écriture sur le disque, 3 problèmes de qualité.",
		digits=0
)
print(xtafls,file=str_c(tabwdy,"tabflsall.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)	
options(encoding = "native.enc")
@
Le dépouillement correspond à du temps de lecture de fichier (Figure
\ref{tps}), il ne comprend pas la maintenance des
données, l'inscription dans la base ou les vérifications. 
En prenant comme base un temps de dépouillement de 6 heures par jour, 5
jours par semaine, la durée totale de dépouillement n'est que de l'ordre de
7 jours contre 15 jours pour la saison précédente (2019-2020), et un mois pour
2018-2019 (Tableau \ref{tabletps}).
Ce temps plus limité est lié en partie à l'enlèvement du didson de l'eau en
février.

\input{../../../pdata/didson/rapport/table/2021/depouillement.tex}
On retrouve des temps de dépouillement dépassant 30 minutes lors des pics de
migration, la mesure des anguilles restant chronophage (Figure \ref{tpspoint}).  
\begin{figure}[htbp]
        \centering
        \begin{subfigure}{0.4\textwidth}
                \centering
                \includegraphics{2021/tpspoint}
                \caption[Temps de dépouillement par fichier de 30
                minutes]{Temps de dépouillement en \Sexpr{saison}.}
                \label{tpspoint}
       \end{subfigure}%         
       \quad
      \begin{subfigure}{0.4\textwidth}
                \centering
                \includegraphics{2021/tpsboxplot}
                \caption[Temps de dépouillement par fichier de 30
                minutes]{BoxPlot des temps de dépouillement en \Sexpr{saison}.}
                \label{tpsboxplot}
        \end{subfigure}%    
        \caption[Temps de dépouillement, distribution et boxplot]{Temps de
        dépouillement, distribution et boxplot.}
              \label{tps}
\end{figure}
Cette année comme les autres, les fichiers ont été vérifiés grâce à la double
inscription des dépouillements, à la fois dans un fichier excel, et après
traitement des fichiers textes comprenant les données poisson.

<<muletsalevins, echo=FALSE, eval=FALSE,results=hide>>=

hour<-as.numeric(strftime(dd$dsf_timeinit,format="%H"))
mois<-strftime(dd$dsf_timeinit,format="%m")
mois<-factor(mois,levels=c("10","11","12","01","02","03","04"))
week<-as.numeric(strftime(dd$dsf_timeinit,format="%W"))
hour<-as.numeric(strftime(dd$dsf_timeinit,format="%H"))
#describe(dd)
#plot(dd$dsf_timeinit,dd$dsr_muletscore)
#plot(dd$dsf_timeinit,dd$dsr_fryscore)
#plot(tapply(dd$dsr_fryscore,week,mean,na.rm=TRUE))
#plot(0:23,tapply(dd$dsr_fryscore,hour,mean,na.rm=TRUE),xlab="hour",ylab="score moyen mulets",type="l")
muletw<-tapply(dd$dsr_muletscore,week,mean,na.rm=TRUE)
muletwn<-as.numeric(names(muletw))
muletwn[as.numeric(names(muletw))<20]<-muletwn[as.numeric(names(muletw))<20]+max(muletwn)+1
muletwn<-muletwn-min(muletwn)
fryw<-tapply(dd$dsr_fryscore,week,mean,na.rm=TRUE)
frywn<-as.numeric(names(fryw))
frywn[as.numeric(names(fryw))<20]<-frywn[as.numeric(names(fryw))<20]+max(frywn)+1
frywn<-frywn-min(frywn)
png(file=str_c(imgwdy,"mulet.png"))
plot(muletwn,muletw,xaxt="n",type="h",ylab="score moyen de gêne",xlab="date",lwd=2,col=orange_EV)
points(frywn+0.2,fryw,xaxt="n",type="h",lwd=2,col=turquoise_EV)
ax<-seq.POSIXt(from=min(dd$dsf_timeinit),to=max(dd$dsf_timeinit),by="week")
ax<-strftime(ax,format="%d-%m")
axis(1,at=1:length(ax),labels=ax) # obligé de traffiquer ???
dev.off()

@

Deux facteurs principaux gênent la lecture des fichiers du didson, il s'agit de
la présence d'alevins et de la présence de mulets. Les présences gênantes
d'alevins et de mulets peuvent exister en début de saison en octobre et novembre, sans toutefois constituer un facteur limitant pour le comptage. Ils
disparaissent en hiver avant de réapparaitre en mars (Figures \ref{mulet},
\ref{al}).


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2015/mulet}
  \caption[présence de mulets lors des comptages]{Histogramme montrant la
  présence de mulets (\textcolor{orange_EV}{\rule[0.5mm]{0.5cm}{0.5mm}}) et 
  d'alevins (\textcolor{turquoise_EV}{\rule[0.5mm]{0.5cm}{0.5mm}}) dans les
  comptages, les valeurs sont aggrégées sous forme de moyenne à partir de scores
  allant de 0 (pas de poissons) à 5 (poissons très gênants pour le comptage).}
  \label{mulet}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2015/alevin}
  \caption[Bancs d'alevins]{Banc d'alevins le 24 avril 2015.}
  \label{al}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2015/alevin2}
  \caption[Banc d'alevins]{Banc d'alevins le 26 avril 2015.}
  \label{al2}
\end{figure}

Les mulets sont plus gênants que les alevins, avec une
lecture difficile dès que le score dépasse 2, ce qui n'est arrivé qu'en octobre
cette année. Les mulets ont toutefois une activité diurne et la gêne est
en général concentrée en début et fin de nuit.

%Il n'y a pas eu suffisamment de
%dépouillements de journées complètes en 2018--2019, et les valeurs diurnes /
%nocturnes de 2013--2014 ont été appliquées pour le calcul du coefficient $\mu$
%(Figure \ref{h_fonct}).


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/horaires}
  \caption[Horaires de suivi]{Heures de début et de fin des fichiers
  dépouillés, et heures de lever et de coucher du soleil (en jaune). Les rectangles bleus
  à violet correspondent à des horaires de fichiers dépouillés, en noir pas de
  dépouillement, en orange début et fin des durées de pénombre civiles
  correspondant à une position du soleil à -6° en dessous de l'horizon.}
  \label{h_fonct}
  % heure de fonctionnement
\end{figure}

\subsubsection{Problèmes dans le suivi}
\label{parqualite}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2015/flash}
  \caption[Interférence du didson]{Flash du didson}
  \label{flash}
\end{figure}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2014/echo_surface}
  \caption[Echo à la surface]{Echo du didson à la surface.}
  \label{echo}
\end{figure}

L'ensemble des problèmes techniques sont résumés sur les Figures \ref{debitturbidite}, \ref{fig_horairespb} pour le
détail par 30 minutes, et \ref{fig_effectif_pb} pour le graphique saisonnier.

\input{../../../pdata/didson/rapport/table/2021/tabfls.tex}
\input{../../../pdata/didson/rapport/table/2021/tabflsall.tex}
\subsubsection{Positionnement du didson}
<<positionnement, echo=FALSE, eval=TRUE,results=hide>>=
# pour extrapoler d3ej$ex>1
d3ej2<-d3ej[d3ej$dsf_season==saison,]
# JE passe sur un nouveau d3ej2 pour pas casser le dsf_position
#mosaic(~dsf_position+optvanne4|mois,data=d3ej,
#		split_vertical=c(TRUE,TRUE,FALSE),main="Mosaic plot showing occurence of didson position") ###Mosaic Plot for each sampling point
d3ej2$dsf_position <- as.character(d3ej2$dsf_position)
d3ej2$dsf_position[is.na(d3ej2$dsr_id)] <- "0"
d3ej2$dsf_position[is.na(d3ej2$dsf_fls_id)] <- "00"
d3ej2$dsf_position[d3ej2$dsf_fls_id==2] <- "00"
d3ej2$dsf_position[d3ej2$dsf_fls_id==1] <- "00"

d3ej2$dsf_position <- as.factor(d3ej2$dsf_position)
tab <- table(d3ej2$optvanne4,d3ej2$dsf_position,d3ej2$mois)
coloring <- matrix(NA,nrow=4,ncol=4)
rownames(coloring) <- dimnames(tab)[[1]] # fonctionnement de la vanne
colnames(coloring) <- dimnames(tab)[[2]] # position du didson"
coloring["0","00"] <- "black"
coloring["s","00"] <- orange_EV
coloring["f","00"] <- orange_EV
coloring["sf","00"] <- orange_EV
coloring["0","00"] <- "black"
coloring["s","00"] <- orange_EV
coloring["f","00"] <- orange_EV
coloring["sf","00"] <- orange_EV
coloring["0","0"] <- "black"
coloring["0","s"] <- "black"
coloring["0","f"] <- "black"
coloring["f","0"] <- "grey"
coloring["f","s"] <- rouille
coloring["f","f"] <- turquoise_EV
coloring["s","0"] <- "grey"
coloring["s","s"] <- turquoise_EV
coloring["s","f"] <- rouille
coloring["sf","0"] <- "grey"
coloring["sf","s"] <- turquoise_EV
coloring["sf","f"] <- turquoise_EV
#coloring[,"n"]<-"white"
#long.labels <- list(set_varnames = c(dsf_position="Position didson (0=non lu,f=fond,s=surface)",
#				optvanne4="Ouverture vanne (0=fermee,s=surface,f=fond,sf=les deux)"))
long.labels <- list(set_varnames = c(dsf_position="Position didson",
				optvanne4="Ouverture vanne"))
#pdf(file=str_c(imgwdy,"position09.pdf"),width=4,height=4)
#mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="09"),
#		gp=gpar(fill=coloring,col="black"),
#		labeling_args = long.labels,
#		split_vertical=TRUE,main="") 
#dev.off()
pdf(file=str_c(imgwdy,"position10.pdf"),width=4,height=4)
#if (nrow(subset(d3ej2,d3ej2$mois=="10"))!=0) 
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="10"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position11.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="11"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position12.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="12"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position01.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="01"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position02.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="02"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position03.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="03"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
pdf(file=str_c(imgwdy,"position04.pdf"),width=4,height=4)
mosaic(dsf_position~optvanne4,data=subset(d3ej2,d3ej2$mois=="04"),
		gp=gpar(fill=coloring,col="black"),
		labeling_args = long.labels,
		split_vertical=TRUE,main="") 
dev.off()
vvv$perc$"0" <- round(100*d3ej_perc_pos[d3ej_perc_pos$ex=="0" & d3ej_perc_pos$dsf_season==saison,"perc"])
vvv$perc$"1" <- round(100*d3ej_perc_pos[d3ej_perc_pos$ex=="1" & d3ej_perc_pos$dsf_season==saison,"perc"])
vvv$perc$"2" <- round(100*d3ej_perc_pos[d3ej_perc_pos$ex=="2" & d3ej_perc_pos$dsf_season==saison,"perc"])
vvv$perc$"3" <- round(100*d3ej_perc_pos[d3ej_perc_pos$ex=="3" & d3ej_perc_pos$dsf_season==saison,"perc"])
vvv$perc$"4" <- round(100*d3ej_perc_pos[d3ej_perc_pos$ex=="4" & d3ej_perc_pos$dsf_season==saison,"perc"])
save(vvv,file=str_c(datawdy,"vvv.Rdata"))
@


\begin{figure}[htbp]
        \centering
%        \begin{subfigure}{0.2\textwidth}
%                \centering
%                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2021/position09}
%                \caption{Septembre}
%                \label{position09}
%       \end{subfigure}        
%       ~
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position10}
                \caption{Octobre}
                \label{position10}
       \end{subfigure}        
       \quad
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position11}
                \caption{Novembre}
                \label{position11}
       \end{subfigure}        
       ~
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position12}
                \caption{Décembre}
                \label{position12}
       \end{subfigure}        
       \quad
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position01}
                \caption{Janvier}
                \label{position01}
       \end{subfigure}        
       ~
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position02}
                \caption{Février}
                \label{position02}
       \end{subfigure}        
       \quad
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position03}
                \caption{Mars}
                \label{position03}
       \end{subfigure}        
        ~
        \begin{subfigure}{0.2\textwidth}
                \centering
                \includegraphics[trim=5mm 10mm 15mm 10mm,clip]{2022/position04}
                \caption{Avril}
                \label{position04}
       \end{subfigure}        
    \caption[Position du didson par rapport à la vanne 4]{Position du didson et de
    la vanne 4, taille des rectangles relative au nombre d'occurences d'un type
    de positionnement de vanne et d'un type de positionnement didson pour chaque mois.
    En lignes, positionnement du didson, 0 = pas de lecture, s = surface
    (Figure \ref{didsonsurface}), f=fond (Figure \ref{didsonD1}).
    En colonnes, ouverture de la vanne, 0= pas d'ouverture, s=surface, f=fond,
    sf= surface et fond (l'ouverture change au cours des 30 minutes). 
    
    Couleurs :
    \textbf{\textcolor{orange_EV}{violet}} le didson n'enregistre
    pas pour des raisons techniques, \textbf{noir} vanne fermée, \textbf{\textcolor{Gray}{gris}} pas de lecture,
    \textbf{\textcolor{turquoise_EV}{turquoise}} le didson est bien positionné,
    \textbf{\textcolor{rouille}{marron}} le didson enregistre mais il est mal
    placé ou encore (et c'est le cas pour la majorité des périodes) la vanne
    4 est fermée et une vanne ou un volet continue à débiter.
    Grâce à l'automate, le nombre de périodes où le didson est mal placé s'est
    considérablement réduit.}
    \label{fig_position}
\end{figure}

L'analyse du positionnement et du fonctionnement du sonar permettent de
déterminer quelle est la part de valeurs manquantes, qu'il faudra extrapoler pour
reconstituer les effectifs migrant au droit du sonar. L'utilisation de
l'automate pour le placement du didson a permis de considérablement réduire les
périodes où le didson est mal placé.  On peut résumer les fonctionnements du
sonar dans la période de 17h à 9h sur l'ensemble de la saison de migration comme suit (Figure \ref{fig_position}):
\begin{itemize}
  \item
      La vanne 4 est fermée (rectangles \textbf{noirs}),
      que ce soit en surface ou au fond, et il n'y a pas de passage possible.
      Cette situation correspond à
      \num[round-mode = places,
round-precision = 1]{\Sexpr{vvv$perc$"0"}}\% du temps,

  \item Dans tous les autres cas, le pertuis 4 est ouvert
  \begin{itemize}
  \item 
      le didson n'a pas pu être positionné (problèmes techniques)
      \num[round-mode = places,
round-precision = 1]{\Sexpr{vvv$perc$"2"}}\% du temps, (rectangles
      \textbf{\textcolor{orange_EV}{orange}}),
  \item
      le  didson fonctionne, il est bien positionné
      \num[round-mode = places,
round-precision = 1]{\Sexpr{vvv$perc$"1"}}\% du temps (rectangles
        \textbf{\textcolor{turquoise_EV}{turquoise}}),
  \item
      le didson fonctionne, mais il est mal positionné (rectangles
      \textbf{\textcolor{rouille}{marron}}), mais les fichiers ont quand même
      fait l'objet d'un dépouillement seulement \num[round-mode = places,
round-precision = 1]{\Sexpr{vvv$perc$"3"}}\% du temps,
   \item  
      les fichiers du didson n'ont pas été lus, ou le didson n'a pas
      fonctionné pendant \num[round-mode = places,
round-precision = 1]{\Sexpr{vvv$perc$"4"}}\% du
      temps (zones \textbf{\textcolor{Gray}{grises}}).
 \end{itemize}
\end{itemize}
Cette année, les problèmes de fonctionnement du didson en octobre et novembre
sont visibles (en orange, Figure \ref{position10}). L'absence d'automate a
entraîné certaines périodes où le didson était mal positionné (en marron). En
février, le didson a été retiré de l'eau et donc n'a pas fonctionné (en orange
Figure \ref{position02}), mais pour l'essentiel, les problèmes sur la centrale 4
ont entrainé l'absence de manoeuvre et la vanne et les volets sont restés fermés (en noir, 
Figure \ref{position02}). 
Les problèmes d'enregistrement au pic des crues et après la déterioration du câble en mars et avril sont par contre très importants.  (Figures \ref{position12} \ref{position02} \ref{position03} et \ref{position04} - en violet, Figure \ref{fig_effectif_pb} rectangles verts).
Les fichiers non dépouillés en gris correspondent majoritairement aux fichiers
entre 9h et 10h, après le lever du soleil (Figure \ref{fig_horairespb}).\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{\dimexpr.8pt+\fboxsep\relax}
\noindent       
\fbox{%
    \parbox{\linewidth-2\fboxsep-1.6pt}{%
    \parindent\defaultparindent%
    \indent 
Les périodes d'incident technique couvrent
\num{\Sexpr{vvv$perc$"2"}}\% du temps. Le \emph{positionnement}
du didson par rapport aux ouvertures au fond ou en surface est correct 
\num{\Sexpr{vvv$perc$"1"}}\% du temps.
La vanne 4 (ou le volet 4) sont fermés 
\num{\Sexpr{vvv$perc$"0"}}\% du temps.
}
\vspace{\dimexpr.8pt+\fboxsep\relax}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Qualité des images}

<<taille_all, echo=FALSE, eval=TRUE,results=hide>>=
# ce chunk c'est juste pour faires les graphes tous les calculs sont faits dans efficacité
nat=nrow(dddp) # nombre anguilles taille 14360
# Commenter la ligne qui suit pour prendre en compte toutes les données dans le calcul
#dddp<-dddp[dddp$dsf_id%in%dsfindexOK,]

dddp$date<-as.Date(dddp$dsf_timeinit,tz=Sys.timezone())
dddp$count<-1
# problème de lentille en 2018
dddp$pblens <- dddp$date > dmy(23012018) & dddp$date <  dmy(23012018)
dddp[dddp$psf_l_cm==0,]
dddp<-dddp[!is.na(dddp$psf_l_cm)&dddp$psf_l_cm>0,]

# ci dessous attention on coupe pour des classes de distance différentes
dddp$psf_l_cl<-cut(dddp$psf_l_cm,c(0,45,60,150)) # classes de taille
dddp$c_radius<-cut(dddp$psf_radius_m,c(0,7,9,11,13)) # classes de distance
dddp$psf_l_cl2<-cut(dddp$psf_l_cm,c(0,45,60,80,150)) # classes de taille (ajout d'une classe à 80 cm) cette variable prend le nom de ***taille_cm***
dddp$c_radius2<-cut(dddp$psf_radius_m,c(2,5,7,9,11,13,15)) # classes de distance (cette variable prend le nom de ***distance_m*** dans efficacite

# FOND 
dddpf3<-dddp[dddp$dsf_position=="vanne"&dddp$dsf_distancestart<5,]
dddpf3$c_radius<-cut(dddpf3$psf_radius_m,c(3,5,7,9,11,14)) # classes de distance
dddpf3$c_radius2<-cut(dddpf3$psf_radius_m,c(3,5,7,9,11,14)) # classes de distance
#xtabs(count~dsf_distancestart+dsf_incl+dsf_position,data=dddpf3)
#d3ej$count=1
#d3ejf3<-d3ej[d3ej$dsf_position=="f"&d3ej$dsf_distancestart<5,]
#xtabs(count~dsf_distancestart+dsf_incl,data=d3ejf3)
#describe(dddpf3$psf_radius_m)
# VOLET
dddpv<-dddp[dddp$dsf_position=="volet",]
dddpv$c_radius<-cut(dddpv$psf_radius_m,c(5,7,9,11,13,15)) # classes de distance
dddpv$c_radius2<-cut(dddpv$psf_radius_m,c(5,7,9,11,13,15)) # classes de distance
#hist(dddpv$psf_radius_m)
#xtabs(count~dsf_distancestart+dsf_incl+dsf_position,data=dddpv)


# FOND 4 ° 
dddpf5<-dddp[dddp$dsf_position=="vanne"&dddp$dsf_distancestart>=5,]
dddpf5$c_radius<-cut(dddpf5$psf_radius_m,c(5,7,9,11,13,15)) # classes de distance
dddpf5$c_radius2<-cut(dddpf5$psf_radius_m,c(5,7,9,11,13,15)) # classes de distance
#xtabs(count~dsf_distancestart+dsf_incl+dsf_position,data=dddpf5)


#####################""
# PREMIERE ANALYSE AVEC TOUT
#############################
#def.par <- par(no.readonly = TRUE) # save default, for resetting...
## divide the device into two rows and two columns
## allocate figure 1 all of row 1
## allocate figure 2 the intersection of column 2 and row 2
#layout(matrix(c(1,1,0,2), 2, 2, byrow = TRUE))
### show the regions that have been allocated to each plot
#layout.show(2)
#
### divide device into two rows and two columns
### allocate figure 1 and figure 2 as above
### respect relations between widths and heights
#nf <- layout(matrix(c(1,1,0,2), 2, 2, byrow = TRUE), respect = TRUE)
#layout.show(nf)
#
### create single figure which is 5cm square
#nf <- layout(matrix(1), widths = lcm(5), heights = lcm(5))
#layout.show(nf)

##-- Create a scatterplot with marginal histograms -----
#xhist <- hist(dddp$psf_l_cm, breaks = seq(20,120,5), plot = FALSE)
#yhist <- hist(dddp$psf_radius_m,breaks = seq(2,16,2), plot = FALSE)
#xtop <- max(xhist$counts)
#ytop <- max(yhist$counts)
#xrange <- c(-0, 120)
#yrange <- c(2, 16)
#nf <- layout(matrix(c(2,0,1,3),2,2,byrow = TRUE), c(3,1), c(1,3), TRUE)
##layout.show(nf)
#
#par(mar = c(3,3,1,1))
#
#par(mar = c(0,3,1,1))
#barplot(xhist$counts, axes = FALSE, ylim = c(0, xtop), space = 0)
#par(mar = c(3,0,1,1))
#barplot(yhist$counts, axes = FALSE, xlim = c(0, ytop), space = 0, horiz = TRUE)

# Création d'un densityplot avec histogrammes de bordure
str(dddp)

pdf(file=str_c(imgwdy,"taille_distance.pdf"))
#vplayout <- function(x, y) { viewport(layout.pos.row = x, layout.pos.col = y)   }
#grid.newpage()
#pushViewport(viewport(layout = grid.layout(4,1,just="center")))   
## Diagram of a simple layout
#grid.show.layout(grid.layout(2,2,width=unit(c(0.8,0.2),"null"),
#				height=unit(c(0.2,0.8),"null")))
grid.newpage()
vp<-viewport(layout=grid.layout(2,2,width=unit(c(0.8,0.2),"null"),
				height=unit(c(0.2,0.8),"null")))
vplayout <- function(x, y) { viewport(layout.pos.row = x, layout.pos.col = y)   }
pushViewport(vp)
g <- ggplot(dddp,aes(x=psf_l_cm,y=psf_radius_m))+
		stat_bin2d(bins = 30)+
		geom_density2d(colour="yellow")+
		theme(legend.key = element_rect(colour = NA, fill = 'grey20'),
				legend.position=c(0.9,0.8),
				legend.text = element_text(size = 10, colour = 'black'), 
				legend.title = element_text(size = 10, face = "bold", hjust = 0, colour = 'black'),
				legend.box='horizontal',
				legend.background = element_rect(colour = NA, fill = NA))	+
		scale_fill_gradient(low=bleu_EV, high=turquoise_EV)+
		ylab("distance d'observation (m)")+
		xlab("Taille anguille (cm)")+
		scale_x_continuous(limits=c(20,120))+
		scale_y_continuous(limits=c(5,15))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(2,1))
g<-ggplot(dddp,aes(x=psf_l_cm))+geom_bar(colour=turquoise_EV,fill=rouille)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(20,120))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(1,1))
g<-ggplot(dddp,aes(x=psf_radius_m))+geom_bar(colour=turquoise_EV,fill=rouille)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(5,15))+
		theme(plot.margin = unit(c(0,0,0,0), "cm"))+coord_flip()
print(g,vp=vplayout(2,2))
pushViewport(vplayout(1,1))
grid.text(str_c("N=",nrow(dddp)), x=0.5, y=0.5, rot=0,
		gp=gpar(fontsize=20, col="yellow"))
upViewport()
pushViewport(vplayout(1,2))
grid.text(str_c("Tous"), x=0.5, y=0.5, rot=-45,
		gp=gpar(fontsize=20, col="black"))
dev.off()




mycolors <- colorRampPalette(c(bleu_EV, "blue", turquoise_EV, orange_EV, "brown",rouille))
# Pour toutes les années
pdf(file=str_c(imgwdy,"taille_dist_mois_all.pdf"),width=8,height=4)
ggplot(dddp[dddp$mois%in%c("11","12","01","02","03","04"),],aes(x=psf_l_cm))+
		geom_density(aes(y = ..density..,fill=mois),position="stack",alpha=1)+
		facet_grid(. ~ c_radius2,scales="free_x")+
		scale_fill_manual("Mois",values=mycolors(length(unique(dddp$mois))))+
		coord_flip()+theme_bw()+
		xlab("Taille (mm)")+ylab("classes de distance (densite)")+
		theme(
				axis.line = element_line(colour = "black", size = 0.2), 
				axis.text.x = element_text(size = 12 * 0.8, colour = 'white', lineheight = 0.9, vjust = 1), 
				axis.ticks = element_line(colour = "white", size = 0.2))
dev.off()

# même graphique pour la saison en cours....
pdf(file=str_c(imgwdy,"taille_dist_mois.pdf"),width=8,height=4)
ggplot(subset(dddp,dddp$mois%in%c("11","12","01","02","03","04") &	dddp$date>datedebut),aes(x=psf_l_cm))+
		geom_density(aes(y = ..density..,fill=mois),position="stack",alpha=1)+
		facet_grid(. ~ c_radius2,scales="free_x")+
		scale_fill_manual("Mois",values=mycolors(length(unique(dddp$mois))))+
		coord_flip()+theme_bw()+
		xlab("Taille (mm)")+ylab("classes de distance (densite)")+
		theme(
				axis.line = element_line(colour = "black", size = 0.2), 
				axis.text.x = element_text(size = 12 * 0.8, colour = 'white', lineheight = 0.9, vjust = 1), 
				axis.ticks = element_line(colour = "white", size = 0.2))
dev.off()



table(round(dddp$psf_l_cm),dddp$mois)

# nombre d'anguilles de plus de 1m
nrow(dddp[dddp$psf_l_cm>100,])/nrow(dddp) #2%

# correlation significative entre la taille et la distance
c_dddp<-cor.test(dddp$psf_radius_m,dddp$psf_l_cm) # highly significant

# efficacite


tab<-xtabs(count~psf_l_cl2+c_radius2,data=dddp)
# effectifs dans chaque classe taille*distance / effectif total par classe distance
mat<-matrix(rep(table(dddp$c_radius),length(levels(dddp$psf_l_cl))),
		nrow =length(levels(dddp$psf_l_cl)) , 
		ncol=length(levels(dddp$c_radius)), 
		byrow=T)
prop = as.matrix(xtabs(count~psf_l_cl+c_radius,data=dddp))/
		mat
##################################
# ANALYSE DES PROPORTIONS PAR MOIS
####################################
mois_taille = xtabs(count~psf_l_cl2+mois,data=dddp[dddp$date>datedebut,])
mois_taille_all = xtabs(count~psf_l_cl2+mois,data=dddp[,])



#plot(mois_taille)
mois_taille<-mois_taille[,colSums(mois_taille)!=0]
mois_taille_all<-mois_taille_all[,colSums(mois_taille_all)!=0]
chisq.test(mois_taille)
pdf(file=str_c(imgwdy,"mosaic_taille_mois_all.pdf"),width=6,height=6)
mosaic(mois_taille_all, shade= TRUE, colorize = T, gp = shading_hcl, gp_args = list(h = c(178, 10), c = 100, l = c(39, 67)))
#set.seed(rseed)
coindep_test(mois_taille_all, n = 5000) # another stat brought by monte carlo
dev.off()
#matplot(t(prop))
# references tailles >60
save(dddp, file = str_c(datawdy,"dddp1.Rdata"))
@
La qualité des anguilles détectées est notée par l'opérateur avec un facteur allant de 1 (très mauvaise qualité) à 5 (très bonne
qualité). Les images de qualité 1 sont écartées comme trop douteuses. L'analyse
de la qualité des anguilles en fonction de leur taille et de la distance de
détection montre des résultats cohérents lorsqu'on rassemble les images de
toutes les saisons (Figures \ref{qualite_distance_volet_all},
\ref{qualite_distance_vanne_all}):
\begin{itemize}
\item les effectifs diminuent avec la distance (largeur moins
grande des colonnes),  
\item plus on s'éloigne du didson plus la qualité des images détectées diminue,
\item la qualité est globalement meilleure en surface qu'au fond.
\end{itemize}
Pour la saison \Sexpr{saison} les détections sont majoritairement faites en
vannes. Dans ces conditions, les détections de petites anguilles $\tau$
<45cm~\text{mâles} et 45-60cm~\text{petites femelles} sont très réduites, et ces
effectifs faibles se traduisent dans le diagramme
\ref{qualite_distance_vanne_all} où dominent les anguilles de 60 à 80cm. On ne
retrouve pas comme l'année précédente, de moins bonnes qualités d'anguilles
détectées dans les deux premières classes de distance, mais une diminution
progressive de la qualité à mesure que l'on s'éloigne du didson ou que la
taille des anguilles diminue. Il est possible que les observations à grande
vitesse de courant aient été moins nombreuses. La fin des travaux sur la vanne
voisine a peut être également limité les écoulements turbulents en rive.




\begin{figure}[htbp]
        \centering
        \begin{subfigure}{0.5\textwidth}
                \centering
                \includegraphics[trim=2mm 2mm 2mm
                2mm,clip]{2022/qualite_distance2021-2022}%trim l b r t
                \hspace*{25mm}\caption{\small 2021-2022 \\
                N=\Sexpr{vvv$nqualite}\\
                Volets et vannes. Année en cours}
                \label{/qualite_distance2021-2022}
       \end{subfigure}%     
        \\
      \begin{subfigure}{0.45\textwidth}
                \centering
                \includegraphics[trim=2mm 2mm 2mm
                2mm,clip]{2022/qualite_distance_volet_all}%trim l b
                % r t
               \hspace*{25mm} \caption{\small surface \\
                $\delta$=5-15m \\
                N=\Sexpr{vvv$nqualiteallvolet}\\
               }
                \label{qualite_distance_volet_all}
        \end{subfigure}%
           \\
      \begin{subfigure}{0.45\textwidth}
                \centering
                \includegraphics[trim=2mm 5mm 5mm
                2mm,clip]{2022/qualite_distance_vanne_all}%trim l b r
                % t
               \hspace*{25mm} \caption{\small fond \\
                $\delta$=5-15m N=\Sexpr{vvv$nqualiteallvanne}
                }   
                \label{qualite_distance_vanne_all}
        \end{subfigure}
        \caption[Qualité.]{Qualité des détections en fonction des classes de
        distance. En haut données de l'année en cours, deux graphiques du bas
        groupement de l'ensemble des années disponibles. La taille verticale ou
        horizontale est relative à l'effectif dans chacune des catégories.
        Qualité 5 =pas de doute possible, qualité 1 = fort doute.}
       \label{qualite_distance}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Taille des anguilles et efficacité}\label{par_taille}

L'analyse de l'efficacite a été conduite sur l'ensemble des anguilles détectées
(\num{\Sexpr{round(nat,0)}}) en
fonction de la distance au didson et de la taille des anguilles. 
Les anguilles de plus petite taille sont clairement moins détectées loin du
didson (Figures \ref{taille_distance}, \ref{taille_dist_mois_all}).
La corrélation entre la taille des anguilles mesurées
et la distance d'observation est significative (Pearson
cor=\num{\Sexpr{round(c_dddp[["estimate"]],2)}}, p<0.001) (Figure
\ref{taille_dist_mois}).


%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/taille_distance}
  \caption[Taille des anguilles]{Taille des anguilles en fonction de la
  distance au sonar. Couleur en fonction du nombre d'observations par carré.
  Les polygones d'isodensité permettent de mettre en évidence la relation
  distance - taille (les plus petites anguilles ne sont visibles que près du
  didson). Les données correspondent à toutes les anguilles enregistrées depuis
  2012.}
  \label{taille_distance}
\end{figure}
%=====================================================================
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2022/taille_dist_mois_all}
  \caption[Taille des anguilles toutes années]{Structure de taille des anguilles
  en fonction de la distance au sonar et du mois pour l'ensemble des saisons de
  suivi depuis 2012-2013.}
  \label{taille_dist_mois_all}
\end{figure}
%=====================================================================
La comparaison de la distribution des tailles observées en fonction de la
distance au didson met clairement en avant l'arrivée de nombreuses anguilles
mâles qui n'avaient pas été observées jusqu'alors (Figures
\ref{taille_distance}, \ref{taille_dist_mois}).
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{2022/taille_dist_mois}
  \caption[Taille des anguilles \Sexpr{saison}]{Structure de taille des
  anguilles en \Sexpr{saison} en fonction de la distance au sonar et du mois.}
  \label{taille_dist_mois}
\end{figure}
%=====================================================================

% Ci dessous compte tenu des problèmes de détection pas utile d'analyser la taille au 
% cours de la saison.
Les tailles changent en fonction de la période (Test $\chi^2$ p<0.001) et les
petits mâles sont observés en début de saison. La Figure
\ref{mosaic_taille_mois} teste l'hypothèse que les classes de tailles soient distribuées de manière homogène en fonction des mois, de nouveau
en regroupant l'ensemble des années de suivi.
La couleur bleue indique qu'il y a plus d'anguilles dans une des classes que dans une
distribution homogène. On retrouve le fait qu'il y ait moins d'anguilles de
grande taille et plus d'anguilles de petite taille (mâles <45 mm) en début de
saison (Figure \ref{mosaic_taille_mois}).
\textit{A contrario}, les anguilles de plus petites tailles sont moins
nombreuses en décembre et janvier (en rouge). 

%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.45\textwidth]{2022/mosaic_taille_mois_all}
  \caption[Taille des anguilles]{Diagramme en mosaïque montrant la relation
  entre la taille et le mois. En rouge et bleu, les catégories qui sont
  significativement différentes au seuil de 90 et 99\%. L'ensemble des saisons
  de migration est analysé dans ce graphique.
  \citep{zeileis_ResidualbasedShadingsVisualizing_2007}.}
  \label{mosaic_taille_mois}
\end{figure}
%=====================================================================

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{\dimexpr.8pt+\fboxsep\relax}
\noindent       
\fbox{%
    \parbox{\linewidth-2\fboxsep-1.6pt}{%
    \parindent\defaultparindent%
    \indent 
La structure en \emph{taille} des anguilles varie en fonction de la distance au
didson. Les anguilles sont plus difficiles à détecter loin du didson.
L'efficacité de la détection est également plus faible pour les petites
anguilles.}}
\vspace{\dimexpr.8pt+\fboxsep\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<taille_volets, echo=FALSE, eval=TRUE,results=hide>>=
########################
# Données volets
########################

# il n'y a qu'une inclinaison -7 et une distance 5
pdf(file=str_c(imgwdy,"taille_distance_volet.pdf"))
grid.newpage()
vp<-viewport(layout=grid.layout(2,2,width=unit(c(0.8,0.2),"null"),
				height=unit(c(0.2,0.8),"null")))
vplayout <- function(x, y) { viewport(layout.pos.row = x, layout.pos.col = y)   }
pushViewport(vp)
g<-ggplot(dddpv,aes(x=psf_l_cm,y=psf_radius_m))+stat_bin2d(bins = 20)+
		geom_density2d(colour="yellow")+
		scale_x_continuous(limits=c(20,120))+
		theme(legend.key = element_rect(colour = NA, fill = 'grey20'),
				legend.position=c(0.9,0.8),
				legend.text = element_text(size = 10, colour = 'black'), 
				legend.title = element_text(size = 10, face = "bold", hjust = 0, colour = 'black'),
				legend.box='horizontal',
				legend.background = element_rect(colour = NA, fill = NA))	+
		scale_fill_gradient(low=bleu_EV, high=turquoise_EV)+
		ylab("distance d'observation (m)")+
		xlab("Taille anguille (cm)")+
		scale_x_continuous(limits=c(20,120))+
		scale_y_continuous(limits=c(5,15))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(2,1))
g<-ggplot(dddpv,aes(x=psf_l_cm))+geom_bar(colour=turquoise_EV)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(20,120))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(1,1))
g<-ggplot(dddpv,aes(x=psf_radius_m))+geom_bar(colour=turquoise_EV)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(5,15))+
		theme(plot.margin = unit(c(0,0,0,0), "cm"))+coord_flip()
print(g,vp=vplayout(2,2))
pushViewport(vplayout(1,1))
grid.text(str_c("N=",nrow(dddpv)), x=0.5, y=0.5, rot=0,
		gp=gpar(fontsize=20, col="#B3FFB3"))
upViewport()
pushViewport(vplayout(1,2))
grid.text(str_c("Surface \n -7° 5-15m"), x=0.5, y=0.5, rot=-45,
		gp=gpar(fontsize=20, col="black"))
dev.off()

#dddpv$mois<-strftime(dddpv$dsf_timeinit,'%m')
#dddpv$mois<-factor(dddpv$mois, levels=c("09","10","11","12","01","02","03","04"),
#		ordered =TRUE)
#dddpv<-dddpv[!is.na(dddpv$psf_l_cm)&dddpv$psf_l_cm>0,]
#dddpv$c_radius<-cut(dddpv$psf_radius_m,c(0,5,7,9,11,13,15)) #
#pdf(file=str_c(imgwdy,"taille_dist_mois_volet.pdf",width=8,height=4))
#ggplot(dddpf,aes(x=psf_l_cm))+stat_density(aes(ymax = ..density..,fill=mois),geom="ribbon",position="stack",alpha=1)+
#		facet_grid(. ~ c_radius2,scales = "free_y")+
#		scale_fill_manual("Mois",values=jet.colors(length(unique(dddpf$mois))))+
#		coord_flip()+theme_bw()+
#		xlab("Taille (mm)")+ylab("classes de distance")+
#		theme(
#				axis.line = element_line(colour = "black", size = 0.2), 
#				axis.text.x = element_text(size = 12 * 0.8, colour = 'white', lineheight = 0.9, vjust = 1), 
#				axis.ticks = element_line(colour = "white", size = 0.2))
#
#dev.off()
## effectifs dans chaque classe taille*distance / effectif total par classe distance
#tab<-xtabs(count~psf_l_cl2+c_radius2,data=dddpv)
##effectifs dans chaque classe taille*distance / effectif total par classe distance
#mat<-matrix(rep(table(dddpv$c_radius2),length(levels(dddpv$psf_l_cl2))),
#		nrow =length(levels(dddpv$psf_l_cl2)) , 
#		ncol=length(levels(dddpv$c_radius2)), 
#		byrow=T)
#prop = as.matrix(xtabs(count~psf_l_cl+c_radius,data=dddpv))/
#		mat
#matplot(t(prop))

#efficacite1 = prop[1,] / prop[1,1]
#efficacite2 = prop[2,] / prop[2,1]
#efficacite<-1/rbind(c(efficacite1),
#		c(efficacite2),
#		rep(1,5),
#		rep(1,5))
#dimnames(efficacite)<-dimnames(tab)
#tab_corrige<-tab*efficacite

##################################################
#sum(tab_corrige)-sum(tab)

@



<<taille_vannes_dddpf5, echo=FALSE, eval=TRUE,results=hide>>=


pdf(file=str_c(imgwdy,"taille_distance_vannefond.pdf"))
vplayout <- function(x, y) { viewport(layout.pos.row = x, layout.pos.col = y)   }
grid.newpage()
vp<-viewport(layout=grid.layout(2,2,width=unit(c(0.8,0.2),"null"),
				height=unit(c(0.2,0.8),"null")))
vplayout <- function(x, y) { viewport(layout.pos.row = x, layout.pos.col = y)   }
pushViewport(vp)
g<-ggplot(dddpf5,aes(x=psf_l_cm,y=psf_radius_m))+stat_bin2d(bins = 20)+
		geom_density2d(colour="yellow")+
		scale_x_continuous(limits=c(20,120))+
		theme(legend.key = element_rect(colour = NA, fill = 'grey20'),
				legend.position=c(0.9,0.8),
				legend.text = element_text(size = 10, colour = 'black'), 
				legend.title = element_text(size = 10, face = "bold", hjust = 0, colour = 'black'),
				legend.box='horizontal',
				legend.background = element_rect(colour = NA, fill = NA))	+
		scale_fill_gradient(low=bleu_EV, high=turquoise_EV)+
		ylab("distance d'observation (m)")+
		xlab("Taille anguille (cm)")+
		scale_y_continuous(limits=c(5,14))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(2,1))
g<-ggplot(dddpf5,aes(x=psf_l_cm))+geom_bar(colour=turquoise_EV,fill=rouille)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(20,120))+
		theme(plot.margin = unit(c(0,0.2,0,0), "cm"))
print(g,vp=vplayout(1,1))
g<-ggplot(dddpf5,aes(x=psf_radius_m))+geom_bar(colour=turquoise_EV, fill=rouille)+
		xlab("")+ylab("N")+scale_x_continuous(limits=c(0,14))+
		theme(plot.margin = unit(c(0,0,0,0), "cm"))+coord_flip()
print(g,vp=vplayout(2,2))
pushViewport(vplayout(1,1))
grid.text(str_c("N=",nrow(dddpf5)), x=0.5, y=0.5, rot=0,
		gp=gpar(fontsize=20, col="yellow"))
upViewport()
pushViewport(vplayout(1,2))
grid.text(str_c("+6° 2-12m"), x=0.5, y=0.5, rot=-45,
		gp=gpar(fontsize=20, col="black"))
dev.off()



#dddpf5$mois<-strftime(dddpf5$dsf_timeinit,'%m')
#dddpf5$mois<-factor(dddpf5$mois, levels=c("09","10","11","12","01","02","03","04"),
#		ordered =TRUE)
#dddpf5<-dddpf5[!is.na(dddpf5$psf_l_cm)&dddpf5$psf_l_cm>0,]
#dddpf5$c_radius<-cut(dddpf5$psf_radius_m,c(0,5,7,9,11,13,15)) #
#jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
#
#pdf(file=str_c(imgwdy,"taille_dist_mois_vannefond.pdf"),width=8,height=4)
#ggplot(dddpf5,aes(x=psf_l_cm))+stat_density(aes(ymax = ..density..,fill=mois),geom="ribbon",position="stack",alpha=1)+
#		facet_grid(. ~ c_radius,scales = "free_y")+
#		scale_fill_manual("Mois",values=jet.colors(length(unique(dddpf5$mois))))+
#		coord_flip()+theme_bw()+
#		xlab("Taille (mm)")+ylab("classes de distance")+
#		theme(
#				axis.line = element_line(colour = "black", size = 0.2), 
#				axis.text.x = element_text(size = 12 * 0.8, colour = 'white', lineheight = 0.9, vjust = 1), 
#				axis.ticks = element_line(colour = "white", size = 0.2))

#dev.off()

@




<<efficacite, echo=FALSE, eval=TRUE, results=hide>>=

# ce chunk attaque maintenant l'ensemble des années disponibles
# lancer le chunk loadrdata puis taille_all avant
load( file = str_c(datawdy,"dddp1.Rdata"))

dddp$year <- year(dddp$date)
dddp$month <- month(dddp$date)
dddp$saison <- str_c(dddp$year-1,"-",dddp$year)
dddp$saison[dddp$month>6]<-str_c(dddp$year,"-",dddp$year+1)[dddp$month>6]
dddp$distancestart <- 5
#dddp$psf_radius_m[dddp$psf_radius_m<=2.08]
#unique(dddp$dsf_distancestart)
#dddp$psf_radius_m[dddp$psf_radius_m<=3]
dddp$distancestart[dddp$dsf_distancestart<2.98] <- 3
dddp <- chnames(dddp, c("psf_l_cl2","c_radius2","dsf_position"), c("taille_cm","distance_m","position"))
dddp$taille_cm <- factor(dddp$taille_cm,ordered=TRUE)
dddp$distance_m <- factor(dddp$distance_m,levels=c("(2,5]","(5,7]","(7,9]","(9,11]","(11,13]","(13,15]"))
dddp$distance_m[dddp$distance_m=="(2,5]" & dddp$saison=="2014-2015"] <-"(5,7]" # début 2.98
#table(dddp$distancestart,dddp$distance_m,dddp$saison)

N <- dddp %>% 
		dplyr::group_by(saison,taille_cm,distance_m, position, distancestart) %>% 
		dplyr::summarize(N=sum(count),.groups="drop")
#N %>% print(n=500)
corrected<-
		rbind(
				data.frame("position"="volet",
						"corrected"=vvv$volet$det_frames_int_area/vvv$volet$det_frames_int_area[1],
						"distance_m"=c("(5,7]","(7,9]","(9,11]","(11,13]","(13,15]"),
						"distancestart"=5
				),
				data.frame("position"="volet",
						"corrected"=vvv$f3$det_frames_int_area/vvv$f3$det_frames_int_area[1],
						"distance_m"=c("(2,5]","(5,7]","(7,9]","(9,11]","(11,13]"),
						"distancestart"=3
				),
				data.frame("position"="vanne",
						"corrected"=vvv$f3$det_frames_int_area/vvv$f3$det_frames_int_area[1]
						,"distance_m"=c("(2,5]","(5,7]","(7,9]","(9,11]","(11,13]"),
						"distancestart"=3
				),
				data.frame("position"="vanne",
						"corrected"=vvv$f5$det_frames_int_area/vvv$f5$det_frames_int_area[1],
						"distance_m"=c("(5,7]","(7,9]","(9,11]","(11,13]","(13,15]"),
						"distancestart"=5
				)
		)

# joining with the previous table
N <- left_join(N,corrected,by=c("position","distance_m","distancestart"))
# 	after joining the factor is coerced back to a character for distance_m
N$distance_m <- factor(N$distance_m,levels=c("(2,5]","(5,7]","(7,9]","(9,11]","(11,13]","(13,15]"))
#print(N,n=500)
# correction (on va "augmenter" artificiellement les effectifs des zones plus proches car plus petites
N$NC <- N$N/N$corrected
# selection du max des Nombre corrigés de l'augmentation du rayon sur l'ensemble des 
# distances de détection
maxeff <- N %>% group_by(position, distancestart, saison,taille_cm) %>% dplyr::summarize(maxeff=max(NC, na.rm=TRUE),.groups="drop") 
N <- left_join(N,maxeff,by=c("position","taille_cm","distancestart","saison"))

########################
# QUALITE
######################

# A ce stade l'efficacité max est à 1 sur toutes les classes de tailles, or on sait qu'on aura plus
# de mal à détecter une anguille de 45 cm qu'une de 80.
# On utilise les données de qualité

# On calcule les effectifs par classe de qualité >4 et 5, pour les groupes taille*position

Nq <- dddp |> 
		mutate(q45=psf_q>3)%>%
		filter(!is.na(q45)) %>%
		group_by(taille_cm, position,q45,saison) %>% 
		summarize(N=n(),.groups="drop")
# on passe en format large pour avoir les deux colonnes côte à côte et calculer le ratio entre anguilles
# de qualité >=4 (4,5) et celles <3 (2,3)
Nq2 <- Nq %>% 
		pivot_wider(names_from="q45",names_prefix ="q45_",values_from="N") %>%
		mutate(ratio_qal=q45_TRUE/(q45_TRUE+q45_FALSE))

# la référence est la classe de taille (80,150] #  0.6875000 0.6614173 0.7901235 0.8510638
ref_volet <- Nq2 %>%
		filter(position=="volet" & taille_cm=="(80,150]" & !saison %in% c("2017-2018","2018-2019")) %>%
		pull(ratio_qal) %>%
		mean()
# on calcule le coefficient maximum d'efficacité (ratio_qal) par année, position, et classe de taille
Nq3 <- Nq2 %>%
		mutate(ratio_qal_cor=pmin(ratio_qal/ref_volet,1)) %>%
		select(taille_cm, position, ratio_qal_cor, saison)
# print(Nq3,n=Inf)
Nq3[is.na(Nq3$ratio_qal_cor),"ratio_qal_cor"] <-1
N <- left_join(N,Nq3,by = c("taille_cm", "position","saison"))

N$efficacite <- N$NC*N$ratio_qal_cor/N$maxeff


#N[is.na(N$efficacite),]

# Graphique des effectifs (traits plein) et effectif corrigés (traits pointillés)
# pour chaque classe de taille (couleur) et par classe de distance (axe x)
# les effectifs pour les classes les plus distantes sont divisées par la différence
# entre la surface de la zone et celle de la première zone : qu'est ce qu'on aurait eu si le faisceau
# avait été aussi étroit que sur la première zone ? On voit ça sur les traits en pointillés
# Si l'efficacité diminue de manière régulière, on s'attend a avoir une droite... Mais elle peut 
# diminuer seulement à partir d'un seuil ou même augmenter puis diminuer.
png(file=str_c(imgwdy,"nombre_taille_distance.png"),width=40,height=20, units = 'cm', res = 300)
N$distance_mc <- as.numeric(N$distance_m)
maxeffplot <- subset(N, NC==maxeff)

(N %>% 	
			ggplot()+
			geom_point(aes(x=distance_mc, y=maxeff), colour="black", pch=21, fill="yellow", size=4,
					data=maxeffplot)+
			geom_point(aes(x=distance_mc,y=N,colour=taille_cm,group=taille_cm))+
			geom_line(aes(x=distance_mc,y=N,colour=taille_cm,group=taille_cm))+
			geom_point(aes(x=distance_mc,y=NC,colour=taille_cm,group=taille_cm), pch=13)+
			geom_line(aes(x=distance_mc,y=NC,colour=taille_cm,group=taille_cm),lty=3)+
			scale_colour_manual("Classe taille",values=c(bleu_EV,turquoise_EV,orange_EV,jaune_EV))+
			scale_x_continuous(breaks=1:6,labels=levels(N$distance_m)) +
			facet_grid(position~saison+distancestart)+
			ylab("Nombre")+
			xlab("Classe de distance d'observation (m)")+
			theme_bw()+
			theme(panel.background = element_rect(fill = "grey95", 
							colour = "black"),
					axis.line=element_line(colour = "black"),
					panel.grid.major = element_line(colour = "grey99",size = 0.1),
					panel.grid.minor = element_line(colour = "white", size = 0.1)
			)
			)
dev.off()

#pdf(file=str_c(imgwdy,"efficacite_taille_volet.pdf"),width=8,height=4)
#(g<- 
#			N %>% filter(saison=="2019-2020" & position=="volet")	%>%
#			
#			ggplot()+
#			geom_point(aes(x=distance_m,y=N,colour=taille_cm,group=taille_cm))+
#			geom_line(aes(x=distance_m,y=N,colour=taille_cm,group=taille_cm))+
#			geom_point(aes(x=distance_m,y=NC,colour=taille_cm,group=taille_cm), pch=13)+
#			geom_line(aes(x=distance_m,y=NC,colour=taille_cm,group=taille_cm),lty=3)+
#			scale_colour_manual("Classe taille",values=c("#0080FF","#00FF00","red","brown"))+
#			theme_bw()+
#			ylab("Nombre")+
#			xlab("Classe de distance d'observation (m)")+
#			theme(panel.background = element_rect(fill = "grey95", 
#							colour = "black"),
#					axis.line=element_line(colour = "black"),
#					panel.grid.major = element_line(colour = "grey99",size = 0.1),
#					panel.grid.minor = element_line(colour = "white", size = 0.1)
#			)
#			)
#
#dev.off()

# Même graphique que pour les volets pour l'année en cours
#pdf(file=str_c(imgwdy,"efficacite_taille_f5.pdf"),width=8,height=4)
#(g<- 
#			N %>% filter(saison=="2019-2020", dsf_position=="vanne")	%>%
#			mutate(c_radius2=factor(c_radius2, levels=c("(5,7]","(7,9]","(9,11]","(11,13]","(13,15]"))) %>%
#			
#			ggplot()+
#			geom_point(aes(x=c_radius2,y=N,colour=taille_cm,group=taille_cm))+
#			geom_line(aes(x=c_radius2,y=N,colour=taille_cm,group=taille_cm))+
#			geom_point(aes(x=c_radius2,y=NC,colour=taille_cm,group=taille_cm), pch=13)+
#			geom_line(aes(x=c_radius2,y=NC,colour=taille_cm,group=taille_cm),lty=3)+
#			scale_colour_manual("Classe taille",values=c("#0080FF","#00FF00","red","brown"))+
#			theme_bw()+
#			ylab("Nombre")+
#			xlab("Classe de distance d'observation (m)")+
#			theme(panel.background = element_rect(fill = "grey95", 
#							colour = "black"),
#					axis.line=element_line(colour = "black"),
#					panel.grid.major = element_line(colour = "grey99",size = 0.1),
#					panel.grid.minor = element_line(colour = "white", size = 0.1)
#			)
#			)
#
#dev.off()
N$saison2 <- N$saison
N$saison2[N$saison2=="2012-2013"&N$distancestart==3]<-"2012-2013d3"
N$saison2[N$saison2=="2012-2013"&N$distancestart==5]<-"2012-2013d5"
N$saison2[N$saison2=="2013-2014"&N$distancestart==3]<-"2013-2014d3"
N$saison2[N$saison2=="2013-2014"&N$distancestart==5]<-"2013-2014d5"
ok <- complete.cases(N$saison2,N$taille_cm,N$distance_m,N$position,N$efficacite)
sum(!ok)

summary(gef0<-glm(efficacite~1,data=N),family="binomial",link="logit") 
summary(gef1<-glm(efficacite~taille_cm+distance_m,data=N),family="binomial",link="logit") 
summary(gef2<-glm(efficacite~taille_cm+distance_m+position,data=N),family="binomial",link="logit") 
summary(gef3<-glm(efficacite~taille_cm+distance_m+saison2,data=N),family="binomial",link="logit") 
summary(gef4<-glm(efficacite~taille_cm+distance_m+position+saison2,data=N),family="binomial",link="logit")
summary(gef5<-glm(efficacite~distance_m*taille_cm,data=N),family="binomial",link="logit") 
summary(gef6<-glm(efficacite~distance_m*taille_cm*saison2,data=N),family="binomial",link="logit") 
summary(gef7<-glm(efficacite~distance_m*taille_cm*position,data=N),family="binomial",link="logit") # AIC -361 BREAK
summary(gef8<-glm(efficacite~distance_m*taille_cm*position*saison2,data=N),family="binomial",link="logit")# BREAK
summary(gef9<-glm(efficacite~distance_m*taille_cm +position,data=N),family="binomial",link="logit")
summary(gef10<-glm(efficacite~distance_m*taille_cm+ saison2,data=N),family="binomial",link="logit") 
# problèmes de degrés de liberté
#summary(gef11<-glm(efficacite~distance_m*taille_cm+ saison2*position,data=N),family="binomial",link="logit")
summary(gef12<-glm(efficacite~distance_m*taille_cm+ saison2+ position,data=N),family="binomial",link="logit") # AIC  -372
summary(gef13<-glm(efficacite~distance_m*taille_cm*position+saison2,data=N),family="binomial",link="logit")# BREAK

ff <- function(x){
	capture.output(formula(eval(parse(text =x))))}
aic<- cbind(AIC(gef0,gef1,gef2,gef3,gef4,gef5,gef6,gef7,gef8,gef9,gef10,gef12,gef13),
		map_chr(.x=c("gef0","gef1","gef2","gef3","gef4","gef5","gef6","gef7","gef8","gef9","gef10","gef12","gef13"),.f=ff))
aic[order(aic$AIC),]
(aovlmsel<-as.data.frame(anova(gef12,test="Chisq")))
(pdev <- deviance(gef0)-deviance(gef12))/deviance(gef0) # le modèle explique 73 % de la déviance totale

anova(gef1,gef5,gef9,gef12,gef13,test="Chisq")

aovlmsel[,2]<-round(aovlmsel[,2],2)
aovlmsel[,3]<-round(aovlmsel[,3],2)
aovlmsel[,4]<-round(aovlmsel[,4],1)
aovlmsel[,5]<-scales::pvalue(aovlmsel[,5])
aovlmsel[,5] <- str_c("$",aovlmsel[,5],"$")
rownames(aovlmsel)
rownames(aovlmsel)<-c("$Resid.$","$\\delta$","$\\tau$","$saison$","$k (position)$","$\\delta*\\tau$")
colnames(aovlmsel)<-c("$df$","$dev.$","$res. df$", "$res. dev.$","$P(>chi^2$)$")
# le fichier est enregistré en UTF8
options(encoding = "UTF-8")
toto<-latex(aovlmsel,
		title="",
		where="htbp",
		col.just=strsplit("l r r r r r", " ")[[1]],	
		label="tab_aovefficacite",
		caption=str_c("Analyse de variance du modèle logit des efficacités. 
						$\\tau$= taille, $\\delta$= distance au didson"),
		caption.lot=str_c("aov efficacité"),		
		file=str_c(tabwdy,"aovefficacite.tex"))
options(encoding = "native.enc")
N$E <- NA # pour eviter warning
N$E[ok]<-predict(gef12,type="response")
N$E[N$E>1]<-1
N$E[N$E<0.02]<-0 # sinon extrapole terriblement...
N$label<-round(100*N$E)
N$label[N$E<1]<-round(100*N$E,1)[N$E<1]
#A ce stade je recalcule les effectifs corrigés en fonction de la régression
N$Ncor<-N$N/N$E
N$Ncor[is.na(N$Ncor)]<-0
N$Ncor[is.infinite(N$Ncor)]<-0
Ncorres<-tapply(N$Ncor,N$position,sum) # nombre estimés corrigés de l'efficacité


# pas d'interaction ave crPlots => je prends le modèle sans interactions
png(file=str_c(imgwdy,"aovefficacite.png"),width=20,height=20, units = 'cm', res = 300)
layout(matrix(c(1,2,3,0),2,2,byrow=TRUE))
crPlots(gef4,terms=~taille_cm,xlab="",ylab="Taille",las=2)
crPlots(gef4,terms=~distance_m,xlab="",ylab="Classe de distance au didson",las=2)
crPlots(gef4,terms=~position,xlab="",ylab="Position du didson")
dev.off()


#grandesf5<-sum(N[N$taille_cm=="(80,150]"&N$position=="fond5","Ncor"]) # 213
#moyennesf5<-sum(N[N$taille_cm=="(60,80]"&N$position=="fond5","Ncor"])  # 534
#petitesf5<-sum(N[N$taille_cm=="(45,60]"&N$position=="fond5","Ncor"])  # 534
#malesf5<-sum(N[N$taille_cm=="(0,45]"&N$position=="fond5","Ncor"])  # 534
#c1<-(moyennesf5/grandesf5)# 2.5
#c2<-(petitesf5/grandesf5) #2.03
#c3<-(malesf5/grandesf5) #0.93



png(file=str_c(imgwdy,"efficacite.png"),width = 35, height = 25, units = 'cm', res = 300)

g <-  ggplot(N, aes(y=taille_cm,x=distance_m))+
		geom_tile(aes(fill=E))+
		scale_fill_continuous(name="efficacite",low=orange_EV,high=turquoise_EV)+
		facet_wrap(~position+ saison2)+
		geom_text(aes(label=label))+
		theme_bw() +
		theme(panel.border = element_rect(colour = "black"),
				strip.background =  element_rect(colour = "black",fill="white"))+
		xlab(expression(delta (m)))+ylab(expression(tau (cm)))
print(g)
dev.off()
# ci dessous c'est la correction des effectifs observés en comptage
# pas le recalcul des effectifs qui va dépendre de l'efficacité moyenne 
# sur l'ensemble de la fenêtre de comptage.
# mais ça donne une idée....
png(filename=str_c(imgwdy,"Ncor.png"),width = 35, height = 25, units = 'cm', res = 300)
g <-  ggplot(N, aes(y=taille_cm,x=distance_m))+
		geom_tile(aes(fill=Ncor))+
		scale_fill_continuous(name="Ncor",low=bleu_EV,high=orange_EV)+facet_wrap(~position+ saison2)+
		geom_text(aes(label=round(Ncor)), colour="white")+
		theme_bw() +
		theme(panel.border = element_rect(colour = "black"),
				strip.background =  element_rect(colour = "black",fill="white"))+
		xlab(expression(delta (m)))+ylab(expression(tau (cm)))
print(g)
dev.off()

corr <- corrected %>% 
		rename("coef"="corrected")
corr%>%group_by(position) %>%summarize(coeffall=sum(coef)) # 8.33

# l'efficacite moyenne E est pondérée par la surface de chaque faisceau. E0 c'est avant correction (simple moyenne utilisée avant 2021)
efficacite_moyenne <-
		N %>% 
		group_by(saison, position) %>%
		left_join(corr) %>%
		summarize(E0=mean(E), E=sum(E*coef)/sum(coef), .groups="drop")
save(efficacite_moyenne, file=str_c(datawdy,"efficacite_moyenne.Rdata"))
#load(file=str_c(datawdy,"efficacite_moyenne.Rdata"))
options(encoding = "UTF-8")
xtaefficacite_moyenne <- xtable::xtable(efficacite_moyenne[,c("saison", "position", "E")],
		label="tabefficacite_moyenne",
		caption=iconv("Efficacité du didson (E) en fonction de la saison et de la position."),
		digits=2
)
print(xtaefficacite_moyenne, file=str_c(tabwdy,"tabefficacite_moyenne.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)	
options(encoding = "native.enc")

ggplot(efficacite_moyenne) + 
		geom_point(aes(x=saison,y=E,color=position)) +
		geom_line(aes(x=saison,y=E,color=position, group=position))

##################################
# Modélisation des efficacité par taille
####################################

centers <- tapply(dddp$psf_l_cm,dddp$taille_cm,mean)
# on calcule le ratio entre le nombre calculé et nombre par classe de taille par saison

# Calcul des effectifs et des effectifs "supplémentaires" créés par la correction d'efficacité
# je n'utilise par N et Ncor car là je n'ai plus le détail des tailles individuelles pour les histogrammes
EFT <- N %>% group_by(saison, taille_cm) %>% 
		summarize(coeff=sum(Ncor)/sum(N), .groups="drop") 
# calcul de la taille moyenne au sein de chaque classe de taille par année
#TM <- dddp %>% group_by(saison,taille_cm) %>% summarize(center=mean(psf_l_cm))
#EFT <- left_join(EFT,TM)

#ggplot(EFT) + 
#		geom_point(aes(x=center, y= coeff, color=saison))	+ 
#		geom_path(aes(x=center, y= coeff, color=saison, group=saison))

#######################
# structure en taille corrigée
#######################
C <- dddp %>% 
		select(psf_l_cm,  saison) %>%
		split( ~ saison) %>%
		#map( ~ max(x=.x$psf_l_cm))
		map(~hist(x=.x$psf_l_cm,plot=FALSE,breaks=c(20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,130))) %>%
		map_dfr(c("counts"))
C$taille <- c(20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120) # un de moins
C<-C %>% pivot_longer(cols=!taille, names_to="saison",values_to="N")
C$taille_cm <- cut(C$taille,c(0,45,60,80,150))
C$taille_cm <- factor(C$taille_cm,ordered=TRUE) # sinon le join ne marche pas
C1 <- inner_join(C, EFT,by=c("saison","taille_cm"))
C1$Ncor <- C1$N*C1$coeff-C1$N
C2 <- C1 %>% pivot_longer(cols=c("N","Ncor"),names_to="type",values_to="N")


C2$type <- factor(C2$type, levels=c("Ncor","N"))

pdf(str_c(imgwdy,"structure_taille.pdf"),width=5, height=5)
ggplot(C2) + 
		geom_col(aes(x=taille,y=N, fill=type)) +
		facet_wrap(~saison) + 
		scale_fill_manual(values=c(bleu_EV,turquoise_EV)) +
		labs(x="Classe de taille",
				y="Effectifs observés et corrigés de l'efficacité")
dev.off()
# travail sur les tailles à moins de 7 m de distance
resolution<-(c(2,5,7,9,11,13)/2)/96		
save(dddp, file= str_c(datawdy,"dddp_2.Rdata"))
save(efficacite_moyenne, file= str_c(datawdy,"efficacite_moyenne.Rdata"))
# efficacité moyenne en surface et au fond
vvv$efficacite$surface <-round(100*efficacite_moyenne[efficacite_moyenne$position=="volet" & efficacite_moyenne$saison==saison, "E0" ],1)
vvv$efficacite$fond <-round(100*efficacite_moyenne[efficacite_moyenne$position=="vanne" & efficacite_moyenne$saison==saison, "E0" ],1)
save(vvv,file=str_c(datawdy,"vvv.Rdata"))
@


<<qualite, echo=FALSE, eval=TRUE, results=hide>>=
load(file= str_c(datawdy,"dddp_2.Rdata"))

# 5 missing lines for brice and gerard together in 2012-2013 dddp[is.na(dddp$psf_q),]
dddp[is.na(dddp$psf_q),"psf_q"]<-3
dddp[dddp$psf_q==1 & !is.na(dddp$psf_q),]
# Volets
l.l <- list(set_varnames = c(psf_q="Qualite",
				distance_m="Classe de distance"))

png(file=str_c(imgwdy,"qualite_distance_volet_all.png"),width = 15, height = 8, units = 'in', res = 300)
vcd::mosaic(psf_q~taille_cm+distance_m,data=dddp,subset=dddp$position=="volet",
		split_vertical=c(TRUE,TRUE,FALSE),
		labeling_args = l.l)
vvv$nqualiteallvolet <- sum(dddp$position=="volet")
dev.off()

# Vannes
png(file=str_c(imgwdy,"qualite_distance_vanne_all.png"),width = 15, height = 8, units = 'in', res = 300)
vcd::mosaic(psf_q~taille_cm+distance_m,data=dddp,subset=dddp$position=="vanne",
		split_vertical=c(TRUE,TRUE,FALSE),
		labeling_args = l.l)
vvv$nqualiteallvanne <- sum(dddp$position=="vanne")
dev.off()

###########################
# Graphique de qualité par saison et position.
#########################
dddp1<-dddp
levels(dddp1$distance_m) <- c(3,6,8,10,12,14)
l.l <- list(set_varnames = c(psf_q="Qualite",
				distance_m="Centre de classe de distance (m)"))

for (s in 1:length(unique(dddp$saison))){
	saison1 <- unique(dddp1$saison)[s]
	png(filename=str_c(imgwdy,"qualite_distance",saison,".png"),width = 8, height = 8, units = 'in', res = 300)
	dddp1s <- dddp1[dddp1$saison==saison1,]
	if (saison1==saison) vvv$nqualite <- nrow(dddp1s)
	vcd::mosaic(psf_q~taille_cm+distance_m|position,data=dddp1s,
			split_vertical=c(FALSE,TRUE,TRUE,FALSE),
			labeling_args = l.l,
			main = str_c("qualite ",saison, " N=",nrow(dddp1s)))
	dev.off()	
}

save(vvv,file=str_c(datawdy,"vvv.Rdata"))

#Essai avec ggmosaic = bof, ne gère pas les facet_wrap et c'est ce que je voulais....
#library(ggmosaic)
#flights <- fly  %>%
#		filter(!is.na(do_you_recline), !is.na(rude_to_recline))
#
#
#dddp$psf_q <- factor(dddp$psf_q,levels=c("5","4","3","2","1"))
#levels(dddp$distance_m) <- c(3,6,8,10,12,14)
#levels(dddp$taille_cm) <- c("1m", "2f45","3f60","4f80")
#
#(dddp %>%filter(!is.na(psf_q)) %>%
#			ggplot() +
#			geom_mosaic(aes(x=product(psf_q, taille_cm, distance_m), fill = psf_q), divider = ddecker()) + 
#			scale_fill_grey(start = 0.2, end = 0.9)+
#			#scale_alpha_manual(values =c(.7,.9)) +
#			facet_wrap(~position) +
#			scale_y_reverse() +		
#			theme_bw() +
#			theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + 
#			labs(y="taille_cm", x="taille_cm - distance_m", title = "Double Decker Plot"))
#
#(dddp %>%filter(!is.na(psf_q)) %>%
# ggplot() +
#		geom_mosaic(aes(x=product(psf_q, taille_cm, distance_m), fill = psf_q), divider = ddecker()) + 
#		scale_fill_grey(start = 0.2, end = 0.9)+
#		#scale_alpha_manual(values =c(.7,.9)) +
#		facet_wrap(~saison) +
#		scale_y_reverse() +		
#		theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) + 
#		labs(y="taille_cm", x="taille_cm - distance_m", title = "Double Decker Plot"))



@

\subsubsection{Calcul de l'efficacité}\label{par_efficacite}

L'efficacité est calculée en
fonction de la distance au didson $\delta$, de la position vanne ou volet ($k$), 
et de la taille des anguilles $\tau$ (Formule \ref{eq_efficacite3}).
Toutes les variables sont traitées comme des facteurs qualitatifs. L'efficacité
est ensuite calculée à l'aide d'un modèle linéaire généralisé binomial (Formule \ref{eq_efficacite31}).
Le modèle retenu est le modèle  $\delta + \tau + k + saison + \delta*\tau$  
Il existe une interaction entre la taille et la
distance ($\delta*\tau$) (Figure \ref{aovefficacite}, Tableau
\ref{tab_aovefficacite}). En d'autres termes, en plus d'un effet direct de
la taille pour l'efficacité, la réponse en fonction de la distance dépend de la
taille. 
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.45\textwidth]{2022/aovefficacite}
  \caption[AOV efficacité]{Prédictions et résidus de la modélisation linéaire
  de l'efficacité du didson, en fonction de la taille et de la distance au
  didson, pour les deux positions du sonar en fin de saison. Attention il
  existe en plus une interaction entre la taille et la distance, cet effet est
  ignoré ici.}
  \label{aovefficacite}
\end{figure}
%=====================================================================
Pour l'ensembles des années, les diminutions d'effectifs en fonction de la
distance au didson sont résumées en figure \ref{nombre_taille_distance},  
les efficacités sont calculées
en figure \ref{efficacite} et les nombres corrigés issus du recalcul sont
présentés en figure \ref{Ncor} et
\ref{efficacite} (les trois figures sont en annexe).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{\dimexpr.15pt+\fboxsep\relax}
\noindent       
\fbox{%
    \parbox{\linewidth-2\fboxsep-1pt}{%
    \parindent\defaultparindent%
    \indent 
L'efficacité moyenne (Formule \ref{eq_efficacite32}) est de
\num{\Sexpr{vvv$efficacite$surface}}\% en surface et
\num{\Sexpr{vvv$efficacite$fond}}\% au fond.}
}
%\vspace{\dimexpr.8pt+\fboxsep\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Migration}
\subsubsection{Migration en fonction du cycle nycthéméral}
<<horaires, echo=FALSE, eval=TRUE,results=hide>>=
#ATTENTION IL FAUT PASSER PAR LE CHUNK loadrdata pour créer xmin xmax....

dddee<-merge(ddde,eph,by="date",all.x=TRUE,all.y=FALSE) #3476
dddee$date<-strptime(str_c(dddee$date," 00:00:00"),format="%Y-%m-%d %H:%M:%S")
#dddee
#didsonfile
# didsonread
# didsonreadresult
#envinoment
#ephemeride
# ci dessous j'utilise des rectangles, c'est la partie horizontale....
#dddee$Hdeb<-strptime(strftime(dddee$dsf_timeinit,"%H:%M"),"%H:%M")
#dddee$Hfin<-strptime(strftime(dddee$dsf_timeend,"%H:%M"),"%H:%M")
twi<-6/180*12
dddee$lever_twilight<-dddee$lever_soleil_h-twi
dddee$coucher_twilight<-dddee$coucher_soleil_h+twi
dddee$date <- as.POSIXct(dddee$date)
#g<-ggplot(dddee)+geom_rect(aes(xmin=xmin,xmax=xmax,ymin=Hdeb,ymax=Hfin))+
#		geom_point(aes(x=date,y=lever_soleil_h),colour="blue",data=eph)+
#		geom_point(aes(x=date,y=coucher_soleil_h),colour="red",data=eph)

dddee<-dddee[(dddee$Hfin-dddee$Hdeb)>0,]
pdf(file=str_c(imgwdy,"horaires_all.pdf"),width=7,height=7)
g<-ggplot(dddee)+
		geom_rect(aes(xmin=xmin,xmax=xmax,ymin=Hdeb,ymax=Hfin,fill=Hdeb))+
		scale_fill_gradient2("heure",low = bleu_EV, mid = "#D4D4FA", high ="#380071" ,midpoint=12,space = "Lab")+
		geom_path(aes(x=date,y=lever_soleil_h),colour="yellow",data=dddee,alpha=0.6,size=2)+
		geom_path(aes(x=date,y=coucher_soleil_h),colour="yellow",data=dddee,alpha=0.6,size=2)+
		geom_path(aes(x=date,y=lever_twilight),colour=orange_EV,data=dddee,alpha=0.8,size=1,lty=2)+
		geom_path(aes(x=date,y=coucher_twilight),colour=orange_EV,data=dddee,alpha=0.8,size=1,lty=2)+
		scale_y_continuous(breaks=seq(1, 24, 2), minor_breaks = seq(1, 24, 0.5))+
		ylab("Heure")+theme(panel.background = element_rect(fill="black"),
				panel.grid.major = element_line(colour = "grey50"),
				panel.grid.minor = element_line(colour = "grey20"),
				axis.text = element_text(colour ="black"))
print(g)
dev.off()

pdf(file=str_c(imgwdy,"horaires.pdf"),width=7,height=7)
g <- dddee %>% filter(dsf_season==saison)%>%
		ggplot()+
		geom_rect(aes(xmin=xmin,xmax=xmax,ymin=Hdeb,ymax=Hfin,fill=Hdeb))+
		scale_fill_gradient2("heure",low = bleu_EV, mid = "#D4D4FA", high ="#380071" ,midpoint=12,space = "Lab")+
		geom_path(aes(x=date,y=lever_soleil_h),colour="yellow", alpha=0.6, size=2)+
		geom_path(aes(x=date,y=coucher_soleil_h),colour="yellow", alpha=0.6, size=2)+
		geom_path(aes(x=date,y=lever_twilight),colour=orange_EV, alpha=0.8, size=1,lty=2)+
		geom_path(aes(x=date,y=coucher_twilight),colour=orange_EV, alpha=0.8, size=1,lty=2)+
		scale_y_continuous(breaks=seq(1, 24, 2), minor_breaks = seq(1, 24, 0.5))+
		ylab("Heure")+theme(panel.background = element_rect(fill="black"),
				panel.grid.major = element_line(colour = "grey50"),
				panel.grid.minor = element_line(colour = "grey20"),
				axis.text = element_text(colour ="black"))
print(g)
dev.off()


dddee$nuit <- dddee$Hdeb>dddee$coucher_soleil_h|dddee$Hfin<dddee$lever_soleil_h
# using lubridate
dddee$hour <- hour(dddee$dsf_timeinit)
dddee$neel <- dddee$drr_eelplus+dddee$drr_eelminus
dddee$count <- 1 
njoursuivi <- length(unique(ddde$date)) # 119
#dddee[,c("date","Hdeb","Hfin")][dddee$Hfin-dddee$Hdeb<0,]

#########################################################
# Extraction d'un tableau de données contenant les jours complets
#########################################################
# f = fulldays 
fulldays<-as.POSIXct(strptime(str_c(fulldays," 00:00:00"),format="%Y-%m-%d %H:%M:%S"))
dddeef <- dddee[dddee$date%in%fulldays,c("date",
				"dsf_timeinit",
				"dsf_position",
				"lever_soleil_h",
				"coucher_soleil_h",
				"Hdeb",
				"Hfin",
				"drr_eelplus",
				"drr_eelminus",
				"vanne4",
				"volet4",
				"nuit",
				"neel",
				"hour","count")]
nhf <- data.frame(h=names(tapply(dddeef$neel,dddeef$Hdeb,sum,na.rm=TRUE)),
		n=tapply(dddeef$neel,dddeef$Hdeb,sum,na.rm=TRUE))
nhf$h <- as.numeric(as.character(nhf$h))
#d3ej corresponds to <=9 and >17 so the day no watched values correspond to

# PARAMETRE DU MODELE : perchf917> mu > muinv
mu <- round(100*sum(nhf$n[nhf$h>9 & nhf$h<=17])/sum(nhf$n),1)
perchfj <- round(100*sum(dddeef$neel[!dddeef$nuit],na.rm=TRUE)/sum(dddeef$neel,na.rm=TRUE),1)
dddeef <- dddeef[rev(order(dddeef$nuit)),]
nb_suivi_h <- tapply(dddeef$count,dddeef$Hdeb,sum,na.rm=TRUE)
nb_suivi_h <- 48*nb_suivi_h/sum(nb_suivi_h) # 24 au total
# on s'attend a avoir moins d'anguilles les heures sans suivi. Ici on calcule
# le nombre moyen d'anguilles par suivi.
dat_h <- data.frame("hour"=as.numeric(names(tapply(dddeef$neel,dddeef$Hdeb,sum,na.rm=TRUE))),
		"ncor"=tapply(dddeef$neel,dddeef$Hdeb,sum,na.rm=TRUE)/
				nb_suivi_h)
# migration de 9h inclus à 17 h
muobs <- round(100*sum(dat_h[dat_h$hour>9&dat_h$hour<=17,"ncor"])/sum(dat_h$ncor),1)
mu  <-  muobs # cette année on utilise la valeur observée
dddeef$hourm <- dddeef$hour
dddeef$hourm[dddeef$hourm<=9] <- 24+dddeef$hourm[dddeef$hourm<=9]
dddeef$hourm <- dddeef$hourm-min(dddeef$hourm)# 0 à 17h00
dddeef$nuit[dddeef$nuit] <- "couché"
dddeef$nuit[dddeef$nuit=="FALSE"] <- "levé"
#§§§§§§§§COMMENTE POUR GAGNER DU TEMPS §§§§§§§§
png(file=str_c(imgwdy,"heure_jourcomplet.png"), width=12,height=12, units = 'cm', res = 300)
g <- ggplot(dddeef, aes(x = hourm, fill = nuit)) + 
		geom_histogram(aes(y=neel),breaks = seq(0,24), width = 0.6, colour = NA,stat="identity") +
		coord_polar(start=3*pi/4) +
		theme_minimal() + 
		scale_fill_manual("Soleil",values=c("couché"=bleu_EV,"levé"=orange_EV)) +
		ylab("Nombre") + 
		scale_x_continuous("", limits=c(0,24), breaks = seq(0, 23), labels = c(seq(9, 23),seq(0,8)))
print(g)
dev.off()
#Fonctionnement jour nuit du barrage
png(file=str_c(imgwdy,"fonctionnement_journuit_barrage.png"), width=15,height=10, units = 'cm', res = 300)
dddeef$ouverture_barrage <- "ferme"
dddeef$ouverture_barrage[dddeef$volet4] <- "volet (surface)"
dddeef$ouverture_barrage[dddeef$vanne4] <- "vanne (fond)"
dddeef %>% filter(!is.na(ouverture_barrage)) %>%
		group_by(hour,nuit,ouverture_barrage) %>% summarize(count=sum(count)) %>% 
		ggplot(aes(x = hour, fill = nuit)) + 
		geom_histogram(aes(y=count),breaks = seq(0,24), width = 1, colour = "grey20",stat="identity") +
		coord_polar(start = 0) +
		theme_minimal() + 
		scale_fill_manual("Nuit",values=c("couché"=bleu_EV,"levé"=orange_EV)) +
		ylab("Nombre") + 
		ggtitle("Fonctionnement barrage") + 
		scale_x_continuous("",  breaks = seq(0, 23), labels = seq(0, 
						23))+
		facet_wrap(~ouverture_barrage)
dev.off()
#########################################################
# Sur toute la série mais entre 8 h00 et 18 h00
#########################################################
d3e2j <- dddee[dddee$hour>17|dddee$hour<=9,] 
d3e2j$hourm <- d3e2j$hour
d3e2j$hourm[d3e2j$hourm<=9] <- 24+d3e2j$hourm[d3e2j$hourm<=9]
d3e2j$hourm <- d3e2j$hourm-8 # 0 à 18h00
d3e2j$nuit[d3e2j$nuit] <- "couché"
d3e2j$nuit[d3e2j$nuit=="FALSE"] <- "levé"
d3e2j <- d3e2j[!is.na(d3e2j$dsf_position),]


########################
# JOURS COMPLETS TRAVAIL SUR LA DENSITE
##########################
# il faut une ligne par poissons
dddp <- dddp[!is.na(dddp$dsf_id),]
dddp$date <- as.Date(dddp$dsf_timeinit)
dddpf <- dddp[dddp$date%in%as.Date(fulldays),]


dddpf$hour <- hour(dddpf$dsf_timeinit)
dddpf$hourc <- circular(dddpf$hour%%24, # convert to 24 hrs
		units="hours", template="clock24")
bw <- 10*bw.nrd0(dddpf$hourc) 
dens <- density.circular(dddpf$hourc, bw = bw)  # bw must be given
pdf(file=str_c(imgwdy,"circular_full_days.pdf"),width=8,height=6)
plot(dens, plot.type = "line", join = TRUE, main = iconv("Probability de présence d'anguille en fonction de l'heure","UTF8"), 
		xlab = "Heure", ylab = "", yaxt = "n")
dddee$hm <- as.numeric(strftime(dddee$dsf_timeinit,"%H"))+as.numeric(strftime(dddee$dsf_timeinit,"%M"))/60

rug(jitter(dddpf$hour,amount=0.05),ticksize=0.03,lwd=0.1)
dev.off()
#########################################################
# circular density 
#########################################################
dddp$hour <- hour(dddp$dsf_timeinit)
d3pj <- dddp[dddp$hour>17|dddp$hour<=9,] 
d3pj$hourc <- circular(d3pj$hour%%24, # convert to 24 hrs
		units="hours", template="clock24")
bw <- 10*bw.nrd0(d3pj$hourc) 
dens <- density.circular(d3pj$hourc, bw = bw)  # bw must be given
pdf(file=str_c(imgwdy,"circular_9-17.pdf"),width=8,height=6)
plot(dens, plot.type = "line", join = TRUE, main = iconv("Probability de présence d'anguille en fonction de l'heure","UTF8"), 
		xlab = "Heure", ylab = "", yaxt = "n")
rug(jitter(d3pj$hour,amount=0.05),ticksize=0.03,lwd=0.1)
dev.off()
#########################################################
# TABLEAU
#########################################################
# Effectifs corrigés des ouvertures de vanne
# dddeef pour tableaux avec les jours complets
require(dplyr)
nhours <- dddeef%>%dplyr::select(hour)%>%distinct()%>%nrow()


# proportion des suivis effectués par rapport à l'ensemble, calculés par heure 
# (si tous les suivis sont également répartis on obtient 1/24 donc on multiplie par 24
dat_h_fulldays  <-  dddeef %>% 
		dplyr::select(count,hour,neel)%>%
		group_by(hour)%>%
		dplyr::summarize(nb_suivi_h=dplyr::n(),n=sum(neel,na.rm=TRUE))%>%
		ungroup()%>%
		mutate(nb_suivi_h=24*nb_suivi_h/sum(nb_suivi_h))%>%
		mutate(ncor=n/nb_suivi_h)%>%
		select(-nb_suivi_h)

dat_h_all <- d3e2j %>% 
		dplyr::select(count,hour,neel)%>%
		dplyr::group_by(hour)%>%
		summarize(nday=sum(neel,na.rm=TRUE))%>%
		ungroup()

dat_h <- full_join(dat_h_fulldays, dat_h_all)

colnames(dat_h)<-c("heure","24 h","24 h cor.","nuit")
somme<-colSums(dat_h,na.rm=TRUE)
somme[1]<-NA
dat_h<-rbind(dat_h,somme)
dat_h<-as.data.frame(dat_h)
dat_h<-dat_h[order(dat_h$heure),]
rownames(dat_h)[nrow(dat_h)]<-"Somme"
dat_h<-dat_h[,-1]
#barplot(dat$ncor)
options(encoding = "UTF-8")
xdat_h<-xtable(dat_h,
		label="repartition_horaire",
		caption=c(str_c("Répartition horaire des anguilles détectées au didson, 
								nuit = suivi ",njoursuivi," jours toute la saison entre 18h 00 et 9h00 ,
								24 h=répartition pour les ",length(fulldays)," jours de suivi complet,
								24 h cor= idem mais valeurs corrigées des ouvertures de vannes."),"Répartition
						horaire des anguilles détectées au didson."),
		digits=0
)
print(xdat_h,file=str_c(tabwdy,"repartition_horaire.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)
options(encoding = "native.enc")

@
<<horairespb, echo=FALSE, eval=TRUE,results=hide>>=
### Horaires avec fichiers à pb
d3ej$ouverturebarrage<-d3ej$vanne1|d3ej$vanne2|d3ej$vanne3|d3ej$vanne4|d3ej$vanne5|
		d3ej$volet1|d3ej$volet2|d3ej$volet3|d3ej$volet4|d3ej$volet5
# flsall = fls 0 
#0;"OK"
#1;"Acquisition"
#2;"Ecriture"
#3;"Qualité"

d3ej$flsall <- d3ej$dsf_fls_id
d3ej$flsall[d3ej$flsall==0 & !indexOK] <- 4
#4;"Mauvais positionnement"
d3ej$flsall[d3ej$optvanne4=="0" & !d3ej$ouverturebarrage] <- 5
#5 La vanne est fermée mais le barrage aussi
d3ej$flsall[is.na(d3ej$flsall)] <- 6
#6 NA pas de données
#open_in_excel(d3ej)
first_year <- 2013
for (i in 1:length(unique(d3ej$dsf_season))){
	saison1 <- unique(d3ej$dsf_season)[i]
	if (i ==1) the_year <- first_year else the_year=the_year+1
	png(file=str_c(imgwd,the_year,"/horairespb.png"),width = 15, height = 15, units = 'cm', res = 300)
	g <- ggplot(d3ej[d3ej$dsf_season==saison1,])+
			geom_rect(aes(xmin=xmin,xmax=xmax,ymin=Hdeb,ymax=Hfin,fill=factor(flsall)))+#"yellow"
			scale_fill_manual("qualité",values=c("0"=turquoise_EV,"1"=jaune_EV,"2"="limegreen","3"=orange_EV,"4"=rouille,"5"="grey"))+ # ajouter orange derrière yellow si pb qualité
			ylab("Heure")+theme(panel.background = element_rect(fill="black"),
					panel.grid.major = element_line(colour = "grey50"),
					panel.grid.minor = element_line(colour = "grey20"),
					axis.text = element_text(colour ="black"))
	print(g)
	dev.off()
}
@

Le suivi des migrations a été effectué entre 17 h et 9 h (Figure
\ref{h_fonct}). 


\begin{figure}[htbp]
        \centering        
        \begin{subfigure}{0.4\textwidth}
                \centering
                \includegraphics[trim=0mm 15mm 0mm
                15mm,clip]{2021/heure_jourcomplet.png}
                \caption{Horaires de passages toutes saisons}
           \label{fig_heure_jourcomplet}
        \end{subfigure}
        \begin{subfigure}{0.55\textwidth}
                \centering
                \includegraphics{2022/fonctionnement_journuit_barrage.png} 
                \caption{heures de fonctionnement du barrage.}
        \label{fig_fonctionnement_journuit_barrage}
        \end{subfigure}
         \begin{subfigure}{0.4\textwidth}
                \centering
                \includegraphics{2022/circular_full_days} 
                \caption{modèle circulaire.}
        \label{fig_circular_full_days}
        \end{subfigure}
        \caption[Horaires de  passage]{Horaires de passage des anguilles 
        en fonction de l'alternance jour nuit (voir Figure \ref{fig_heure_jourcomplet}), 
        (a) pour les \Sexpr{length(fulldays)} jours où un suivi de 24 h a été
                effectué sur l'ensemble des saisons, 
        (b) fonctionnement du barrage pour ces mêmes jours,
        (c) modélisation des effectifs horaires par un modèle circulaire.}
        \label{h_pass}
        % heure de passage
\end{figure}

En compilant l'ensemble des saisons avec des suivis toute la journée, nous
disposons de \num[round-mode = places,
 round-precision = 0]{\Sexpr{length(fulldays)}} journées pour lesquelles le
suivi a été effectué au delà de ces heures. Le pourcentage d'anguilles migrant
de 9h30 à 17h30 est de mu=\Sexpr{mu} \footnote{Les deux années
2013--2014 et 2014--2015, un coefficient de $\mu$ =  11.9\% avait été
utilisé \citep{briand_suivi_2015, briand_suivi_2016}, 
puis une valeur de 5.6 \%.} (Figure\ref{fig_heure_jourcomplet}).


Sur les périodes sur lequelles le dépouillement complet a été effectué, il
n'est pas évident qu'il y ait un biais lié à des ouvertures du barrage plus
importantes à certaines heures (Figure \ref{fig_fonctionnement_journuit_barrage}).


Une modélisation prenant en compte le caractère circulaire des données conduit
aux résultats Figure \ref{fig_circular_full_days} avec un pic de passage vers 21
h Figure \ref{h_pass}, Tableau \ref{repartition_horaire}.


\input{../../../pdata/didson/rapport/table/2022/repartition_horaire.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{\dimexpr.8pt+\fboxsep\relax}
%\noindent       
%\fbox{%
%    \parbox{\linewidth-2\fboxsep-1.6pt}{%
%    \parindent\defaultparindent%
%    \indent 
%Les migrations sont essentiellement nocturnes avec une migration entre 9h30 et
%17h00 (inclus) de \Sexpr{muobs}\%.. 
%}}
%\vspace{\dimexpr.8pt+\fboxsep\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Comportement de migration}
<<comportement, echo=FALSE,eval=TRUE,results=hide>>= 
load(file= str_c(datawdy,"dddp_2.Rdata")) # dddp après traitement dans efficacité
perctrav <- round(100*sum(table(dddp$psf_move)[1])/sum(table(dddp$psf_move))) # 32% des anguilles traversent
#(table(dddp$psf_move,taille_composition)/colSums(table(dddp$psf_move,dddp$dsf_position)))
#xtabs(count~taille_cm+psf_motion+mois+saison,data=dddp)
dddp[is.na(dddp$psf_move),"psf_move"]<-"<-->"
dddp[dddp$psf_move=="?","psf_move"]<-"<-->"

dddp[is.na(dddp$psf_motion),"psf_motion"]<-"Running"
dddp$psf_motion<-as.factor(dddp$psf_motion)
levels(dddp$psf_motion)<-c("A","R","M") # a=arrière Reste (hanging) M migration (Running)
(ta<-table(dddp$psf_motion,dddp$psf_move))
table(dddp$psf_motion,dddp$psf_move,dddp$psf_dir)

sum(ta)#1739
chisqta<-chisq.test(ta,simulate.p.value = TRUE)# 0.0001

long.labels <- list(set_varnames = c(psf_motion="Migration horizontale",
				psf_move="Migration verticale"))
pdf(file=str_c(imgwdy,"comportement.pdf"),width=4,height=4)
mosaic(psf_move~psf_motion,shade=TRUE,gp = shading_Friendly,data=dddp,labeling_args = long.labels) 
#mosaic(psf_move~psf_motion,shade=TRUE,gp = shading_Friendly,data=dddp[dddp$mois=="04",],labeling_args = long.labels) 
dev.off()
options(encoding = "UTF-8")
xta <- xtable(ta,
		label="tab_comportement",
		caption=c(
				"Effectifs de comportements observés en surface et en vanne,
						A migration en arrière, R reste sur place, M migration active vers l'aval,
						<--> traversée complète,
						In entrée par le dessus ou le dessous,
						Out sortie par le dessus ou le dessous"
				,"Comportement des anguilles au droit du sonar")
)
print(xta, file=str_c(tabwdy,"comportement.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)
options(encoding = "native.enc")
ta0 <- table(dddp$psf_move,dddp$position)
ta1<-ta0/matrix(rep(
				colSums(table(dddp$psf_move,dddp$position)),nrow(ta0)),nrow=nrow(ta0),byrow=TRUE)
Nvanne <- colSums(table(dddp$psf_move,dddp$position))[1]
Nvolet <- colSums(table(dddp$psf_move,dddp$position))[2]
ta1 <- round(100*ta1)
colnames(ta1) <- c("fond","surface")
options(encoding = "UTF-8")
xta1 <- xtable(ta1,
		label="tab_traversee",
		digits=0,
		caption=c(
				str_c("Pourcentage d'anguilles effectuant la traversée du faisceau, <--> traversée complète,
								In entrée par le dessus ou le dessous,
								Out sortie par le dessus ou le dessous,
								N vanne=",Nvanne,", N volet=",Nvolet,"."),
				"Traversée du faisceau en surface et au fond")
)
print(xta1,file=str_c(tabwdy,"traversee.tex"),
		table.placement="htbp",
		caption.placement = "top",
		NA.string = "",
		include.rownames=TRUE)
options(encoding = "native.enc")
graphics.off()

@
Les différents comportements de nage, et de traversée du faisceau, sont décrits
en matériel et méthodes (paragraphe \ref{par_depouillement}). Il semble y avoir
un effet du type de nage sur la probabilité qu'une anguille traverse tout l'écran ($\chi ^2$
p=\textcolor{grisbleufonce}{\Sexpr{round(chisqta[["p.value"]],3)})}.
Les anguilles en nage à contre courant ont en effet une probabilité plus forte que les autres de
rentrer dans le faisceau. La proportion d'anguilles effectuant une 
traversée complète
(\textcolor{grisbleufonce}{\Sexpr{round(perctrav)}}\%) est faible ce qui indique une prospection verticale de la colonne d'eau par les anguilles. Comme pour les
 autres saisons, cette prospection est plus importante lorsque le didson
est positionné en surface (Tableau \ref{tab_traversee}).
\input{../../../pdata/didson/rapport/table/2022/comportement.tex}
\input{../../../pdata/didson/rapport/table/2022/traversee.tex}

%\begin{figure}[htbp]
%  \centering
%  \includegraphics[width=0.4\textwidth]{comportement}
%  \caption[comportement des anguilles]{diagramme de visualisation des effectifs en
%  fonction du comportement de nage horizontale et verticale.
%  $A$=Descente tête vers l'arrière, $H$=l'anguille reste devant le
%  didson, $M$=Migration,$<-->$ l'anguille effectue l'ensemble de sa traversée dans
%  l'intervalle vertical du faisceau du sonar, $In$ l'anguille entre dans le
%  faisceau par-dessus ou dessous, $InOut$ l'anguille rentre et ressort, $Out$ l'anguille sort du faisceau}
%  \label{comportement}
%\end{figure}
\subsubsection{Biomasses et sexe ratios}
\label{parpoids}
<<biomasse, echo=FALSE, eval=TRUE,results=hide>>=
load("C:/workspace/pdata/devalpomi/ang_laurent/data/big_anguille.RData")
# NLS
# La proc nls ne donne pas pour l'instant d'intervalle de confiance (pointwise) de la prédiction
# Il faut recourir à du bootstrap.....
#mod<-nls( lo_poids~ A*lo_taille^3,data=big_anguille)
#summary(mod)
#confint(mod, parm, level = 0.95,parm="A")
#big_anguille$prednls<-predict(mod, se.fit = TRUE) # se.fit currently ignored
# ci dessous ne donne pas grand chose
#big_anguille$prednlslowIC<-confint(mod, parm, level = 0.95,parm="A")[1]*(big_anguille$lo_taille)^3
#big_anguille$prednlshighIC<-confint(mod, parm, level = 0.95,parm="A")[2]*big_anguille$lo_taille^3

big_anguille$taille3<-(big_anguille$lo_taille/1000)^3
# plot(taille3~lo_poids,data=big_anguille) une droite

rlmmodb<-MASS::rlm(lo_poids~0+taille3,data=big_anguille)
summary(rlmmodb)
pred <- predict(rlmmodb,se.fit=TRUE,type="response",interval="prediction")
big_anguille$predlm<-pred$fit[,1]
big_anguille$predlowIC<-pred$fit[,2]
big_anguille$predhighIC<-pred$fit[,3]

# Données Vilaine
datvil<-read.table(str_c(datawd,"taille_poids_vilaine.csv"),header=TRUE,sep=";")
datvil$taille3<-(datvil$taille/1000)^3
lmmod<-lm(poids~0+taille3,data=datvil)
rlmmod<-rlm(poids~0+taille3,data=datvil) # robust prediction
summary(rlmmod)
summary(lmmod)
pred<-predict(rlmmod,se.fit=TRUE,type="response",interval="prediction")
datvil$predlm<-pred$fit[,1]

datvil$predlowIC<-pred$fit[,2]
datvil$predhighIC<-pred$fit[,3]
pdf(file=str_c(imgwd,"taille_poids.pdf"))
g<-ggplot(big_anguille[!big_anguille$a_exclure_poids&!big_anguille$a_exclure_taille,])
g<-g+geom_ribbon(aes(x=lo_taille,ymin=predlowIC,ymax=predhighIC),fill="limegreen",alpha=0.5)+
		geom_point(aes(x=lo_taille,y=lo_poids),col="darkgreen")+
		#geom_line(aes(x=lo_taille,y=prednls),col="blue")+ # NLS
		#geom_line(aes(x=lo_taille,y=prednlslowIC),col="skyblue",tly=2)+ # NLS
		#geom_line(aes(x=lo_taille,y=prednlshighIC),col="skyblue",lty=2)+ # NLS
		geom_line(aes(x=lo_taille,y=predlm),col="green")+
		geom_point(aes(x=taille,y=poids),col="magenta",data=datvil)+
		geom_line(aes(x=taille,y=predlm),col="#FE0CD6",data=datvil)+
		geom_ribbon(aes(x=taille,ymin=predlowIC,ymax=predhighIC),fill="#E5BF4B",col="#A6035C",alpha=0.5,data=datvil)+
		xlab("taille (mm)")+ylab("poids (g)")
print(g)
dev.off()



# ci dessous mix, ne marche pas sur la structure globale
#require(mixdist)
#tailledfpar<-data.frame("pi"=c(0.11,0.89),#proportion
#		"mu"=c(35,89),# moyennes,
#		"sigma"=c(5,14)# SD
#mixtailledf<-mix(tailledf,tailledfpar,constr = mixconstr(consigma = "NONE"), emsteps = 3)
#plot(mixtailledf)
######################################################
# ci dessous la décomposition polymodale on y croit pas ....
####################################################
require(mixdist)
# travail sur les tailles à moins de 7 m de distance
tailleinf7 <- dddp$psf_l_cm[dddp$psf_radius_m<7 & dddp$saison==saison]
taille <- dddp$psf_l_cm[dddp$saison==saison]
#tail(tailleinf7[order(tailleinf7)])
# head(tailleinf7[order(tailleinf7)])

hist(tailleinf7,breaks=c(20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130))
intervalsrightinf7<-hist(round(tailleinf7))$breaks[2:length(hist(round(tailleinf7))$breaks)]
tailledfinf7<-data.frame(rightb=intervalsrightinf7,
		N=hist(round(tailleinf7))$counts,
		taille=hist(round(tailleinf7))$mids
)
intervalsright<-hist(round(taille))$breaks[2:length(hist(round(taille))$breaks)]
tailledf<-data.frame(rightb=intervalsright,
		N=hist(round(taille))$counts,
		taille=hist(round(taille))$mids
)
tailledfpar<-data.frame("pi"=c(0.15,0.85),#proportion
		"mu"=c(37,60),# moyennes,
		"sigma"=c(5,10))# SD
# fixmu vecteur pour indiquer quelles moyennes sont forcées
mixtailledfinf7 <- mix(tailledfinf7,tailledfpar,constr =
				mixconstr(consigma = "SFX",conmu="MFX", fixsigma=c(FALSE,FALSE),fixmu=c(TRUE,FALSE)),emsteps = 3)
#mixtailledf<-mix(tailledfinf7,tailledfpar,constr =
#				mixconstr(consigma = "NONE",conmu="NONE"),emsteps = 3)
summary(mixtailledfinf7)
plot(mixtailledfinf7)
#Anthony Acou 2010 (Loire) donne la limite à 460 mmm		
# sexe_ratio <- mixtailledf$parameters$pi[1] 16 % surestimé
# pour
sexe.ratio_inf7 <- sum(tailledfinf7$N[tailledfinf7$rightb<50])/sum(tailledfinf7$N)# 9% de mâles sur la structure en taille corrigée de près
sexe.ratio <- sum(tailledf$N[tailledf$rightb<50])/sum(tailledf$N)# 8% de mâles sur la structure en taille globale corrigée... OK


tailledf$taille3 <- (tailledf$taille/100)^3
tailledf$weight <- predict(rlmmod,newdata=tailledf)
vvv$mean_weight <- sum(tailledf$weight*tailledf$N/sum(tailledf$N))# 516

# 31.16 sum surface Vilaine, km2 voir sqldf commenté
#TODO check here
# EDA 31.16
#

# 31.16/10400 0.0029
# CALCUL POUR LA LOIRE
#Extraction EDA au niveau de Ancenis
#select *,
#st_distance(st_transform(the_geom,4326),ST_GeomFromText('POINT(-1.1777 47.3617)',4326)) as distance 
#from rht.crosstab_rhtvs2
#where ST_dwithin(st_transform(the_geom,4326),ST_GeomFromText('POINT(-1.1777 47.3617)',4326),500)
#order by distance;
#
##id_drain 214245
#select sum(surface), sum(abondance)*0.05 from rht.crosstab_rhtvs2 where id_drain in (select rht.upstream_segments(214245));
# -- 133056 nombre 414.38 surface
# Calcul de la surface en eau en supposant que le ration rht/bd_topo est le même que sur la Vilaine
#select 414.38*120.64/31.16 -- 1604 km2
#-- pour 2008 2009
#select 150000*1.053 --157950
#select 157950/160400 --0.98
save(tailledf,tailledfinf7,file=str_c(datawdy,"tailledf.Rdata"))
@

 La courbe taille poids calculée en 2012--2013 est utilisée pour prédire les
 distributions de poids d'anguilles à partir des tailles mesurées au didson (Figure \ref{structure_taille}). Le poids moyen
des anguilles est estimé à \num{\Sexpr{round(vvv$mean_weight)}}g.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.45\textwidth]{2022/structure_taille}
  \caption[Structure en taille]{Structure en taille des anguilles, en turquoise
   effectifs bruts (N), en bleu foncé effectifs corrigés de l'efficacité (Ncor).}
  \label{structure_taille}
\end{figure}
Les sexes ratios calculés en utilisant une limite de 
 taille entre les mâles et les femelles à 450 mm \citep{acou_estimation_2010} 
 s'établissent à \num{\Sexpr{round(100*sexe.ratio)}} \% de mâles en
 \Sexpr{saison}, soit la plus importante proportion de mâles observée
 jusqu'alors.
 Les chiffres de sexe ratio montrent une diminution puis une réaugmentation de
 la proportion de mâles. Les premières années 2012-2013 et 2013-2014, ce
 pourcentage était de 12 et 15 \%  \citep{briand_suivi_2014, briand_suivi_2015}, 9\%
en 2014-2015 et 2015-2016 \citep{briand_suivi_2016,
briand_suivi_2017}, 7\% en 2016-2017 \citep{briand_suivi_2018}, 5\% en
2017-2018 \citep{briand_suivi_2018}, 7 \% en 2018-2019
\citep{briand_suivi_2019}, 8\% en 2019-2020 \citep{briand_suivi_2020}.

% le pdf fait planter l'impression
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=0.45\textwidth]{taille_poids.png}
%\caption[fig_taille_poids]{Modélisation de la relation taille-poids, en magenta,
%données recueillies sur la Vilaine en 2001, 2009 et 2010, en vert, source ONEMA,
%données Loire Bretagne. La régression s'écrit,  $P(g)$=\Sexpr{round(coef(rlmmodb),1)}$\times
%L(mm)^3$ pour les données Bretagne (N=\Sexpr{length(summary(rlmmodb)$residuals)})
%et $P(g)$=\Sexpr{round(coef(rlmmod),1)}$\times L(mm)^3$
%(N=\Sexpr{length(summary(rlmmod)$residuals)}) pour les données Vilaine.}
%\label{fig_taille_poids}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{\dimexpr.8pt+\fboxsep\relax}
\noindent       
\fbox{%
    \parbox{\linewidth-2\fboxsep-1.6pt}{%
    \parindent\defaultparindent%
    \indent 
D'après la structure en taille corrigée de l'efficacité, le poids moyen des
anguilles argentées est estimé à \num{\Sexpr{round(vvv$mean_weight)}}g pour la
dévalaison 2021--2022. }}
\vspace{\dimexpr.8pt+\fboxsep\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Estimation des effectifs migrants}
\label{parestimationodot}

<<nombre, echo=FALSE, eval=TRUE, results=hide>>=
#stop("on travaille ici")
# load(file=str_c(datawdy,"d3ej.all.Rdata"))
# if ("efficiency" %in% colnames(d3ej)) d3ej<-d3ej[,-grep("efficiency",colnames(d3ej))]
#plot(d3edj$enj_date,d3edj$sum_eel_plus,ylim=c(-20,200))
#points(d3edj$enj_date,-d3edj$sum_eel_minus,col="red")

#sum(d3edj$sum_eel_plus,na.rm=TRUE)+sum(d3edj$sum_eel_minus,na.rm=TRUE)# 1990
# d3ej vient de ddde mais limité de jour
# je remet les positionnements de vanne
#plot(d3ej$dsf_timeinit,d3ej$dsf_fls_id)
efficacitedata <- as.data.frame(efficacite_moyenne[,c("saison","position","E")])
colnames(efficacitedata) <- c("dsf_season","dsf_position","E")
efficacitedata$dsf_position[efficacitedata$dsf_position == "vanne"] <- "f"
efficacitedata$dsf_position[efficacitedata$dsf_position == "volet"] <- "s"
efficacitedata$dsf_position[is.na(efficacitedata$dsf_position)] <- "n"


d3ej <- left_join(d3ej,efficacitedata,by=c("dsf_position","dsf_season"))
d3ej <- d3ej[order(d3ej$dsf_timeinit),]

d3ej$Nprimo4 <- rowSums(d3ej[,c("drr_eelplus","drr_eelminus")],na.rm=TRUE)

# Ensemble des détections du fichier poisson
(Nprim04all <- sum(colSums(ddde[,c("drr_eelplus","drr_eelminus")],na.rm=TRUE))) # 16976
(Nprim04allCY <- sum(colSums(ddde[ddde$dsf_season==saison,c("drr_eelplus","drr_eelminus")],na.rm=TRUE))) # 1434
sum(d3ej$Nprimo4) # plus faible car limité de jour #16626

duree <- d3ej$dsf_timeend-d3ej$dsf_timeinit
duree[duree>30]<-duree[which(duree>30)+1] # je décale et je prends le temps du voisin
d3ej$rho<-30/as.numeric(duree) 
# 30 tout le temps car pas d'utilisation du rotateur
d3ej$No4<-(d3ej$Nprimo4/d3ej$E)*d3ej$rho # rho vaut 1 sans le rotateur



d3ej$N4<-d3ej$No4/d3ej$psurface
d3ej$N<-d3ej$N4/d3ej$pvol4
d3ej$H<-strftime(d3ej$dsf_timeinit,format="%H")
d3ej$W<-strftime(d3ej$dsf_timeinit,format="%W")
d3ej$W<-as.factor(d3ej$W)
d3ej$H<-as.factor(d3ej$H)
d3ej$hourm<-as.numeric(as.character(d3ej$H))
d3ej$hourm[d3ej$hourm<=8]<-24+d3ej$hourm[d3ej$hourm<=8]
d3ej$hourm<-d3ej$hourm-18 # 0 à 18h00
d3ej$position<-as.factor(d3ej$position)
#d3ej$ndays<-as.numeric(as.Date(d3ej$dsf_timeinit)-as.Date(min(d3ej$dsf_timeinit)))
d3ej$day<-as.numeric(strftime(d3ej$dsf_timeinit,format="%j"))
d3ej$day[d3ej$day<250]<-d3ej$day[d3ej$day<250]+365
d3ej$ndays<-d3ej$day-min(d3ej$day)+1
stopifnot(length(indexOK)==nrow(d3ej))
percOK<-round(100* sum(indexOK)/length(indexOK))
d3ejok<-d3ej[d3ej$dsf_id%in%dsfindexOK,] # 31 %
d3ejokex3<-d3ej[d3ej$dsf_id%in%dsfindexOKex3,] #sum(d3ej$dsf_id%in%dsfindexOKex3) 18%
# Quelques extrapolations en divisant par zéro, correspond
# à l'ouverture de la vanne, ouverture très faible, dans la fonction de calcul
# dans d3ej
if (sum(is.infinite(d3ejok$N4))>0){
	warning(str_c("il y a ",sum(is.infinite(d3ejok$N4))," de valeurs NaN pour N4"))
	d3ejok[is.infinite(d3ejok$N4),"N4"]<-NA 
	
}
# d3ejok[is.na(d3ejok$N),c("Nprimo4","pdebit4","psurface","position")]
if (sum(is.infinite(d3ej$N))>0){
	warning(str_c("il y a ",sum(is.infinite(d3ej$N))," de valeurs NaN pour N"))
	d3ejok[is.infinite(d3ejok$N),"N"]<-NA 
	d3ej[is.infinite(d3ej$N),"N"]<-NA 
}
##################
# ci dessous ne sert pas vraiment, on préfère passer par d3ejok et d3ejko
##################

# ensemble des détections y compris celles pour lesquelles le didson est mal positionné
(Nprimo4 <- sum(d3ej$Nprimo4,na.rm=TRUE))
# extrapolation en utilisation l'efficacité, pour l'ensemble des détections
(No4 <- sum(d3ej$No4,na.rm=TRUE))
# extrapolation à la vanne pour l'ensemble des détections
(N4 <- sum(d3ej$N4,na.rm=TRUE))
muinv <- (100-mu)/100
# extrapolation jour/ nuit pour l'ensemble des détections
(N<-sum(d3ej[,"N"],na.rm=TRUE)/muinv)
#100*N/mu

# Même calcul que précédemment mais par position

(Nprimo4k <- tapply(d3ej$Nprimo4,d3ej$position,sum,na.rm=TRUE))
(No4k <- tapply(d3ej$No4,d3ej$position,sum,na.rm=TRUE))
(N4k <- tapply(d3ej$N,d3ej$position,sum,na.rm=TRUE))

#tapply(d3ej$pdebit4,d3ej$position,mean,na.rm=TRUE)
#tapply(d3ej$psurface,d3ej$position,mean,na.rm=TRUE)
# Dévalaison observée dans le champ de détection de la vanne 4



##################
# Calculs pour les détections ou le didson est bien positionné
##################
# Detections dans le champ de détection avant correction de l'efficacité
(Nprimo4ok <- sum(d3ejok$Nprimo4,na.rm=TRUE))
# Dévalaison réelle dans le champ de détection du didson sur la vanne 4
# 4, c'est à dire corrigee des problemes d'efficacite de détection
(No4ok <- sum(d3ejok$No4,na.rm=TRUE))
# Devalaison N4 conditions ok. Dévalaison sur l'ensemble de la vanne 4
(N4ok <- sum(d3ejok$N4,na.rm=TRUE))
# Devalaison par pas de temps, dans les condiditions ou le didson permet le
# suivi de la migration (ok)
(Nok <- sum(d3ejok$N,na.rm=TRUE)/muinv)
#####################################
# Dévalaison réelle dans le champ de détection du didson sur la vanne 4 par positions
############################################
# Detections dans le champ de détection avant correction de l'efficacité
(Nprimo4okk <- tapply(d3ejok$Nprimo4,d3ejok$position,sum,na.rm=TRUE))
# n est NA, on vire (n est utilisé pour éviter les plantages sur le calcul des surfaces
# il correspond aux enregistrements ou la position du didson est inconnue (pas de données du barrage)
(Nprimo4okk <- Nprimo4okk[!is.na(Nprimo4okk)])

# Detections après correction de l'efficacité
(No4okk <- tapply(d3ejok$No4,d3ejok$position,sum,na.rm=TRUE))
# pareil on vire les NA pour n
(No4okk <- No4okk[!is.na(No4okk)])

# Extrapolation dans le champ de la vanne
(N4okk <- tapply(d3ejok$N4,d3ejok$position,sum,na.rm=TRUE))
# pareil on vire les NA pour n
(N4okk <- N4okk[!is.na(N4okk)])

# Extrapolation à l'ensemble du barrage.
(Nokk <-  tapply(d3ejok$N,d3ejok$position,sum,na.rm=TRUE)/muinv)
(Nokk <- Nokk[!is.na(Nokk)])

#ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=Nprimo4,col=position))
#ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=N4,col=position))
#ggplot(d3ej)+geom_point(aes(x=dsf_timeinit,y=N,col=position))


# Anguilles à la montée
pminus=data.frame(cbind(tapply(d3ej$drr_eelminus,d3ej$mois,sum,na.rm=TRUE),
				tapply(rowSums(d3ej[,c("drr_eelplus","drr_eelminus")]),na.rm=TRUE,d3ej$mois,sum)))
pminus<-pminus[-1,]
pminus=rbind(pminus,colSums(pminus))
pminus$percminus<-pminus[,1]/pminus[,2]
colnames(pminus)<-c("minus","tous","percminus")
rownames(pminus)[nrow(pminus)]<-"total"
save(Nprim04all,Nprim04allCY, file=str_c(datawdy,"Nprim04all.Rdata"))

@

Un total de
\num{\Sexpr{round(Nprim04all)}}
anguilles a été compté au didson sur l'ensemble de la période de suivi depuis
2012 dont \num{\Sexpr{round(Nprim04allCY)}} pour l'année en cours. Lorsque
plusieurs lectures sont disponibles pour un même fichier, les fichiers correspondant au
meilleur filtre (CSOT) de dépouillement sont utilisés.
Ce nombre diminue à
\num{\Sexpr{round(sum(colSums(d3ej[,c("drr_eelplus","drr_eelminus")],na.rm=TRUE)))}}
anguilles lorsqu'on ne sélectionne que les
anguilles comptées entre 18 h et 8h . Puis il diminue encore à
\num{\Sexpr{round(sum(colSums(d3ejok[,c("drr_eelplus","drr_eelminus")],na.rm=TRUE)))}}
lorsqu'on ne sélectionne que les fichiers pour lesquels le didson est positionné
correctement, et qui ne présentent pas de problème de qualité, d'écriture ou
d'acquisition. Les fichiers pour lesquels l'acquisition est jugée correcte $\odot$ correspondent
à \num{\Sexpr{round(percOK)}}\% du temps.\\
A partir de cette sélection, les différentes étapes d'extrapolation conduisent
aux effectifs N$\odot$ décrits au tableau \ref{tabfinal}. Les effectifs comptés
pour chaque position du didson et chaque pas de temps $N'_{o4}(t,k)$ sont
divisés par l'efficacité $\bar{E(k)}$ et le facteur $\rho$ pour obtenir les effectifs corrigés au droit du didson
$N_{o4}(t,k)$ suivant la formule \ref{eq_efficacite32}.\\
A partir de ces effectifs, les données sont extrapolées au niveau de la vanne
$N_{4}(t,k)$ en utilisant la surface totale diminuée d'une tranche d'eau de 2 m
en surface lorsque les écoulements se font par le fond. Elles sont extrapolées
comme les autres années à une zone correspondant à 6
fois la charge sur le volet lorsque les écoulements se font en surface (coefficient $\lambda$=6).
%en utilisant des coefficients de valeur $\Lambda$=2 pour les vannes et $\lambda$=6 pour les volets (Formule \ref{eqmigvan2})
Enfin, les effectifs sont extrapolés à l'ensemble du barrage pour obtenir la prédiction $N\odot$ (Formule
\ref{eq_Ntotal}). Lors de cette dernière extrapolation, on corrige aussi des
effectifs estimés de jour pour obtenir la migration sur l'ensemble du cycle
journalier (Formule \ref{eq_mu}).
\subsubsection{Prédiction pour les données manquantes}


<<load_all_years, echo=FALSE, eval=TRUE,results=hide>>=
# d3ej vient de ddde mais limité de jour
# dans un premier temps je l'ai compilé à partir des fichiers, puis j'ai décidé de tout recharger directement à partir de la base

# library(dplyr)
#for (Y in 2013:(CY)){
#	datawdyy <- str_c(datawd,Y,"/")
#	load(file=str_c(datawdyy,"d3ej.Rdata"))
#	if(Y ==2013){
#		d3ej.all <- d3ej	
#	}  else{
#		d3ej.all <- rbind(d3ej.all,d3ej)
#	} 
#}
#save(d3ej.all, file=str_c(datawdy,"d3ej.all.Rdata"))

# loaded from the database now
#for (Y in 2013:(CY)){
#	datawdyy <- str_c(datawd,Y,"/")
#	load(file=str_c(datawdyy,"d3edj.Rdata"))
#	if(Y ==2013){
#		d3edj.all <- d3edj	
#	}
#	else{
#		d3edj.all <- rbind(d3edj.all,d3edj)
#	} 
#	
#}
#save(d3edj.all, file=str_c(datawdy,"d3edj.all.Rdata"))


# runonce
#for (Y in 2013:(CY)){
#	datawdyy <- str_c(datawd,Y,"/")
#	load(file=str_c(datawdyy,"dddp.Rdata"))
#	if (!"periode"%in% colnames(dddp) ) {
#		cat("Attention", Y, " Sans période \n")
#		dddp$periode <-NA
#		}
#	if(Y ==2013){
#		dddp.all <- dddp	
#
#	}
#	else{
#		dddp.all <- rbind(dddp.all,dddp)
#	} 
#	
#}
#xxxx<- dddp.all[!is.na(dddp.all$periode),c("dsf_id","periode")]
#sqldf("UPDATE did.t_didsonfiles_dsf set dsf_periode = periode FROM xxxx where xxxx.dsf_id = t_didsonfiles_dsf.dsf_id ")


# Données journalières après calcul, voir si j'en ai besoin
#for (Y in 2013:(CY-1)){
#	datawdyy <- str_c(datawd,Y,"/")
#	load(file=str_c(datawdyy,"dj.Rdata"))
#	if(Y ==2013){
#		dj.all <- dj	
#		colnames(dj.all) <- c("enj_date","deb_qtotalj","type","N")
#	}  else{
#		dj.all <- rbind(dj.all,dj)
#	} 
#}
#dj.all$type[dj.all$type=="odot"]<-"odots"
#colnames(dj.all) <- c("date","Q","type","N")
#dj.all$year <- year(dj.all$date)
#dj.all$month <- month(dj.all$date)
#dj.all$saison <- str_c(dj.all$year-1,"-",dj.all$year)
#dj.all$saison[dj.all$month>6]<-str_c(dj.all$year,"-",dj.all$year+1)[dj.all$month>6]
## Jour avec didson bien positionné ?
#dj.all.odot <- dj.all %>% 
#		dplyr::filter(type=="odots") 


@

<<Nombre_all, echo=FALSE, eval=TRUE,results=hide>>=
# chargement

load(file=str_c(datawdy,"d3ej.all.Rdata")) 
load(file=str_c(datawdy,"d3edj.all.Rdata"))
load(file= str_c(datawdy,"efficacite_moyenne.Rdata"))


muinv <- (100-mu)/100
D0 <- d3ej
Dj <- d3edj


# rappel -----------------------------------------------

# ex = extrapolation calculés dans l'ordre, le premier surpasse le dernier
# par exemple si la vanne est fermée, le statut sera toujours 0 même si pb technique
#  0 d3ej$optvanne4=="0" la vanne est fermée
#  4 => la position est "n" = pas de didson ou  fls (1,2) pb d'aquisition ou d'écriture
#  2 => pas de fichier
#  1 Le didson est bien positionné
# fond fond +  périodes de trantions (d3ej$optvanne4="fs")
# surface surface + périodes de transition
# didson penché loin du didson : vanne et didson sl en surface regarde en bas, volet et didson au fond sl regarde en haut
#3 Le didson marche mais est mal positionné







# Traitement des dates -------------------------------

D0 <- D0 %>% mutate(
		year = year(date),
		month = month(date), # mois existe mais c'est un ordered factor
		H = strftime(dsf_timeinit,format="%H"),
		H = as.factor(H),
		W = strftime(dsf_timeinit,format="%W"),
		W = as.factor(W),
		duree = dsf_timeend - dsf_timeinit,
		hourm = as.numeric(as.character(H)),
		day = as.numeric(strftime(dsf_timeinit,format="%j")),
		position = as.factor(position),
		indexOK = (dsf_fls_id == 0 | dsf_fls_id == 3) & ex == 1, # pas de problème de filestatus bloquant et didson bien positionné (regarde au bon endroit)  
		indexOKex3 = dsf_fls_id == 0 & ex == 3  # le didson est mal positionné
)


Dj <- Dj %>% mutate(
		year = year(enj_date),
		month = month(enj_date),
		day = as.numeric(strftime(enj_date,format="%j")))

#D0$saison <- NA
#D0$saison[D0$month< 6] <-  str_c(D0$year-1,"-",D0$year)[D0$month< 6]
#D0$saison[D0$month>=6] <- str_c(D0$year,"-",D0$year+1)[D0$month>= 6]
D0$duree[D0$duree>30] <- 30 
D0$hourm[D0$hourm<=8] <- 24+D0$hourm[D0$hourm<=8]
D0$hourm <- D0$hourm-18 # 0 à 18h00
D0$day[D0$day<250] <- D0$day[D0$day<250]+365
D0$ndays <- D0$day - min(D0$day)+1
D0$indexOK[is.na(D0$indexOK)] <- FALSE
D0$indexOKex3[is.na(D0$indexOKex3)] <- FALSE

Dj$dsf_season <- NA
Dj$dsf_season[Dj$month< 6] <-  str_c(Dj$year-1,"-",Dj$year)[Dj$month< 6]
Dj$dsf_season[Dj$month>=6] <- str_c(Dj$year,"-",Dj$year+1)[Dj$month>= 6]
Dj$day[Dj$day<250] <- Dj$day[Dj$day<250]+365
Dj$ndays <- Dj$day - min(Dj$day)+1



# Jointure avec les efficacites -------------------------

D1 <- left_join(D0,
		efficacite_moyenne %>%
				mutate(position=recode(position,"vanne"="f","volet"="s")) %>%
				rename(dsf_position=position, dsf_season=saison),
		by=c("dsf_position","dsf_season"))
D1 <- D1[order(D1$dsf_timeinit),]


# calculs d'effectifs au barrage ------------------------

# nombre observés au droit du didson corrigés de l'efficacité
D2 <- D1 %>% 
		mutate (
				rho = 30/as.numeric(duree),			
				Nprimo4 = rowSums(.[c("drr_eelplus","drr_eelminus")],na.rm=TRUE),
				No4 = Nprimo4*rho/E,
				N4 = No4/psurface,
				N = N4/pvol4
		)
D2$N[D2$vol4==0] <- 0
D2$N4[D2$vol4==0] <- 0
#open_in_excel(D2)
stopifnot(sum(duplicated(D2$dsf_id))==0)




# CALCUL DES VALEURS MANQUANTES ------------------------------------------------------

#   dsf_fls_id fls0
#   0	      0      enregistrement normal   
#   1	      1      problème d'acquisition, 
#   2	      1      problème d'écriture, 
#   3	      0      problème de qualité, 
#   4	      1      mauvais positionnement du didson ou écoulement ailleurs sur le barrage, 
#   5	      0      vanne fermée mais ensemble du #barrage fermé également

# ex = extrapolation calculés dans l'ordre, le premier surpasse le dernier
# par exemple si la vanne est fermée, le statut sera toujours 0 même si pb technique
#  0 d3ej$optvanne4=="0" la vanne est fermée
#  4 => la position est "n" = pas de didson ou  fls (1,2) pb d'aquisition ou d'écriture
#  2 => pas de fichier
#  1 => Le didson est bien positionné
# fond fond +  périodes de trantions (d3ej$optvanne4="fs")
# surface surface + périodes de transition
# didson penché loin du didson : vanne et didson sl en surface regarde en bas, volet et didson au fond sl regarde en haut
#  3 => Le didson marche mais est mal positionné

# en pratique ex=3 correspond à tous les fichiers Didson avec fls 0 (ok) ou 3 (pb qualité) [car ex4 eclue les fls 1 et 2]
# et où il y a un écoulement sur la vanne et le didson est mal positionné
D2$ex3 <- as.numeric(D2$ex==3 |D2$ex==0 & D2$volbarrage30>0)


# D2j group par numéro de jour et fait le sumarize
# en comptant le nomre de positions fond surface
# periodes jour (note cette étape est nécessaire pour avoir les "stats" par jour
# le group by suivant les donnera par ex3 0 ou 1
# on fait un join à la fin pour tout regrouper


D2j <- dplyr::select(D2,ndays,N,ex3,dsf_position, dsf_season)%>%
		dplyr::group_by(ndays,dsf_season)%>%
		dplyr::summarize(nex3=sum(ex3),
				pos_s=sum(dsf_position=="s")/dplyr::n(),
				pos_f=sum(dsf_position=="f")/dplyr::n(),
				.groups="drop")


# D3j groupe par jour et par position bonne ou mauvaise
D3j <- D2 %>% 
		dplyr::select(dsf_season,ndays,N,indexOK,ex3,volbarrage30)%>%
		dplyr::group_by(dsf_season,ndays,ex3)%>%
		dplyr::summarize(N=sum(N),nb=dplyr::n(),vol=sum(volbarrage30), .groups="drop")
D3j0 <- dplyr::filter(D3j,ex3==0) %>% select(-ex3) # bien positionné
D3j1 <- dplyr::filter(D3j,ex3==1) %>% select(-ex3)# mal positionné

# on cree un tableau avec le nombre de fichiers bien positionné et le nb mal 
# positionnés en parallèle
# par jour
D4j <- full_join(D3j1,D3j0,by=c("ndays","dsf_season"),suffix = c(".1", ".0")) %>%
		arrange(dsf_season,ndays)

#colnames(D4j)

# Dans le fichier ci dessous .1 correspond aux arrêts de tout type
# .0 correspond à une lecture dans de bonnes conditions.

nrow(D4j) #1506
nrow(Dj) # 1494
D5j <- left_join(Dj,D4j,by=c("ndays", "dsf_season"))
D5j <- left_join(D5j, D2j, by=c("ndays", "dsf_season")) # compte les périodes fls et fond sur surface

# extrapolation des effectifs manquants
D5j$vol.1[D5j$nex3==0] <- 0
D5j$nb.1[D5j$nex3==0] <- 0
#View(D5j[is.na(D5j$vol.1), ])
# une journée complètement manquante le 2017-11-21, pas de données dans D2 ni d3ej ???
# très peu de débit, pas à s'en soucier
D5j$vol.1[is.na(D5j$vol.1)] <- 0
D5j$N.1 <- D5j$N.0*(D5j$vol.1)/D5j$vol.0
#open_in_excel(D5j)

D5j$N <- D5j$N.0 + D5j$N.1

#
#ggplot(D5j)+ geom_point(aes(x=N.0, y=N.1)) +
#		facet_wrap(~dsf_season)
#
#ggplot(D2)+ geom_point(aes(x=date,y=N4)) 

# modèle


D5j$deb_qtotalj[is.na(D5j$deb_qtotalj)]<-0
D6j <- D5j %>%
		mutate(delta_1d=deb_qtotalj-lag(deb_qtotalj)
		)

cumsum. <- function(data) cumsum(data$deb_qtotalj)
# delta_3d et delta_7d compiled by Nils
delta_3d. <- function(data) zoo::rollapply(data$delta_1d, 3, sum, partial=TRUE) # partial pour avoir la meme longueur
delta_7d. <- function(data) zoo::rollapply(data$delta_1d, 7, sum, partial=TRUE)
# delta 3 et delta 7 ont des longueurs differentes
D7j <- D6j %>% group_by(dsf_season) %>% nest() %>%
		mutate(cumflow=map(data,cumsum.),
				delta_3d=map(data,delta_3d.),
				delta_7d=map(data,delta_7d.)) %>%				
		unnest(cols = c(data, cumflow,delta_3d,delta_7d)) %>% ungroup() 
D7j$dsf_season <- as.factor(D7j$dsf_season)
D7j$month <- as.factor(D7j$month)


# plot(D7j$cumflow)
# extrapoler la tendance à partir des données dispo sur une journée ------------------

require(mgcv)
pdev<-function(mod){
	(mod$null.deviance-mod$deviance)/mod$null.deviance
}

summary(g0 <- mgcv::gam(N~1,dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g0)
summary(g1 <- mgcv::gam(N~dsf_season,dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g1)
summary(g2 <- mgcv::gam(N~dsf_season+s(ndays),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g2)
summary(g3 <- mgcv::gam(N~s(ndays, by=dsf_season),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g3)
summary(g4 <- mgcv::gam(N~s(ndays, by=dsf_season)+s(deb_qtotalj),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g4)
summary(g5 <- mgcv::gam(N~s(ndays, by=dsf_season)+s(deb_qtotalj)+s(enj_turb),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g5)
summary(g6 <- mgcv::gam(N~dsf_season+s(ndays, by=dsf_season, k=5)+s(deb_qtotalj)+s(enj_turb)+s(cumflow, k=3) ,dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g6)
summary(g7 <- mgcv::gam(N~dsf_season+s(ndays, by=dsf_season, k=5)+s(deb_qtotalj)+s(enj_turb)+s(cumflow, k=3) + s(delta_1d),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g7) # delta NS
summary(g8 <- mgcv::gam(N~dsf_season+s(ndays, by=dsf_season, k=5)+s(deb_qtotalj)+s(enj_turb)+s(cumflow, k=3) + s(delta_3d),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g8) # delta NS
summary(g9 <- mgcv::gam(N~dsf_season+s(ndays, by=dsf_season, k=5)+s(deb_qtotalj)+s(enj_turb)+cumflow + s(delta_7d),dat=D7j[D7j$N>0,],family=Gamma(link="log")))
AIC(g9) # delta NS
#Deviance explained = 60.6%
pdf(file=str_c(imgwdy,"gam_predict.pdf"),width=7,height=7)
plot(g8,pages=1,all.terms=TRUE,shade=TRUE,ylim=c(-20,20))
dev.off()
AIC(g1,g2,g3,g4,g5,g6,g7,g8,g9)
gam.check(g8)
concurvity(g9)
options(encoding = "UTF-8")
tg8<- itsadug::gamtabs(g8, 
		caption="Modèle de prédiction des effectifs",
		label="tableau_modele_miss")
cat(tg8,
		file=str_c(tabwdy,"tableau_modele_miss.tex"),
		sep="\n")
options(encoding = "native.enc")

######################################
# predictions pour les jours manquants
# utilisation d'un modèle gam sur qtotal + effet saisonnier ... bizarre...
# avec un creux en janvier
#####################################
p1 <-    is.na(D7j$N)
#d3edj[p1,"N.2"]
D7j[p1,"N.2"] <- 0
D7j[p1,"N.2"] <- predict(g9,newdata=D7j[p1,],type="response")


png(filename=str_c(imgwdy,"N_interannuel.png"),width = 8, height = 8, units = 'in', res = 300)
D7j %>% select(-N) %>% pivot_longer(cols=starts_with("N."),names_to="type",values_to="N") %>%
		mutate(type=factor(type,levels=c("N.2","N.1","N.0"))) %>%
		group_by(dsf_season,type) %>% 
		summarize(N=sum(N,na.rm=TRUE), .groups="drop")%>%
		ggplot() +
		geom_col(aes(x=dsf_season,y=N,fill=type),position = "stack") +
		xlab("saison") +
		scale_fill_manual(values=c(jaune_EV,orange_EV,turquoise_EV),
				labels = c("N(+)", "N(x)", "N(.)"))
dev.off()



save(D2, D7j, file=str_c(datawd,"D2D7j.Rdata"))


@




<<missing_values, echo=FALSE, eval=FALSE,results=hide>>=
stop("DEPRECATED")
#load(file=str_c(datawdy,"d3edj.Rdata"))
d3edj$day <- as.numeric(strftime(d3edj$enj_date,format="%j"))
d3edj$day[d3edj$day<250] <- d3edj$day[d3edj$day<250]+365
d3edj$ndays <- d3edj$day-min(d3edj$day)+1

d3ejko <- d3ej[!indexOK,] # fichiers non utilisés pour le calcul
d3ejko$N <- NA

# d3ejf dans un meme tableau toutes les lignes : celles OK et les autres qu'on est allé rechercher
# periodes 30minutes
d3ejf <- rbind(d3ejko,d3ejok)	
d3ejf <- d3ejf[order(d3ejf$dsf_timeinit),] # toutes les lignes

# d3edj2 group par numéro de jour et fait le sumarize
# en comptant le nomre de positions fond surface
# periodes jour
d3edj2 <- dplyr::select(d3ejf,ndays,N,flsall,dsf_position)%>%
		dplyr::group_by(ndays)%>%
		dplyr::summarize(nfls0=sum(flsall%in%c(0,3)),
				pos_s=sum(dsf_position=="s")/dplyr::n(),
				pos_f=sum(dsf_position=="f")/dplyr::n())



#   flsall	flsall2
#   0	      0      enregistrement normal   
#   1	      1      problème d'acquisition, 
#   2	      1      problème d'écriture, 
#   3	      0      problème de qualité, 
#   4	      1      mauvais positionnement du didson ou écoulement ailleurs sur le barrage, 
#   5	      0      vanne fermée mais ensemble du #barrage fermé également

# creation d'un vecteur flsall2 contenant deux positions 0 ou 1
d3ejf$flsall2 <- d3ejf$flsall
d3ejf$flsall2[d3ejf$flsall2%in%c(0,3)] <- 0
d3ejf$flsall2[d3ejf$flsall2%in%c(1,2,4)] <- 1

# d3edj3 groupe par jour et par position bonne ou mauvaise
d3edj3<-dplyr::select(d3ejf,ndays,N,indexOK,flsall2,volbarrage30)%>%
		dplyr::group_by(ndays,flsall2)%>%
		dplyr::summarize(N=sum(N,na.rm=TRUE),nb=dplyr::n(),vol=sum(volbarrage30))
d3edj31 <- dplyr::filter(d3edj3,flsall2==1) # mal positionné
d3edj30 <- dplyr::filter(d3edj3,flsall2==0) # bien positionné

# on cree un tableau avec le nombre de fichiers bien positionné et le nb mal 
# positionnés en parallèle
# par jour
d3edj4 <- merge(d3edj31,d3edj30,by="ndays",all.x=TRUE,all.y=TRUE)
colnames(d3edj4) <- gsub("x","1",colnames(d3edj4))
colnames(d3edj4) <- gsub("y","0",colnames(d3edj4))
colnames(d3edj4)[1] <- "ndays"



# Dans le fichier ci dessous .1 correspond aux arrêts de tout type
# .0 correspond à une lecture dans de bonnes conditions.


d3edj <- merge(d3edj,d3edj4,by="ndays")
d3edj <- merge(d3edj,d3edj2,by="ndays")
# calculer le nombre de fenêtre de migration manquantes
#d3edj[d3edj$sumok==0,"Nd"]<-NA



# l'extrapolation est surement surestimée car les fonctionnements
# en volets sont en général en fin de nuit.
d3edj$vol.1[is.na(d3edj$vol.1)] <- 0
d3edj$N.1 <- d3edj$N.0*(d3edj$vol.1)/d3edj$vol.0
# 
#open_in_excel(d3edj)
# valeurs manquantes début de saison, interpolation
d3edj$N <- d3edj$N.0+d3edj$N.1


#################################
# Extrapolation des jours manquants
# voir didson2016 pour loess pour quelques jours
# voir didson 2015 pour gam avec presence absence
# ################################

# extrapoler la tendance à partir des données dispo sur une journée
d3edj[d3edj$nfls0==0,"N.0"] <- NA
require(mgcv)
nrow(d3ejok) # 3184

#d3edj$N
g0 <- mgcv::gam(N~s(deb_qtotalj,k=3),dat=d3edj[d3edj$N>0,],family=Gamma(link="log"))
summary(g0)
pdf(file=str_c(imgwdy,"gam_predict.pdf",width=7,height=7))
plot(g0,pages=1,all.terms=TRUE)
dev.off()

######################################
# predictions pour les jours manquants
# utilisation d'un modèle gam sur qtotal + effet saisonnier ... bizarre...
# avec un creux en janvier
#####################################
p1 <-    is.na(d3edj$N)
#d3edj[p1,"N.2"]
d3edj[p1,"N.2"]<-0
d3edj[p1,"N.2"] <- predict(g0,newdata=d3edj[p1,],type="response")
#p2<-c(44,45,47)
## d3edj[p2,]
#d3edj[p2,"N.2"]<-predict(g0,newdata=d3edj[p2,],type="response")

# d3edj[p3,]


######################################################
#pdf(file=str_c(imgwdy,"fig_effectif_pb.pdf"),width=9,height=7)
#opar <- par(c(5, 4, 4, 4) + 0.1)
#plot(d3edj$enj_date,d3edj$N,type="n",ylab="N & 10debit m3.s-1",xlab="date")
#
#pb <- d3ej$dsf_timeinit[d3ej$dsf_fls_id==3&!is.na(d3ej$dsf_fls_id)]
#if (length(pb>0)){
#	pb<-data.frame("date"=pb,"delta"=NA)
#	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
#	pb$delta[1]<-30
#	w<-which(pb$delta>690)
#	dateinit<-c(pb[1,"date"],pb[w,"date"])
#	dateinit<-as.Date(dateinit,tz=Sys.timezone())
#	datefin<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
#	datefin<-as.Date(datefin,tz=Sys.timezone())
#} else {dateinit=NULL;datefin=NULL}
##pb<-d3ej$dsf_timeinit[d3ej$dsf_fls_id==2&!is.na(d3ej$dsf_fls_id)]
##if (length(pb>0)){
##	pb<-data.frame("date"=pb,"delta"=NA)
##	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
##	pb$delta[1]<-30
##	w<-which(pb$delta>690)
##	dateinit2<-c(pb[1,"date"],pb[w,"date"])
##	dateinit2<-as.Date(dateinit2,tz=Sys.timezone())
##	datefin2<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
##	datefin2<-as.Date(datefin2,tz=Sys.timezone())
##}else {dateinit2=NULL;datefin2=NULL}
#############################
#pb <- d3ej$dsf_timeinit[d3ej$dsf_fls_id==1|d3ej$dsf_fls_id==2]
#if (length(pb>0)){
#	pb<-data.frame("date"=pb,"delta"=NA)
#	pb$delta[2:nrow(pb)]<-pb$date[2:nrow(pb)]-pb$date[1:(nrow(pb)-1)]
#	pb$delta[1]<-30
#	w<-which(pb$delta>690)
#	dateinit3<-c(pb[1,"date"],pb[w,"date"])
#	dateinit3<-as.Date(dateinit3,tz=Sys.timezone())
#	datefin3<-c(pb[w-1,"date"],pb[nrow(pb),"date"])
#	datefin3<-as.Date(datefin3,tz=Sys.timezone())
#} else {dateinit3=NULL;datefin3=NULL}
## plot, mais pas les axes 
##plot(d3edj$enj_date,d3edj$deb_qtotalj,type="l",yaxt='n',col="black",ylab="",xlab="date")
#if (!is.null(dateinit3)){
#	rect(xleft=dateinit3,ybottom=0,xright=datefin3,ytop=5000,col=makeTransparent(jaune_EV,50),border=jaune_EV)#,density=6)
#}
#if (!is.null(dateinit)){
#	rect(xleft=dateinit,ybottom=0,xright=datefin,ytop=5000,col=makeTransparent("steelblue",50),border="steelblue")#,density=8,angle
#	#= -45) 
#}
##if (!is.null(dateinit2)){
##	rect(xleft=dateinit2,ybottom=0,xright=datefin2,ytop=5000,col="yellow",border="orange")
##}
################################################################
##rect(xleft=16394,ybottom=0,xright=16426,ytop=3000,col=rouille)
##rect(xleft=16456,ybottom=0,xright=16483,ytop=3000,col=rouille)
##text(x=17158,y=4500,label="pb acqu",pos=4)
##text(x=17186,y=4000,label="pb acqu",pos=4)
##text(x=17211,y=4500,label="corrosion",pos=4)
#
##text(x=16425,y=1800,label="Pb efficacité",pos=4)
#rect(xleft=as.numeric(dmy("23112018")),ybottom=0,xright=as.numeric(dmy("13122018")),ytop=6000,border=rouille)
#text(x=as.numeric(dmy("04122018")),y=5000,label="A",col=orange_EV)
#rect(xleft=as.numeric(dmy("13122018")),ybottom=0,xright=as.numeric(dmy("01022019")),ytop=6000,border=rouille)
#text(x=as.numeric(dmy("15012019")),y=5000,label="B",col=orange_EV)
#rect(xleft=as.numeric(dmy("01022019")),ybottom=0,xright=as.numeric(dmy("01032019")),ytop=6000,border=rouille)
#text(x=as.numeric(dmy("14022019")),y=5000,label="C",col=orange_EV)
#rect(xleft=as.numeric(dmy("01032019")),ybottom=0,xright=as.numeric(dmy("01052019")),ytop=6000,border=rouille)
#text(x=as.numeric(dmy("01042019")),y=5000,label="D",col=orange_EV)
#
#
#points(d3edj$enj_date,d3edj$N,col=orange_EV,type="h",lwd=2)
#points(d3edj$enj_date,d3edj$N.0,col=turquoise_EV,type="h",lwd=2)
#points(d3edj$enj_date,d3edj$N.2,col="purple",type="h",lwd=2)
#points(d3edj$enj_date[d3edj$enj_date<dmy("13122018")],d3edj$N.0[d3edj$enj_date<dmy("13122018")],col="mediumorchid",type="h",lwd=2)
##points(d3edj$enj_date,d3edj$N.4,col="purple",type="h",lwd=1)
##axis(side=4,at=pretty(0:max(d3edj$N,na.rm=TRUE)),label=as.character(pretty(0:max(d3edj$N,na.rm=TRUE))/10))
#text(17487,3200,"Did. FOND",col=rouille,adj = c(0,0))
#points(d3edj$enj_date[d3edj$pos_f>0],rep(3000,sum(d3edj$pos_f>0)),col=rouille,type="p",lwd=2,pch=15)
#text(17487,3700,"Did. SURF",col=bleu_EV,adj = c(0,0))
#points(d3edj$enj_date[d3edj$pos_s>0],rep(3500,sum(d3edj$pos_s>0)),col=bleu_EV,type="p",lwd=2,pch=15)
#
#axis(1, pos=0,labels=FALSE,lwd.ticks=0)
#points(d3edj$enj_date,d3edj$deb_qtotalj*10,type="l", col="blue")
#points(d3edj$enj_date,d3edj$debit4j*10,type="l",col="red")
#dev.off()
#
#
#
#
#
#d3edj$N<-rowSums(d3edj[,c("N.0","N.1")],na.rm=TRUE)
#d3edj[d3edj$nfls0==0,"N"]<-NA
#d3edj$N[!is.na(d3edj$N.2)]<-d3edj$N.2[!is.na(d3edj$N.2)]
## extrapoler les données à partir de la librairie zoo
#write.table(d3edj,row.names = FALSE,file=str_c(datawdy,"d3edj.csv"),sep=";")
#detach(package:dplyr)
#(Nko.1<-sum(d3edj$N.1,na.rm=TRUE)/muinv)# 11181.98
#(Nko.3<-sum(d3edj$N.2,na.rm=TRUE)/muinv)# 923 effectifs des jours manquants
#

@




<<tableaufinal, echo=FALSE, eval=TRUE,results=hide>>=
# Devalaison observée dans le champ de la vanne pour positions mauvaise ...
# didson en vanne alors que en volet, ou en volet alors que écoulement en vannes

load(file=str_c(datawd,"D2D7j.Rdata"))
D7j %>% select(-N) %>% pivot_longer(cols=starts_with("N."),names_to="type",values_to="N") %>%
		mutate(type=factor(type,levels=c("N.2","N.1","N.0"))) %>%
		group_by(dsf_season,type) %>% 
		summarize(N=sum(N,na.rm=TRUE), .groups="drop")%>%
		pivot_wider(names_from=type, values_from=N)



# Calculs pour les détections ou le didson est bien positionné ---------------------

Dok <- D2 %>% filter(indexOK) # tableau des enregistrement 30 min ou le didson est bien positionné
#Dok_ex3 <- D2 %>% filter(indexOKex3) # tableau des enregistrements 30 min ou le didson est mal positionné
vvv$number.odot <- 
# Quelques extrapolations en divisant par zéro, correspond
# à l'ouverture de la vanne, ouverture très faible, dans la fonction de calcul
# dans Dok
		
		if (sum(is.infinite(Dok$N4))>0){
			warning(str_c("il y a ",sum(is.infinite(Dok$N4))," de valeurs NaN pour N4"))
			Dok[is.infinite(Dok$N4),"N4"]<-NA 
		}

if (sum(is.infinite(Dok$N))>0){
	warning(str_c("il y a ",sum(is.infinite(Dok$N))," de valeurs NaN pour N"))
	Dok[is.infinite(Dok$N),"N"]<-NA 
}

res.0 <- Dok %>% group_by(dsf_season) %>% 
		summarize(
				# Detections dans le champ de détection avant correction de l'efficacité
				Nprimo4ok = sum(Nprimo4,na.rm=TRUE),
				# Dévalaison réelle dans le champ de détection du didson sur la vanne 4
				# c'est à dire corrigee des problemes d'efficacite de détection
				No4ok = sum(No4,na.rm=TRUE),
				# Devalaison N4 conditions ok. Dévalaison sur l'ensemble de la vanne 4
				N4ok = sum(N4,na.rm=TRUE),
				# Devalaison par pas de temps, dans les condiditions ou le didson permet le
				# suivi de la migration (ok)
				Nok = sum(N,na.rm=TRUE)/muinv,
				.groups="drop"
		)%>% mutate(position="$\\sum\\odot$")%>% select("Saison"=dsf_season,
				"type"=position,
				"$N'_{o4}$"=Nprimo4ok,
				"$N_{o4}$"=No4ok,
				"$N_{4}$"=N4ok,	
				"$N$"=Nok) 

res.0_pos <- Dok %>% group_by(dsf_season, position) %>% 
		summarize(
				# Detections dans le champ de détection avant correction de l'efficacité
				Nprimo4ok = sum(Nprimo4,na.rm=TRUE),
				# Dévalaison réelle dans le champ de détection du didson sur la vanne 4
				# c'est à dire corrigee des problemes d'efficacite de détection
				No4ok = sum(No4,na.rm=TRUE),
				# Devalaison N4 conditions ok. Dévalaison sur l'ensemble de la vanne 4
				N4ok = sum(N4,na.rm=TRUE),
				# Devalaison par pas de temps, dans les condiditions ou le didson permet le
				# suivi de la migration (ok)
				Nok = sum(N,na.rm=TRUE)/muinv,
				.groups="drop"
		)	%>% 
		mutate("type"=str_c(position,"$\\odot$")) %>% 
		select("Saison"=dsf_season,
				type,
				"$N'_{o4}$"=Nprimo4ok,
				"$N_{o4}$"=No4ok,
				"$N_{4}$"=N4ok,	
				"$N$"=Nok) 


#TODO verifier que les chiffres de D2 sont ceux de D7 pour N.0
tapply(D7j$N.0, D7j$dsf_season,sum, na.rm=TRUE)
tapply(Dok$N, Dok$dsf_season,sum, na.rm=TRUE)


res.1 <-  D7j %>% select(-N) %>% pivot_longer(cols=starts_with("N."),names_to="type",values_to="N") %>%
		group_by(dsf_season,type) %>% 
		summarize(N=round(sum(N,na.rm=TRUE)), .groups="drop")%>%
		filter(type=="N.1") %>%
		select("Saison"=dsf_season,	N) %>%
		rename('$N$'=N) %>%
		mutate(type="$\\otimes$(?)","$N'_{o4}$"=NA,"$N_{o4}$"=NA,"$N_{4}$"=NA) 

res.2 <-  D7j %>% select(-N) %>% pivot_longer(cols=starts_with("N."),names_to="type",values_to="N") %>%
		group_by(dsf_season,type) %>% 
		summarize(N=round(sum(N,na.rm=TRUE)), .groups="drop") %>%
		filter(type=="N.2") %>%
		select("Saison"=dsf_season,	N) %>%
		rename('$N$'=N) %>%
		mutate(type="$\\oplus$(?)","$N'_{o4}$"=NA,"$N_{o4}$"=NA,"$N_{4}$"=NA) 		
# tous
res.t <-  D7j %>% select(-N) %>% pivot_longer(cols=starts_with("N."),names_to="type",values_to="N") %>%
		group_by(dsf_season) %>% 
		summarize(N=round(sum(N,na.rm=TRUE)), .groups="drop") %>% 
		select("Saison"=dsf_season,	N) %>%
		rename('$N$'=N) %>%
		mutate(type="$\\sum\\odot\\otimes\\oplus$(?)","$N'_{o4}$"=NA,"$N_{o4}$"=NA,"$N_{4}$"=NA) 			


res <- bind_rows(res.0,
		res.0_pos,		
		res.1,
		res.2,
		res.t) 
res <- res %>%
		mutate(ma. = match(res$type,c("s$\\odot$","f3$\\odot$","f5$\\odot$","sl$\\odot$","$\\sum\\odot$",
								"$\\otimes$(?)","$\\oplus$(?)","$\\sum\\odot\\otimes\\oplus$(?)"))) %>%
		arrange(Saison, ma.) %>%
		mutate(ma.=1:n()) # re arranging, as I will drop seasons



# group rows for longtable
final <- bind_rows(
				res %>% filter(type=="s$\\odot$") %>% mutate("Saison"=paste0("\\multirow{7}{*}{",Saison,"}")),
				res %>% filter(type!="s$\\odot$") %>% mutate("Saison"="")
		)	%>%
		arrange(ma.)%>%
		select(-ma.)%>%
		mutate_if(is.numeric,round)



# ci dessous utilise l'option table.format de Siunitx
# S[table-format = 5] means no digits 5.3 would be 5 number and 3 digits
# Attendion ajouter un 6 à n.rgroups
options(encoding = "UTF-8")
toto <- latex(final,
		center='centering',
		table=F,
		rowname=NULL,
		booktab=T,
		numeric.dollar=F,
		title="",
		where="htbp",
		#colnamesTexCmd="bfseries", 
		col.just=c("l",
				"l",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]"),
		label="tabfinal",
		caption="Extrapolation des effectifs, 
				$N'_{o4}$ effectifs comptés au droit du sonar,
				$N_{o4}$=effectifs corrigés de l'efficacité du didson,
				$N_{4}$=effectifs estimés au droit de la vanne,
				$N$= effectifs estimés sur l'ensemble du barrage,
				$\\otimes$ = effectifs comptés au didson alors que celui-ci est mal positionné par rapport à l'écoulement, 
				$\\odot$= période de suivi complet sans problème de qualité,
				$\\otimes$=période de suivi extrapolée à partir des densités moyennes du jour,
				problème d'enregistrement ou de qualité ou mauvais positionnement du didson, en marron(4) sur la figure \\ref{fig_horairespb} et orange sur la figure \\ref{fig_position}.
				$\\oplus$=périodes sans suivi, les points d'interrogation indiquent des extrapolations incertaines,
				$\\sum$= Somme.
				Les positions $s$, $f3$, $f5$, $sl$ indiquent : $s$ position du didson en surface, $f3$ fond aquisition 3-13 m, $f5$ fond acquisition 5-15,
				$sl$ didson regardant vers la surface ou le fond pour tenter de déterminer la position verticale des anguilles. ",
		caption.lot=str_c("Extrapolation des effectifs."),		
		file=str_c(tabwdy,"tabfinal.tex"),
		# arguments pour longtable :
		longtable = TRUE,
		n.rgroup=c(7, 8, 7, 6, 6, 6, 6, 6, 7),
		continued = "\\dots suite \\dots",
		collabel.just = c("l",
				"l",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]",
				"S[table-format = 5.0]"),
		lines.page = 33,
#multicol = FALSE#,
#insert.bottom = "\\dots page suivante \\dots"
)
options(encoding = "native.enc")
final <- res
save(final,file=str_c(datawdy,"final.Rdata"))

vvv$number.odot.all <- D7j %>% filter(!is.na(N.0)) %>%group_by(dsf_season) %>% summarize(N=n())
vvv$number.odot <-  round(vvv$number.odot.all[vvv$number.odot.all$dsf_season==saison, "N"]) %>% pull()
vvv$number.otimes.all <- D7j %>% filter(!is.na(N.1)) %>%group_by(dsf_season) %>% summarize(N=n())
vvv$number.otimes <-  round(vvv$number.otimes.all[vvv$number.otimes.all$dsf_season==saison, "N"]) %>% pull()
vvv$Nprim04.odot <- res %>% filter(Saison==saison & type =="$\\sum\\odot$") %>% pull("$N'_{o4}$") %>% round()
vvv$N.otimes <- res %>% filter(Saison==saison & type =="$\\otimes$(?)") %>% pull("$N$") %>% round()
vvv$N.oplus <- res %>% filter(Saison==saison & type =="$\\oplus$(?)") %>% pull("$N$") %>% round()
vvv$N.odot <- res %>% filter(Saison==saison & type =="$\\sum\\odot$") %>% pull("$N$") %>% round()
vvv$N <- res %>% filter(Saison==saison & type =="$\\sum\\odot\\otimes\\oplus$(?)") %>% pull("$N$") %>% round()
vvv$total_weight <- round(vvv$mean_weight*vvv$N/10^6,1)
vvv$kg_per_ha <- vvv$total_weight*1000/(120.64*100)  # kg/ha

# p1  correspond à is.na(D7j$N) = jours sans N, on regroupe avec D7j pour avoir les saisons
vvv$number.missingday.all <-  cbind(D7j, p1) %>% group_by(dsf_season) %>% select(p1) %>% summarize(N=n())
vvv$number.missingday <-  round(vvv$number.missingday.all[vvv$number.missingday.all$dsf_season==saison, "N"]) %>% pull()

save(vvv,file=str_c(datawdy,"vvv.Rdata"))

@

<<figurefinal, echo=FALSE, eval=TRUE, results=hide>>=
#d3ejok$"fit" <- NA                    
#d3ejok$"se.fit" <- NA           
#d3ejok$"residual.scale" <- NA  
#d3ejok$"UL" <- NA                       
#d3ejok$"LL" <- NA 

#d3ej$odot <- d3ej$dsf_id%in%dsfindexOK
#tapply(d3ejf$N,d3ejf$odot,sum,na.rm=TRUE) # pour vérif
#dj <- tapply(d3ejf$N,list(d3ejf$date,d3ejf$odot),sum,na.rm=TRUE)
#dates <- as.Date(rownames(dj),tz=Sys.timezone())
#dj1 <- data.frame("dates"=dates,"N"=dj[,1],"type"="otimes")
#dj2 <- data.frame("dates"=dates,"N"=dj[,2],"type"="odot")
#dj3 <- tapply(d3ej$deb_qtotalj,d3ejf$date,mean,na.rm=TRUE)
#dj <- as.data.frame(rbind(dj1,dj2))
#dj$debit <- as.vector(dj3)
##colnames(dj) <- c("$nb(\\otimes$","$nb\\odot$","$\\sum_d(N\\odot)$","$\\sum_d(\\hat{P}(N)\\otimes$")


dj <- D7j  %>% 
		select("dsf_season","enj_date","N.0","N.1","N.2","deb_qtotalj")  %>%
		rename("odot"="N.0","otimes"="N.1", "oplus"="N.2","Q"="deb_qtotalj", "date"="enj_date") %>%		
		melt(id.vars=c("dsf_season","date","Q"),
				variable.name="type",
				value.name="N")



dj$type <- factor(dj$type, levels=rev(levels(dj$type)))

pdf(file=str_c(imgwdy,"fig_effectif.pdf"),width=7,height=7)
dj %>% 
		filter(dsf_season == saison) %>% 
		ggplot( aes(x=date, y=N, fill=type)) +
		ylab(expression(N~"&"~10*debit~m^3*s^-1)) +
		xlab(str_c("date (saison ", CY-1,"-",CY,")")) +
		geom_bar(position="stack", stat="identity") +
		scale_fill_manual("Effectif",values=c(turquoise_EV,
						orange_EV,jaune_EV),
				breaks=c("odot","otimes","oplus"),
				labels = c("N(.)", "N(x)", "N(+)")) +
		geom_line(aes(x=date,y=Q*10),lwd=1.2,col=bleu_EV) +	
		theme_bw()
dev.off()
save(dj,file=str_c(datawdy,"dj.Rdata"))


effmois <- dj %>% mutate(mois = lubridate::month(dj$date, label = TRUE, abbr = TRUE, locale= Sys.getlocale("LC_TIME"))) %>%
		group_by (dsf_season, mois ,type ) %>% 
		summarize(effectif=sum(N, na.rm=TRUE)) %>%
		pivot_wider(names_from=c("type"),names_prefix ="N_",values_from="effectif") %>%
		rename("Saison"="dsf_season", "$N\\odot$"=N_odot, "$N\\otimes$"=N_otimes,"$N\\oplus$"=N_oplus)

effmois  <- effmois %>%
		ungroup() %>%
		mutate(ma. = match(as.numeric(effmois$mois),c(9,10,11,12,1,2,3,4))) %>%
		arrange(Saison, ma.) %>%
		mutate(ma.=1:n()) # re arranging, as I will drop seasons



# group rows for longtable
effmois <- bind_rows(
				effmois %>% filter(mois=="sept"|mois=="oct" & ! Saison %in% c("2012-2013", "2015-2016")|mois=="nov" &  Saison %in% c("2017-2018","2018-2019")) %>% 
						mutate("Saison"=Saison),
				effmois %>% filter(!(mois=="sept"|mois=="oct" & ! Saison %in% c("2012-2013", "2015-2016")|mois=="nov" &  Saison %in% c("2017-2018","2018-2019"))) %>%
						mutate("Saison"="")
		)	%>%
		arrange(ma.)%>%
		select(-ma.)%>%
		mutate_if(is.numeric,round)

options(encoding = "UTF-8")
xtaeffmois<-xtable(effmois,
		label="table_effectif_mois",
		digits=0,
		caption=c("Effectif mensuel d'anguilles argentées estimé sur la Vilaine.",
				"Effectif mensuel")
)
addtorow          <- list()
addtorow$pos      <- list()
addtorow$pos[[1]] <- c(0)
addtorow$command  <- c(paste(
				"\\hline \n",
				"\\endhead \n",
				"\\hline \n",
				"{\\footnotesize ... suite page suivante...} \n",
				"\\endfoot \n",
				"\\endlastfoot \n",
				sep=""))


print(xtaeffmois,file=str_c(tabwdy,"table_effectif_mois.tex"),
		caption.placement = "top",
		tabular.environment = 'longtable',
		floating = FALSE,
		NA.string = "",
		include.rownames = FALSE,
		add.to.row =  addtorow,     # this is where you actually make the substitution
		hline.after = c(-1),          # because addtorow will substitute the default hline for the first row
		sanitize.colnames.function = function(X)X,
		sanitize.text.function = function(X)X
)
options(encoding = "native.enc")
dj2 <- D7j  %>% 
		select("dsf_season","enj_date","N.0","N.1","N.2","N","deb_qtotalj","pos_f","pos_s")  %>%
		filter(dsf_season==saison)
png(file=str_c(imgwdy,"fig_effectif_pb.png"), width = 29.7, height = 21, units = 'cm', res = 300)
opar <- par(c(5, 4, 4, 4) + 0.1)
plot(dj2$enj_date,dj2$N,type="n",ylab="N & 10debit m3.s-1",xlab="date", ylim=c(0,10000))
# calcul des périodes consécutives pour dsf_fls_id
date <- d3ej$dsf_timeinit[d3ej$dsf_fls_id>0 & !is.na(d3ej$dsf_fls_id) & d3ej$dsf_season==saison]
fls_id <- d3ej$dsf_fls_id[d3ej$dsf_fls_id>0 & !is.na(d3ej$dsf_fls_id) & d3ej$dsf_season==saison]
# df avec datefin datedebut, les lignes vont être enlevées
pb <- data.frame("datedebut"=date, 
		"datefin"=date+ as.difftime(30,units = "mins"), 
		"fls_id"=fls_id		
)
pb$delta <- difftime(pb$datefin,pb$datedebut,units ="days")
nr <- nrow(pb)
i = 1
if (nr>0){	
	while (i < nr){
		i = i+1
		# on enlève les lignes séquentielles soit avec la meme date fin que date debut ligne suivante
		# soit avec la durée entre matin et soir as.difftime(0.67,units="days") obligé de passer par une
		# egalité proche (abs(A-B)<1e-10 sinon problèmes de non egalité
		# dans la boucle while on recalcule delta et on enlève la ligne i
		# le test détecte aussi si on change de fls_id		
		if (pb$datedebut[i]==pb$datefin[i-1] & pb$fls_id[i]==pb$fls_id[i-1] | 
				abs(as.numeric(round(pb$delta[i-1],2)-floor(pb$delta[i-1])-as.difftime(0.67,units="days")))<1e-10 & pb$fls_id[i]==pb$fls_id[i-1]){
			pb$datefin[i-1] <- pb$datefin[i]
			pb <- pb[-i,]
			i=i-1
			pb$delta <- difftime(pb$datefin,pb$datedebut,units ="days")
		}
		nr=nrow(pb)
	}	
	# on passe en dates car l'abscisse est en dates
	pb$dateinit<-as.Date(pb$datedebut,tz=Sys.timezone())
	pb$datefinit<-as.Date(pb$datefin,tz=Sys.timezone())
}
fn <- function(X) switch(as.character(X), 
			"1" = makeTransparent(jaune_EV,50),
			"2" = makeTransparent(limegreen,50),
			"3" = makeTransparent(orange_EV,50))
pb$col <- mapply(fn,pb$fls_id)
fn1 <- function(X) switch(as.character(X),  
			"1"=jaune_EV,
			"2"= limegreen,
			"3"=orange_EV)
pb$border <- mapply(fn1,pb$fls_id)

rect(xleft=pb$dateinit,ybottom=0,xright=pb$datefinit,ytop=5000,col=pb$col,border=pb$border)
points(dj2$enj_date,dj2$N,col=bleu_EV,type="h",lwd=2)
points(dj2$enj_date,dj2$N.0,col=turquoise_EV,type="h",lwd=2)
points(dj2$enj_date,dj2$N.2,col=orange_EV,type="h",lwd=2)
#axis(side=4,at=pretty(0:max(dj2$N,na.rm=TRUE)),label=as.character(pretty(0:max(dj2$N,na.rm=TRUE))/10))
text(dj2$enj_date[1],2800,"Did. FOND",col=rouille,adj = c(0,0))
points(dj2$enj_date[dj2$pos_f>0],rep(3000,sum(dj2$pos_f>0)),col=rouille,type="p",lwd=2,pch=15)
text(dj2$enj_date[1],3700,"Did. SURF",col="gray",adj = c(0,0))
points(dj2$enj_date[dj2$pos_s>0],rep(3500,sum(dj2$pos_s>0)),col="gray",type="p",lwd=2,pch=15)

axis(1, pos=0,labels=FALSE,lwd.ticks=0)
points(d3edj$enj_date,d3edj$deb_qtotalj*10,type="l", col="blue")
points(d3edj$enj_date,d3edj$debit4j*10,type="l",col="red")
dev.off()
@

<<positionnement, echo=FALSE, eval=TRUE,results=hide>>=
#lambda <- c(1,1.5,2,3,4,6,8,10,20)
#f3=c(24193,24736,24966,28444,32513,39787,43457,47766,48147)/muinv
#ff=c(18731,23533,27067,33335,38694,47281,52096,57304,58486)/muinv
#s=c(0,53404,16189,9505,8158,8732,11230,14026,20833)/muinv
#maxestim <- 1000*round((s[length(s)]+max(f3)+max(ff))/1000)
#minestim <- 1000*round((min(s[s>0])+min(f3)+min(ff))/1000)
#maxestimpoids <- round(mean_weight*maxestim/10^6,1)
#minestimpoids <- round(mean_weight*minestim/10^6,1)
#maxestimprod <- round(maxestimpoids*10^3/(120.64*100),1)
#minestimprod <- round(minestimpoids*10^3/(120.64*100),1)
#dfe <- data.frame(lambda,f3,ff,s)
#dfe <- melt(dfe,id.vars="lambda")
## JE NE COMPRENDS PAS POURQUOI PLANTE EN SWEAVE ET PAS SINON... s ?
#pdf(str_c(imgwdy,"dfe.pdf"),width=6,height=6)
#g <- ggplot(dfe,aes(x=lambda,y=value,col=variable))+geom_point()+geom_line()+
#		scale_colour_manual("Position",values=c(bleu_EV, rouille,orange),
#				labels=list(expression(f(+4)),expression(f-3),expression(s)))+
#		xlab(expression(lambda~"||"~Lambda))+
#		ylab("N")+
#		annotate("point", x = c(1,1.5,2,3),y=c(0,53404,16189,9505)/muinv,
#				alpha = .2,col="orange",size=5)+
#		annotate("text",x=4,y=56004/muinv,label="Fenêtre > didson")+
#		annotate("point",x=1.7,y=25000/muinv,size=10,col="blue",alpha=0.2)+
#		annotate("text",x=2.5,y=25000/muinv,label="Lambda=2",parse=TRUE,hjust=0)+
#		annotate("text",x=4,y=12000,label="lambda>=4",parse=TRUE,hjust=0)
#print(g)
#dev.off()
@
La deuxième étape du calcul des effectifs correspond à la prédiction des
migrations lorsque le didson est dans une mauvaise position ($\otimes$), c'est à
dire en surface alors que les écoulements sont au fond, et au fond alors que les
écoulements sont en surface, ou quand le didson est en arrêt technique. Le
nombre de données correspondant à ce type de configuration est de
\num{\Sexpr{vvv$number.otimes}} enregistrements  ($\otimes$), contre
\num{\Sexpr{vvv$number.odot}} enregistrements en fonctionnement normal
($\odot$). Les effectifs extrapolés à partir des migrations observées le même
jour  est de  N $\otimes$=\num{\Sexpr{vvv$N.otimes}} anguilles argentées.

Sur l'ensemble des années, il y a eu \num{\Sexpr{vvv$number.missingday}}
journées avec aucun enregistrement du fait de problèmes d'acquisition ou
d'écriture disque (Figure \ref{fig_horairespb}).
Pour ces jours, un modèle GAM a été utilisé pour extrapoler 
 les effectifs en migration à partir des valeurs des jours proches ($\oplus$).
 La migration correspondant à ces journées manquantes est estimée à N =
 \num{\Sexpr{vvv$N.oplus}} anguilles argentées (Figure \ref{gam_predict}).
 
 %=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/gam_predict}
  \caption[Modèle prédiction effectifs manquants]{Modélisation des effectifs
  manquants à l'aide d'un modèle gam (tendance saisonnière + effet saison +
  débit + cumul débit depuis le début de la saison) + turbidité + variation du
  débit à 3 jours (delta 3d).}
  \label{gam_predict}
\end{figure}
%=====================================================================

Les différentes étapes de la reconstitution des effectifs sont résumées dans le tableau \ref{tabfinal} et
aboutissent à l'estimation d'un effectif de \num{\Sexpr{vvv$N}}
anguilles argentées en dévalaison.
A partir de l'ensemble des effectifs ($\odot$+$\otimes$) et du poids moyen calculé au paragraphe
\ref{parpoids}, la biomasse d'anguille est estimée à
\num[round-precision=1]{\Sexpr{round(vvv$total_weight,1)}} tonnes.

La migration estimée par mois est présentée au tableau
\ref{table_effectif_mois}, le résumé du modèle est présenté au tableau
\ref{tableau_modele_miss} en annexe. Le modèle est identique à celui de l'année
précédente mais les débits à 3 jours (delta 3d) ont été utilisés en lieu des
débits à 7 jours.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{\dimexpr.8pt+\fboxsep\relax}
\noindent       
\fbox{%
    \parbox{\linewidth-2\fboxsep-1.6pt}{%
    \parindent\defaultparindent%
    \indent 
Les effectifs extrapolés à partir des données considérées comme fiables
(N$\odot$=\num{\Sexpr{vvv$N.odot}}, les effectifs modélisés pour les
mauvaises configurations (N$\otimes$=\num{\Sexpr{vvv$N.otimes}}) et les
effectifs extrapolés pour les jours sans estimation 
  (N$\oplus$=\num{\Sexpr{vvv$N.oplus}}) donnent une
  estimation quantitative partielle des effectifs d'anguilles argentées en
  dévalaison sur la Vilaine N=\num{\Sexpr{vvv$N}} soit
  \Sexpr{vvv$total_weight} tonnes (Tableau \ref{tabfinal}).
  
}}\vspace{\dimexpr.8pt+\fboxsep\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<lpm, echo=FALSE, eval=TRUE,results=hide>>=
#############################
# Données pab
#############################
#
#require(stacomiR)
#options(
#		stacomiR.dbname = "bd_contmig_nat_iav",
#		stacomiR.host = readline(prompt = "Enter host: "),	
#		stacomiR.port = "5432",		
#		stacomiR.user = readline(prompt = "Enter user: "),
#		stacomiR.password = readline(prompt = "Enter password: ")
#)
#stacomi(TRUE,sch="iav")	
#
#bM_lpm <- new("report_mig_mult")
#bM_lpm <- choice_c(bM_lpm,
#		dc=5,
#		taxa=c("Petromyzon marinus"),
#		stage=c("11"),
#		datedebut=str_c(CY,"-01-01"),
#		datefin=str_c(CY,"-12-31"))
#bM_lpm <- charge(bM_lpm)
#bM_lpm <- connect(bM_lpm)
#bM_lpm <- calcule(bM_lpm)
#plot(bM_lpm)
#pab <- bM_lpm@calcdata[["dc_5"]][["data"]]
## ATTENTION AUX DATES METTRE A JOUR
#pab <- pab[as.Date(pab$debut_pas) >= dmy(01032020) & as.Date(pab$debut_pas)<dmy(01072020), c("debut_pas", "Effectif_total")]
#colnames(pab) <- c("date","nb_pab")
#save(pab,file=str_c(datawdy,"lpm_pab.Rdata"))
#load(file=str_c(datawdy,"lpm_pab.Rdata"))
##################
# lpm count didson
###########################
lpm$count <-1
tt <- tapply(lpm$count,lpm$date,sum)
ddlpm<-data.frame("date"=names(tt),"effectif"=tt)

vvv$lpm <- sum(tt)
##################
# eel count didson
###########################
#dlpm<-d3edj[,c("enj_date","deb_qtotalj","debit4j","N")]
#ddlpm$date<-as.Date(ddlpm$date)
#colnames(dlpm)<-c("date","deb_qtotalj","debit4j","N")
#
#dlpm<-merge(dlpm,ddlpm,by="date",all.x=TRUE)
#pab$date<-as.Date(pab$date)
#dlpm<-merge(dlpm,pab,by="date",all.x=TRUE,all.y=TRUE)
#dlpm$deb_qtotalj[is.na(dlpm$deb_qtotalj)] <- 0
#dlpm$debit4j[is.na(dlpm$debit4j)] <- 0
#pdf(file=str_c(imgwdy,"lpm.pdf"),width=7,height=7)
#plot(dlpm$date,dlpm$effectif,type="b",xlab="Date",ylab="Nombre de lamproies | Q (m3/s)",ylim=c(0,max(dlpm$deb_qtotalj,na.rm=TRUE)),col=bleu_EV,pch=16,cex=1.2)
#points(dlpm$date,dlpm$nb_pab,type="b",col=rouille)
#points(dlpm$date,dlpm$deb_qtotalj,type="l",col=orange_EV)
#points(dlpm$date,dlpm$debit4j,type="l",col="red")
#rect(grconvertX(as.Date(ymd("2019-02-01"))),grconvertY(0),grconvertX(as.Date(ymd("2019-05-01"))),grconvertY(50),lty=2)
#rect(grconvertX(dlpm$date[1]),grconvertY(150),grconvertX(dlpm$date[170]),grconvertY(420),col="grey80")
#par("plt"=c(0.25,0.6,0.5,0.8),new=TRUE,col="white",col.axis="white",col.lab="white",fg="white")
#iii<-dlpm$date>=as.Date(ymd("2019-02-01"))&dlpm$date<as.Date(ymd("2019-05-01"))
#plot(dlpm$date[iii],dlpm$effectif[iii],type="h",xlab="",ylab="",ylim=c(0,50),col=bleu_EV,pch=15)
#points(dlpm$date[iii],dlpm$nb_pab[iii],type="b",col=rouille)
#points(dlpm$date[iii],dlpm$deb_qtotalj[iii],type="l",col=orange)
#points(dlpm$date[iii],dlpm$debit4j[iii],type="l",col="red")
#dev.off()
@

\pagestyle{styleannexe}

\section{Discussion}
\subsection{Migration}

Plusieurs pics de débits autour de 100 \si{\cubic\metre\per\second} ont été
observés très tôt dans la saison en octobre et novembre. Ces pics se sont
accompagnés par des pics de migration de l'ordre de 1500 anguilles par jour.
Lors du deuxième pic la migration est reconstituée car l'ordinateur a eu des
problèmes d'acquisition. Plus tard dans la saison en janvier et février,
deux pics de débits avec des débits de grande crue de l'ordre de 700
\si{\cubic\metre\per\second} se sont succédés. Le premier pic, composé d'une
première vague de débit puis d'un ressaut, a permis la migration d'effectifs
journaliers de l'ordre de 3000- 4000 anguilles par jour lors du pic. Le didson
a été retiré de l'eau lors du deuxième pic, mais sur plusieurs nuits, les effectifs en migration étaient nuls,
et la qualité des images était suffisamment bonne pour pouvoir détecter les
anguilles argentées car la turbiditité était faible. Il est très probable que
les effectifs ayant migré lors de ce deuxième pic ont été faibles (ce que donne le modèle de prédiction) 
car les forts débits du mois de janvier ont déjà permis le départ d'une grande
part du stock potentiel d'anguilles argentées du bassin. Globalement, les
effectifs totaux sur la saison sont de N=\num{\Sexpr{vvv$N}} soit
  \Sexpr{vvv$total_weight} tonnes (Tableau \ref{tabfinal}, Figure
  \ref{fig_N_interannuel}).
  

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/horairespb}
  \caption[Fonctionnement du didson]{Fonctionnement du didson. Les rectangles
  correspondent chacun à une période d'enregistrement, 
  0  \textcolor{turquoise}{\rule[0mm]{1mm}{2mm}} enregistrement normal, 
  1  \textcolor{jaune_EV}{\rule[0mm]{1mm}{2mm}} problème d'acquisition, 
  2  \textcolor{limegreen}{\rule[0mm]{1mm}{2mm}} problème d'écriture, 
  3  \textcolor{orange_EV}{\rule[0mm]{1mm}{2mm}} problème de qualité, 
  4  \textcolor{rouille}{\rule[0mm]{1mm}{2mm}} mauvais positionnement du didson
  ou écoulement ailleurs sur le barrage, 
  5 \textcolor{gray}{\rule[0mm]{1mm}{2mm}} vanne fermée mais ensemble du
  barrage fermé également.}
  \label{fig_horairespb}
  % heure de fonctionnement
\end{figure}



\subsection{Biais et précision}
\subsubsection{Confusion avec d'autres espèces}
L'anguille présente une morphologie et une nage particulière qui
permettent de la discerner des autres poissons \citep{langkau_can_2012}.
En \Sexpr{saison}, \Sexpr{vvv$lpm} lamproies marines 
(\textit{Petromyzon marinus}) ont été détectées, une en février, une en mars, et
le reste les 12 et 13 avril. Dans la passe à bassins, les principales migrations
de lamproies ont été observées entre le 31 mars et le 16 avril. 
La première lamproie observée (02/02) arrive avant la
première observation sur la passe car le suivi vidéo ne débute que fin février.

\begin{table}
\centering
\caption[Nombre de lamproies]{Nombre de lamproies marines comptées au didson en
fonction des saisons de suivi. Entre parenthèse les lamproies en direction
descendante.}
\label{tab_nblpm}
\begin{tabular}{rr}
  \hline
 Année & effectif  \\ 
  \hline
2012--2013 &  640 \\ 
2013--2014 &  29 \\ 
2014--2015 &  275\\ 
2015--2016 &  655+(278)    \\
2016--2017 & 7+(1)\\
2018--2019 & 1\\
2019--2020 & 0\\
2020--2021 & 58\\
   \hline
\end{tabular}
\end{table}



%\begin{figure}[htbp]
%  \centering
%  \includegraphics[width=0.5\textwidth]{2021/lpm.pdf}
%  \caption[Effectif]{Effectifs journaliers de lamproies en migration, en
%  bleu \textcolor{bleu_EV}{\rule[0.5mm]{1.5mm}{.1pt}} mesurés au droit du
%  didson, en marron
%  \textcolor{rouille}{\rule[0.5mm]{0.7mm}{.3pt}o\rule[0.5mm]{0.7mm}{.3pt}}
%  effectifs comptés en migration sur la passe à bassins\footnote{aucune lamproie cette année}
%  \citep{briand_suivi_2015}, en rouge \textcolor{red}{\rule[0.5mm]{1.5mm}{.3pt}} débits moyens journaliers sur la
%  vanne 4, en orange \textcolor{orange_EV}{\rule[0.5mm]{1.5mm}{.3pt}} débits
%  moyens journaliers sur l'ensemble du barrage. }
%  \label{fig_lpm}
%  % heure de fonctionnement
%\end{figure}

\subsubsection{Taille des anguilles}

La résolution du didson est calculée à partir de la largeur du faisceau (qui correspond
à la moitié de la distance) et du nombre de faisceaux (96) lorsque le didson est
configuré en haute fréquence. La taille des anguilles mesurées correspond au
nombre de faisceaux rencontrés par la cible, mais elle est légèrement sous-estimée 
\citep{bilotta_decline_2011}. En effet, la taille dépasse légèrement un faisceau
sans entrer en contact avec le faisceau suivant. L'erreur de mesure est au maximum de 1 cm à 2m
et elle augmente linéairement jusqu'à 7 cm à 15 m. Globalement on observe une
diminution année après année de la proportion d'anguilles mâles. Ce phénomène
indique très probablement un problème de recrutement au niveau du bassin de la
Vilaine pour les cohortes en migration.

\subsubsection{Efficacité moyenne}

Les efficacité moyennes sont plus faibles que celles calculées historiquement
depuis le nouveau calcul en 2020 intégrant la qualité des anguilles dans le
calcul (Tableau \ref{tabefficacite_moyenne}, Tableau
\ref{tab_efficacite_historique} en annexe). Cette année l'efficacité est
meilleure que l'année dernière ou l'arrêt de la vanne 3 provoquait des
turbulences devant le didson.

\input{../../../pdata/didson/rapport/table/2022/tabefficacite_moyenne.tex}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/fig_effectif}
  \caption[Effectif]{Effectifs journaliers estimés sur l'ensemble du barrage,
				en turquoise $N\odot$ 
				\textcolor{turquoise_EV}{\rule[-0.5mm]{1mm}{3mm}}=effectifs mesurés, en orange $N\otimes$ 
				\textcolor{orange_EV}{\rule[-0.5mm]{0.7mm}{3mm}}=effectifs extrapolés à
				partir de données de densité recueillies dans la journée. 
                En jaune, $N\oplus$
                \textcolor{jaune_EV}{\rule[-0.5mm]{0.7mm}{3mm}} effectifs
                extrapolés à partir d'un modèle saisonnier. En bleu foncé \textcolor{bleu_EV}{\rule{3mm}{0.5mm}} débits
                journaliers estimés au barrage d'Arzal $m3.s^{-1}$(multipliés par 10 pour des raisons graphiques).}
  \label{fig_effectif}
  % heure de fonctionnement
\end{figure}

\subsection{Synthèse inter-annuelle}

Les effectifs par an et leur recalcul à partir d'un modèle intégrant les
données de toutes les années sont comparés (Tableau
\ref{tableau_effectifs_annuels} et Figure \ref{fig_N_interannuel}). 
De 2014 à 2017 les effectifs ont augmenté, probablement du fait du recalcul de
l'efficacité. Ils ont diminué pour 2017--2018 et 2018--2019, et ces deux saisons
un calcul particulier avait été effectué pour corriger du problème de "myopie"
des lentilles du didson. Il est possible que le nouveau calcul -qui ne prend pas
en compte ce problème particulier- sous estime les effectifs \footnote{pas de détection dans la zone la 
plus éloignée du didson donc pas d'extrapolation des effectifs.}. 


% siunitx S[...] left of . is the number of digits left of the decimal and same with the right. 
\begin{table}
\centering
\caption[Production annuelle]{Production en anguilles argentées de la Vilaine à
partir des comptages au didson en fonction des saisons de suivi. 
$N_{old}$ indique les effectifs calculés sur les rapports d'origine, $N_{new}$ indique
les effectifs recalculés en 2021 XXXXXXXXXXXXXXXXXXXXX en assemblant toutes les
données disponibles et utilisant des modèles communs. Débit maximum journalier $Q_{j~max}~m^{3}s^{-1}$.
* comptages partiels pour les effectifs "old".}
\label{table_synthese_production}
\small
\begin{tabular}{cS[table-format=8.0]S[table-format=8.0]S[table-format=5.0]}
  \hline
 Année & {$N{old}$} & {$N_{new}$} & {${Q_{j~max}~m^{3}s^{-1}}$} \\ 
  \hline
2012--2013 & 130000 &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2012-2013" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}} &750\\
2013--2014 & \num{119616} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2013-2014" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}} & 1000\\
2014--2015 * &  \num{69509} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2014-2015"&final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}}
& 400 \\%\cellcolor{gray!20}
2015--2016 &  \num{114186} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2015-2016" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}} & 320 \\
2016--2017 &  \num{81366} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2016-2017" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}}& 200 \\
2017--2018 & \num{68160} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2017-2018" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}}& 200 \\
2018--2019 & \num{64578} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2018-2019" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}}& 200\\
2019--2020 & {-} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2019-2020" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}} & 1000\\
2020--2021 & {-} &
\num{\Sexpr{round(as.numeric(final[final$Saison=="2020-2021" & final$type=="$\\sum\\odot\\otimes\\oplus$(?)","$N$"]),0)}} & 700\\
2021--2022 & {-} & & \\
 \hline
\end{tabular}
\normalsize
\label{tableau_effectifs_annuels}
\end{table}


La tendance interannuelle est à la baisse, avec une légère augmentation à partir
du minimum observé en 2017-2018. La réaugmentation des effectifs est cohérente
avec une modification du sexe ratio à partir du minimum (5\% de mâles) observés
en 2017-2018. Globalement même sur une période d'observation relativement
courte (série de moins de 10 ans), les effectifs sont en baisse. Sur le bassin versant de la Vilaine, le
stock en place est plus qu'ailleurs la résultante des mesures de gestion prises sur la phase civelle.
L'augmentation de la proportion de mâles traduit probablement l'effet combiné de
l'introduction des quotas, de l'augmentation des migrations sur la passe et du 
transport de civelles qui s'est traduit par un pic de recrutement fluvial entre
2012 et 2014 . Les mâles partant en 2021 auraient un âge continental de 6 à 8
ans ce qui est cohérent avec les données de croissance recueillies sur le bassin. Il est
donc probable que cet effectif de mâles donne le pas à un départ de femelles
argentées dans les années qui viennent. Les effectifs plus importants observés
l'année dernière (2019-2020) sont peut être lié à l'effet d'une grande crue
suivant plusieurs années sans débit important qui aurait permis le départ d'un
plus grand nombre d'anguilles argentées, bloquées dans leur progression par la
succession d'ouvrages entravant leur migration.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{2022/N_interannuel}
  \caption[Effectif]{Effectifs annuels estimés sur l'ensemble du barrage,
				en turquoise $(N)\odot$ 
				\textcolor{turquoise_EV}{\rule[-0.5mm]{1mm}{3mm}}=effectifs mesurés, en orange $N\otimes$ 
				\textcolor{orange_EV}{\rule[-0.5mm]{0.7mm}{3mm}}=effectifs extrapolés à
				partir de données de densité recueillies dans la journée et extrapolés en fonction
				du ratio des débits lors des observations et sans. En jaune, $N\oplus$
				\textcolor{jaune_EV}{\rule[-0.5mm]{0.7mm}{3mm}} effectifs extrapolés à d'un
				modèle saisonnier.				}
  \label{fig_N_interannuel}
\end{figure}

\clearpage


\section{Annexes}
\pagestyle{styleannexe} % pour faire apparaitre annexe dans le header de l'annexe
\subsection{Comptage par positions}

Un traitement des données de détection a été programmé pour donner une idée des
détections à la descente (+) et à la montée (-). Les ouvertures de vannes sur
les figures correspondent aux ouvertures moyennes lors des détections (elles
sont pondérées par les effectifs en migration). Chaque figure correspond à un des
positionnements du didson et un type d'écoulement : volet, vanne ou fermé.  
$\Phi$= fonctionnement de la vanne (s= surface, f=fond, o=pas d'écoulement), $\beta$ angle du didson, 
$h$= hauteur du didson en côte orthométrique, $O_t$=
nombre de périodes de 30 minutes, $O_t\circ$=nombre de périodes de 30
minutes ayant fait l'objet d'un dépouillement, $N'_{4o}+$=nombre
d'anguilles observées en dévalaison, $N'_{4o}-$=nombre d'anguilles
observées en montaison (nage dirigée vers l'amont). La hauteur de la
vanne et la charge sur le volet correspondent à la moyenne des hauteurs
observées pondérée par les effectifs en migration.

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode4_phi0_didf_4}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode4_phi0_didf_4"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode4_phi0_didf_4"$incl}, 
                $h$=\Sexpr{ppp$"periode4_phi0_didf_4"$prof}, 
                $O_t$=\Sexpr{ppp$"periode4_phi0_didf_4"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode4_phi0_didf_4"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode4_phi0_didf_4"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode4_phi0_didf_4"$minus},
                date= \Sexpr{iconv(ppp$"periode4_phi0_didf_4"$date,"UTF-8")}
                }
                \label{periode4}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode5_phif_didf_4}
        \caption{
                $\Phi$=\Sexpr{ppp$periode5_phif_didf_4$Phi}, 
                $\beta$=\Sexpr{ppp$periode5_phif_didf_4$incl}, 
                $h$=\Sexpr{ppp$periode5_phif_didf_4$prof}, 
                $O_t$=\Sexpr{ppp$periode5_phif_didf_4$N}, 
                $O_t\circ$=\Sexpr{ppp$periode5_phif_didf_4$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$periode5_phif_didf_4$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$periode5_phif_didf_4$minus},
                date= \Sexpr{iconv(ppp$periode5_phif_didf_4$date,"UTF-8")}
                }
                \label{periode5}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode6_phis_didf_4}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode6_phis_didf_4"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode6_phis_didf_4"$incl}, 
                $h$=\Sexpr{ppp$"periode6_phis_didf_4"$prof}, 
                $O_t$=\Sexpr{ppp$"periode6_phis_didf_4"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode6_phis_didf_4"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode6_phis_didf_4"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode6_phis_didf_4"$minus},
                date= \Sexpr{iconv(ppp$"periode6_phis_didf_4"$date,"UTF-8")}}
        \label{periode6}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode7_phis_dids_-7"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode7_phis_dids_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode7_phis_dids_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode7_phis_dids_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode7_phis_dids_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode7_phis_dids_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode7_phis_dids_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode7_phis_dids_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode7_phis_dids_-7"$date,"UTF-8")}
                 }
                \label{periode7}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode8_phif_dids_-7"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode8_phif_dids_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode8_phif_dids_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode8_phif_dids_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode8_phif_dids_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode8_phif_dids_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode8_phif_dids_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode8_phif_dids_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode8_phif_dids_-7"$date,"UTF-8")}
}
                \label{periode8}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode9_phis_dids_-14"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode9_phis_dids_-14"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode9_phis_dids_-14"$incl}, 
                $h$=\Sexpr{ppp$"periode9_phis_dids_-14"$prof}, 
                $O_t$=\Sexpr{ppp$"periode9_phis_dids_-14"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode9_phis_dids_-14"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode9_phis_dids_-14"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode9_phis_dids_-14"$minus},
                date= \Sexpr{iconv(ppp$"periode9_phis_dids_-14"$date,"UTF-8")}
                }
                \label{periode9}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode10_phis_didf_-7}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode10_phis_didf_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode10_phis_didf_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode10_phis_didf_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode10_phis_didf_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode10_phis_didf_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode10_phis_didf_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode10_phis_didf_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode10_phis_didf_-7"$date,"UTF-8")}
              }
              \label{periode10}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode11_phif_didf_-7}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode11_phif_didf_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode11_phif_didf_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode11_phif_didf_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode11_phif_didf_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode11_phif_didf_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode11_phif_didf_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode11_phif_didf_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode11_phif_didf_-7"$date,"UTF-8")}               
               }
                \label{periode11}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/periode12_phi0_dids_-7}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode12_phi0_dids_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode12_phi0_dids_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode12_phi0_dids_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode12_phi0_dids_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode12_phi0_dids_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode12_phi0_dids_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode12_phi0_dids_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode12_phi0_dids_-7"$date,"UTF-8")}               
                }
                \label{periode12}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode13_phi0_didf_-7"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode13_phi0_didf_-7"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode13_phi0_didf_-7"$incl}, 
                $h$=\Sexpr{ppp$"periode13_phi0_didf_-7"$prof}, 
                $O_t$=\Sexpr{ppp$"periode13_phi0_didf_-7"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode13_phi0_didf_-7"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode13_phi0_didf_-7"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode13_phi0_didf_-7"$minus},
                date= \Sexpr{iconv(ppp$"periode13_phi0_didf_-7"$date,"UTF-8")}               
            }
     \label{periode13}
\end{figure}


\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode14_phif_didf_4"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode14_phif_didf_4"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode14_phif_didf_4"$incl}, 
                $h$=\Sexpr{ppp$"periode14_phif_didf_4"$prof}, 
                $O_t$=\Sexpr{ppp$"periode14_phif_didf_4"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode14_phif_didf_4"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode14_phif_didf_4"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode14_phif_didf_4"$minus},
                date= \Sexpr{iconv(ppp$"periode14_phif_didf_4"$date,"UTF-8")}               
            }
     \label{periode14}
\end{figure}


\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode15_phi0_didf_4"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode15_phi0_didf_4"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode15_phi0_didf_4"$incl}, 
                $h$=\Sexpr{ppp$"periode15_phi0_didf_4"$prof}, 
                $O_t$=\Sexpr{ppp$"periode15_phi0_didf_4"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode15_phi0_didf_4"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode15_phi0_didf_4"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode15_phi0_didf_4"$minus},
                date= \Sexpr{iconv(ppp$"periode15_phi0_didf_4"$date,"UTF-8")}               
            }
     \label{periode15}
\end{figure}



\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode16_phi0_didf_5"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode16_phi0_didf_5"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode16_phi0_didf_5"$incl}, 
                $h$=\Sexpr{ppp$"periode16_phi0_didf_5"$prof}, 
                $O_t$=\Sexpr{ppp$"periode16_phi0_didf_5"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode16_phi0_didf_5"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode16_phi0_didf_5"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode16_phi0_didf_5"$minus},
                date= \Sexpr{iconv(ppp$"periode16_phi0_didf_5"$date,"UTF-8")}               
            }
     \label{periode16}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode17_phif_didf_5"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode17_phif_didf_5"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode17_phif_didf_5"$incl}, 
                $h$=\Sexpr{ppp$"periode17_phif_didf_5"$prof}, 
                $O_t$=\Sexpr{ppp$"periode17_phif_didf_5"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode17_phif_didf_5"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode17_phif_didf_5"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode17_phif_didf_5"$minus},
                date= \Sexpr{iconv(ppp$"periode17_phif_didf_5"$date,"UTF-8")}               
            }
     \label{periode17}
\end{figure}

\begin{figure}[htbp]
        \centering
        \includegraphics[trim=35mm 40mm 25mm
                25mm,clip, width=0.5\textwidth]{2022/"periode18_phis_didf_5"}
        \caption{
                $\Phi$=\Sexpr{ppp$"periode18_phis_didf_5"$Phi}, 
                $\beta$=\Sexpr{ppp$"periode18_phis_didf_5"$incl}, 
                $h$=\Sexpr{ppp$"periode18_phis_didf_5"$prof}, 
                $O_t$=\Sexpr{ppp$"periode18_phis_didf_5"$N}, 
                $O_t\circ$=\Sexpr{ppp$"periode18_phis_didf_5"$Nsuivis},
                $N'_{4o}+$=\Sexpr{ppp$"periode18_phis_didf_5"$plus}, 
                $N'_{4o}-$=\Sexpr{ppp$"periode18_phis_didf_5"$minus},
                date= \Sexpr{iconv(ppp$"periode18_phis_didf_5"$date,"UTF-8")}               
            }
     \label{periode18}
\end{figure}

\clearpage
\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Notations}
\begin{table}[htp] \centering 
  \begin{tabular}{|l | p{6cm}|} 
  \hline    
        $\tau$ & Tailles d'anguilles, <45cm mâles,45-60cm petites
       femelles, 60-80cm femelles, >80cm grandes femelles\\ \hline
         $\delta$ & Classes de distance au sonar (2,5m[, (5,7m[, (7,9m[, (9,11m[, (11,13m[ et
        (13,15m[ \\ \hline   
         $\beta$ & Angle du didson\\ \hline
         $\Phi$ & Type d'écoulement du barrage , $s$ surface, $f$=fond\\ \hline
         $O_t$& Période d'enregistrement de 30 mn\\ \hline
         $O_t\circ$& Période d'enregistrement de 30 mn avec
         visualisation\\\hline
         $h$ & Altitude du didson en IGN69 \\ \hline
         $N'_{4o}(t,\tau,\delta,k)$ & Dévalaison observée dans le champ de
           détection du didson sur la vanne 4\\ \hline
         $N_{4o}(t,\tau,\delta,k)$ & Dévalaison réelle dans le champ de
        détection du didson sur la vanne 4, c'est à dire corrigée des problèmes
        d'efficacité de détection\\ \hline      
         $N_4(t,\tau)$ & Dévalaison sur l'ensemble de la vanne 4\\ \hline   
         $N(t,\tau)$ & Dévalaison au pas de temps $t$ pour la
         classe de taille $\tau$\\ \hline
  \end{tabular} 
\end{table} 
\begin{table}[htp] 
\centering 
  \begin{tabular}{|l | p{6cm}|} 
  \hline     
      $Q_4(t)$ & Débit total de la vanne 4 au temps $t$\\ \hline
      $Q(t)$ & Débit total de la Vilaine au temps $t$\\ \hline 
      $S(k,\delta)$ & Surface couverte par le faisceau à la distance $\delta$
     pour la position $k$\\ \hline
      $S(k)$ & Surface couverte par le faisceau pour la position $k$\\ \hline
      $D(t)$ & Profondeur de la colonne d'eau en amont\\ \hline
      $C(t)$ & Charge d'eau sur le volet en surface\\ \hline
      $F(t,k,\Lambda,\lambda)$ & Fonction de répartition verticale des
     anguilles\\ \hline
       $l$ & Largeur de la vanne\\ \hline
      $\widehat{E(\delta,\tau,k)}$ & Efficacité du didson calculée par un
     glm\\ \hline
      $\bar{E_k}$ & Efficacité moyenne du didson pour chaque position k\\ \hline
      $\rho_k$ & Facteur de correction des effectifs pour tenir compte de la
     minute perdue par demie-heure lorsque le rotateur est actionné\\ \hline
      $\mu$ & Pourcentage d'anguilles migrant de jour\\ \hline
      $\Lambda$ & Coefficient donnant le rapport entre la hauteur de la fenêtre
     de migration au droit du didson et la hauteur de la vanne\\ \hline
      $\lambda$ & Coefficient donnant le rapport entre la hauteur de la fenêtre
     de migration au droit du didson et la charge (hauteur d'eau) sur le volet\\ \hline
      $\hat{P}(N)$ & Effectifs modélisés\\ \hline
      $\odot$ & Période de suivi complet sans problème de qualité\\ \hline
      $\otimes$ & Période de suivi extrapolée, problème d'enregistrement
        ou de qualité\\ \hline
      $\oslash$ & Périodes sans problème de qualité mais avec un mauvais
        positionnement du didson (les périodes $\oslash$ sont inclues dans
        $\otimes$)\\ \hline
     $\oplus$ & Période sans donnée pendant laquelle les effectifs sont
     extrapolés à partir des données des jours voisins.\\
     \hline
     \end{tabular} 
\end{table} 

\newpage{}
\subsection{Tableaux}
\onecolumn
\input{../../../pdata/didson/rapport/table/2022/aovefficacite.tex}
\newpage{}
\input{../../../pdata/didson/rapport/table/2022/tabfinal.tex}
\newpage
\input{../../../pdata/didson/rapport/table/2022/table_effectif_mois.tex}
\newpage
\input{../../../pdata/didson/rapport/table/2022/tableau_modele_miss.tex}
\normalsize
\begin{landscape}
\begin{figure}
    \includegraphics[width=0.8\linewidth,keepaspectratio]{2022/fig_effectif_pb}
\caption[Effectif]{Effectifs journaliers estimés sur l'ensemble du barrage,
				en turquoise $(N)\odot$ 
				\textcolor{bleu_EV}{\rule[-0.5mm]{1mm}{3mm}}=effectifs mesurés, en
				turquoise $N\otimes$
				\textcolor{turquoise_EV}{\rule[-0.5mm]{0.7mm}{3mm}}=effectifs extrapolés à
				partir de données de densité recueillies dans la journée.
                En orange, $N\oplus$
                \textcolor{orange_EV}{\rule[-0.5mm]{0.7mm}{3mm}} effectifs
                extrapolés à partir des données des jours voisins. En bleu \textcolor{blue}{\rule{3mm}{0.5mm}}, débits
                journaliers estimés au barrage d'Arzal $m3.s^{-1}$(multipliés par 10 pour des raisons graphiques).
                En rouge, \textcolor{red}{\rule{3mm}{0.5mm}}, débits de la
                vanne 4. Les barres en gris et marron indiquent la position
                verticale du didson.
                Les rectangles en arrière plan indiquent les problèmes
                d'acquisition (en jaune) et de qualité (en orange) ou
                d'écriture disque (en vert).}
  \label{fig_effectif_pb}
  \end{figure}
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth,keepaspectratio]{2022/nombre_taille_distance}
  \caption[Effectifs observés et corrigés]{Effectifs observés (traits
  plains) et corrigés de l'augmentation de la taille du faisceau (traits
  pointillés) en fonction de la distance, pour l'ensemble des saisons et les
  deux classes de distance. Les cercles jaunes correspondent au maximum observé pour
  les effectifs corrigées (pas toujours au plus près du didson).}
  \label{nombre_taille_distance}
\end{figure}
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth,keepaspectratio]{2022/efficacite}
  \caption[Efficacité]{Efficacité en fonction de la taille des anguilles et de
  la distance au didson, commune aux deux positions du sonar, fond et surface.}
  \label{efficacite}
\end{figure}
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\linewidth,keepaspectratio]{2022/Ncor}
  \caption[Effectifs recalculés]{Effectif recalculés après correction. En
  théorie les effectifs devraient augmenter. Il n'est pas toujours possible
  d'extrapoler les effectifs pour la classe de distance la plus grande, car il
  n'y a alors plus de détections.}
  \label{Ncor}
\end{figure}
%=====================================================================
\end{landscape}
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{2022/taille_distance_vannefond}
  \caption[Taille des anguilles vannes]{Taille des anguilles en fonction de la
  distance au sonar en vannes. Couleur en fonction du nombre d'observations par
  carré.
  Les polygones d'isodensité permettent de mettre en évidence la relation
  distance - taille (les plus petites anguilles ne sont visibles que près du
  didson). Les données correspondent à toutes les anguilles enregistrées depuis
  2012 pour une position du didson au fond.}
  \label{taille_distance_vannefond}
\end{figure}
%=====================================================================
%=====================================================================
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{2022/taille_distance_volet}
  \caption[Taille des anguilles vannes]{Taille des anguilles en fonction de la
  distance au sonar en volets. Couleur en fonction du nombre d'observations par
  carré.
  Les polygones d'isodensité permettent de mettre en évidence la relation
  distance - taille (les plus petites anguilles ne sont visibles que près du
  didson). Les données correspondent à toutes les anguilles enregistrées depuis
  2012 pour une position du didson en surface.}
  \label{taille_distance_volet}
\end{figure}
%=====================================================================

\twocolumn   


 \begin{table}[htbp]
\centering
\caption[Efficacités moyennes historiques]{Efficacités moyennes calculées lors
des précédents rapports pour les différentes positions du didson pour les 7 saisons
de suivi. * Hors problèmes de concentrateur.}
\label{tab_efficacite_historique}
\begin{tabular}{rrr}
  \hline
 Année & surface & fond 5-15m  \\ 
  \hline
2012--2013 & 65 & 53\\ 
2013--2014 & 58 & 58\\ 
2014--2015 & 60 & 53\\ 
2015--2016 & 59 & 55\\
2016--2017 & 53 & 63\\
2017--2018* & 36 & 60\\
2018--2019* & 56 & 52\\
   \hline
\end{tabular}
\end{table}





\clearpage % termine la page et met tous les floats non terminés ici
\twocolumn

\printbibliography

\nul
\vfill
\section*{Remerciements}
Les principaux remerciements, vont au personnel
d'exploitation du barrage d'Arzal, Gilbert Olivier, Laurent Philippot, Thierry
Besnard, Johann Dalhem, Alban Leguen, Cyril Faucon pour leur
aide au quotidien.
Cette étude a été financée par l'Agence de l'eau Loire
Bretagne.


\begin{center}
   Rapport \LaTeX \\
   Dernière compilation le \today correction\\
\Sexpr{str_c("version R ",version$major,".",version$minor)} 
\end{center}






\end{document}

%%============================================================
%%============================================================
%%==========    HINTS    ========================%%

	%% About chapters and TOC
	


	%% A table of contents is produced with the \tableofcontents command. You put the command right where you want the table of contents to go; LaTeX does the rest for you. It produces a heading, but it does not automatically start a new page. If you want a new page after the table of contents, include a \newpage command after the \tableofcontents command.
	%% There are similar commands \listoffigures and \listoftables for producing a list of figures and a list of tables, respectively. Everything works exactly the same as for the table of contents. 
	%% \addcontentsline{file}{sec_unit}{entry}
	%% The \addcontentsline command adds an entry to the specified list or table where file is the extension of the file on which information is to be written: toc (table of contents), lof (list of figures), or lot (list of tables).
	%% sec_unit controls the formatting of the entry. It should be one of the following, depending upon the value of the file argument:
		%% toc the name of the sectional unit, such as part or subsection.
		%% lof figure
		%% lot table 
	%% entry is the text of the entry.
	
	%% For example if you use an unnumbered section heading command to start a preliminary piece of text like a Foreword or Preface, you can write:    
	%% \subsection*{Preface}
	%% \addcontentsline{toc}{subsection}{Preface}    
	%% This will format an unnumbered ToC entry for "Preface" in the "subsection" style.
	
	%% The default ToC will list headings of level 3 and above. To change how deep the table of contents displays automatically the following command can be  used in the preamble:
	%% \setcounter{tocdepth}{4}
	
	%% \chapter[Page layout]{Exploring the page layout} % A heading might be very long; it could span over two or more lines. In that case, we might wish to shorten its corresponding table of contents entry. We can use the optional argument of the sectioning commands to produce shorter entries, different to the actual heading.
%%============================================================

	%% Floating environments

	%% Floating environments such as figures or tables are forbidden in the multicol environment.  
	%% To get around this limitation, you have two options when including a figure or table:
	%% use \begin{figurehere}... \end{figurehere} and \begin{tablehere}... \end{tablehere} 
	%% to place a float in the two column format,
	%% or you can use \begin{figure*} \begin{table*}.  These commands will span your float body across the page, usually at the top --- best for large images and tables.
	
	%% E.g.
	% \begin{figure}[H]
	%   \centering
	%	 \includegraphics[width=\textwidth]{name-of-the-picture}
	%	 \caption{}
	%	 \label{fig:basicProbability}
	% \end{figure}
%%============================================================	
	
	%% References
	%%
	%% Note: 'bibmodel.bst' has been changed so it preserves 
	%% original titles (without change case)
	%%
	%% Following citation commands can be used in the body text:
	%%
	%%  \citet{key}  ==>>  Jones et al. (1990)
	%%  \citep{key}  ==>>  (Jones et al., 1990)
	%%
	%% Multiple citations as normal:
	%% \citep{key1,key2}         ==>> (Jones et al., 1990; Smith, 1989)
	%%                            or  (Jones et al., 1990, 1991)
	%%                            or  (Jones et al., 1990a,b)
	%% \cite{key} is the equivalent of \citet{key} in author-year mode
	%%
	%% Full author lists may be forced with \citet* or \citep*, e.g.
	%%   \citep*{key}            ==>> (Jones, Baker, and Williams, 1990)
	%%
	%% Optional notes as:
	%%   \citep[chap. 2]{key}    ==>> (Jones et al., 1990, chap. 2)
	%%   \citep[e.g.,][]{key}    ==>> (e.g., Jones et al., 1990)
	%%   \citep[see][pg. 34]{key}==>> (see Jones et al., 1990, pg. 34)
	%%  (Note: in standard LaTeX, only one note is allowed, after the ref.
	%%   Here, one note is like the standard, two make pre- and post-notes.)
	%%
	%%   \citealt{key}          ==>> Jones et al. 1990
	%%   \citealt*{key}         ==>> Jones, Baker, and Williams 1990
	%%   \citealp{key}          ==>> Jones et al., 1990
	%%   \citealp*{key}         ==>> Jones, Baker, and Williams, 1990
	%%
	%% Additional citation possibilities
	%%   \citeauthor{key}       ==>> Jones et al.
	%%   \citeauthor*{key}      ==>> Jones, Baker, and Williams
	%%   \citeyear{key}         ==>> 1990
	%%   \citeyearpar{key}      ==>> (1990)
	%%   \citetext{priv. comm.} ==>> (priv. comm.)
	%%   \citenum{key}          ==>> 11 [non-superscripted]
	%% Note: full author lists depends on whether the bib style supports them;
	%%       if not, the abbreviated list is printed even when full requested.
	%%
	%% For names like della Robbia at the start of a sentence, use
	%%   \Citet{dRob98}         ==>> Della Robbia (1998)
	%%   \Citep{dRob98}         ==>> (Della Robbia, 1998)
	%%   \Citeauthor{dRob98}    ==>> Della Robbia
	
%%============================================================
%%============================================================
%%============================================================

